<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>PingCAP Site</title>
    <link>https://pingcap.com/</link>
    <description>Recent content on PingCAP Site</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://pingcap.com/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Bringing TiKV to Rust Devroom at FOSDEM 2018</title>
      <link>https://pingcap.com/blog/FOSDEM-2018-Rust-Devroom-reflection/</link>
      <pubDate>Thu, 15 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/FOSDEM-2018-Rust-Devroom-reflection/</guid>
      <description>At the crack of dawn on February 1, I landed in Brussels, Belgium, for the first time in my life. The goal of my trip wasn’t to taste the local cuisine, tour world-famous museums, or grab a pint of the local brew (though I ended up doing all those things anyway). It was to deliver a talk three days later at &amp;ldquo;FOSDEM 2018 Rust Devroom&amp;rdquo; about our experience at PingCAP using Rust to build TiKV, a distributed transactional Key-Value storage engine.</description>
    </item>
    
    <item>
      <title>Weekly update (February 05 ~ February 11, 2018)</title>
      <link>https://pingcap.com/weekly/2018-02-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-02-12-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 67 PRs in the TiDB repositories.
Added  CreateIndex supports the LOCK option. Add GoVersion info for tidb_version Add a session variable to show the configuration Support show stats_healthy to check if a table needs to be analyzed  Removed  Remove the useless field in jsonColumn Clean up the abandoned storage engine
  Fixed  Check the CreateTable statement charset option Fix the bug of show index printing non-public index when add index operation is not finished Treat a decimal truncate as a warning in update  Improved  Run GC workers parallelly Pass the operator label from Plan to Executor Prepare the candidate index to improve performance Use pseudo estimation when the stats of some table is outdated Ignore the error and keep GC always working Set a min count for AutoAnalyze to avoid the auto analysis of small tables Improve importer tools:  Support randDate by statistics Support generating other types of columns randomly by statistics Generate a string by statistics Support VARCHAR in set Generate the integer data by Histogram  Refine metrics in TiDB:  Rename _count to _num Unify metrics naming Add a metric for pseudo estimation Make metrics content clearer and compacter Move domain metrics and add the privilege load counter Add metrics for DDL and the server Add metrics for the DDL worker Add metrics for expensive executors and statement nodes Add metrics for stats Fix inconsistent labels for the panic counter Move DDL metrics from the ddl package to the metrics package Refine TiKV client metrics Add metrics for the DDL owner Add metrics and logs for ticlient   Weekly update in TiSpark Last week, we landed 6 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.8 Release Notes</title>
      <link>https://pingcap.com/blog/2018-02-11-108/</link>
      <pubDate>Sun, 11 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2018-02-11-108/</guid>
      <description>On Feburary 11, 2018, TiDB 1.0.8 is released with the following updates:
TiDB:  Fix issues in the Outer Join result in some scenarios Optimize the performance of the InsertIntoIgnore statement Fix the issue in the ShardRowID option Add limitation (Configurable, the default value is 5000) to the DML statements number within a transaction Fix an issue in the Table/Column aliases returned by the Prepare statement Fix an issue in updating statistics delta Fix a panic error in the Drop Column statement Fix an DML issue when running the Add Column After statement Improve the stability of the GC process by ignoring the regions with GC errors Run GC concurrently to accelerate the GC process Provide syntax support for the CREATE INDEX statement  PD:  Reduce the lock overheat of the region heartbeats Fix the issue that a hot region scheduler selects the wrong Leader  TiKV:  Use DeleteFilesInRanges to clear stale data and improve the TiKV starting speed Using Decimal in Coprocessor sum Sync the metadata of the received Snapshot compulsorily to ensure its safety  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>Weekly update (January 29 ~ February 04, 2018)</title>
      <link>https://pingcap.com/weekly/2018-02-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-02-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 35 PRs in the TiDB repositories.
Added  Support the load stats command  Removed  Remove iota in DDL package to make the constant clearer  Fixed  limit and offset can be parameter markers in the prepared statement IndexOption can be a list in creating a table Fix the bug of some field length missing in creating a table Fix the bug of parsing Datetime overflow Trim leading zeros before parsing integer literal Fix the float truncate bug  Improved  Importer tools support loadStats by path Support mock table info for importer tools Let DO statement be a read only statement Improve an error handling in ddl Reduce memory allocation in buildDataSource Make Explain clearer Add the metrics package and recover Panic of Worker Refine the joinResult generator to return maxChunkSize chunk Limit lock count for ScanLock request Enhance the IndexRange calculation Refine metrics in TiDB:  Refine DistSQL metrics Add metrics for the meta package Move and refine the server metrics Add metrics for DDL syncer Update metrics for session   Weekly update in TiSpark Last week, we landed 6 PRs in the TiSpark repositories.</description>
    </item>
    
    <item>
      <title>Weekly update (January 22 ~ January 28, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-29-tidb-weekly/</link>
      <pubDate>Mon, 29 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-29-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Add the importer tool Add metrics for GC failure count Add metrics for TiDB-server panic Add metrics for async secondary lock cleanup Support create time in information_schema  Removed  Remove GetSessionVars() in expression evaluation Remove varsutil package, and make Systems a private member of SessionVars  Fixed  Avoid the generation of mysql.</description>
    </item>
    
    <item>
      <title>TiDB DevCon 2018 Recap - News, Latest Development, and Roadmap</title>
      <link>https://pingcap.com/blog/tidb-devcon-2018-recap/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/tidb-devcon-2018-recap/</guid>
      <description>On January 20th, 2018, a chilly Saturday in the middle of the winter, more than 200 coders, hackers, and techies streamed into Garage Café, a chic coffee shop in the heart of Beijing’s techhub, Zhongguancun. They weren’t there to get coffee. They weren’t there to stay warm. They were there to be part of TiDB DevCon 2018, a technology party for the developers, by the developers.
TiDB DevCon 2018 attendees signing-in on the event banner</description>
    </item>
    
    <item>
      <title>TiDB 1.0.7 Release Notes</title>
      <link>https://pingcap.com/blog/2018-01-22-107/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2018-01-22-107/</guid>
      <description>On January 22, 2018, TiDB 1.0.7 is released with the following updates:
TiDB:  Optimize the FIELD_LIST command Fix data race of the information schema Avoid adding read-only statements to history Add the session variable to control the log query Fix the resource leak issue in statistics Fix the goroutine leak issue Add schema info API for the http status server Fix an issue about IndexJoin Update the behavior when RunWorker is false in DDL Improve the stability of test results in statistics Support PACK_KEYS syntax for the CREATE TABLE statement Add row_id column for the null pushdown schema to optimize performance  PD:  Fix possible scheduling loss issue in abnormal conditions Fix the compatibility issue with proto3 Add the log  TiKV:  Support Table Scan Support the remote mode in tikv-ctl Fix the format compatibility issue of tikv-ctl proto Fix the loss of scheduling command from PD Add timeout in Push metric  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>Weekly update (January 15 ~ January 21, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-22-tidb-weekly/</link>
      <pubDate>Mon, 22 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-22-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Add an interface for Chunk to count the memory usage Add a session variable to log the query string  Removed  Remove the old, never used IndexLookUpJoin  Fixed  group_concat should not modify the argument during execution Correct the unsigned pk&amp;rsquo;s behavior  Improved  Optimize the com_field_list command and make Use Database faster Improve the sort efficiency on lookupTableTask.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</guid>
      <description>2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB  SQL parser  兼容更多语法  SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确的估算点查的代价 支持更复杂的条件，更充分使用索引  SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT INGORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计  Server  支持 PROXY protocol   PD  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 region size Fix 了一些调度的 bug  TiKV  支持 Raft learner 优化 Raft Snapshot，减少 IO 开销 支持 TLS 优化 RocksDB 配置，提升性能 Coprocessor 支持更多下推操作 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 TiKV-CTL 的功能 region 支持按 table 进行分裂 支持 delete range 功能 支持设置 snapshot 导致的 IO 上限 完善流控机制  源码地址：https://github.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/blog/2018-01-19-11-alpha/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2018-01-19-11-alpha/</guid>
      <description> On January 19, 2018, TiDB 1.1 Alpha is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  SQL parser  Support more syntax  SQL query optimizer  Use more compact structure to reduce statistics info memory usage Speed up loading statistics info when starting tidb-server Provide more accurate query cost evaluation Use Count-Min Sketch to evaluate the cost of queries using unique index more accurately Support more complex conditions to make full use of index  SQL executor  Refactor all executor operators using Chunk architecture, improve the execution performance of analytical statements and reduce memory usage Optimize performance of the INSERT INGORE statement Push down more types and functions to TiKV Support more SQL_MODE Optimize the Load Data performance to increase the speed by 10 times Optimize the Use Database performance Support statistics on the memory usage of physical operators  Server  Support the PROXY protocol   PD:  Add more APIs Support TLS Add more cases for scheduling Simulator Schedule to adapt to different Region sizes Fix some bugs about scheduling  TiKV:  Support Raft learner Optimize Raft Snapshot and reduce the IO overhead Support TLS Optimize the RocksDB configuration to improve performance Optimize count (*) and query performance of unique index in Coprocessor Add more failpoints and stability test cases Solve the reconnection issue between PD and TiKV Enhance the features of the data recovery tool TiKV-CTL Support splitting according to table in Region Support the Delete Range feature Support setting the IO limit caused by snapshot Improve the flow control mechanism  </description>
    </item>
    
    <item>
      <title>Weekly update (January 08 ~ January 14, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-15-tidb-weekly/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-15-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Support the ODBC syntax of time/date/timestamp literal Add MaxProcs and make the runtime.GOMAXPROCS parameter configurable  Fixed  Fix a bug about index join Close HashJoin goroutines as soon as possible to avoid unexpected errors fetchShowTableStatus should append an integer to the third column instead of a string Correct the behavior when RunWorker is false Refine the typeInfer of group_concat  Improved  Avoid the Children type assertion Merge IntColumnRange with NewRange Upgrade the username length limit to 32 to be compatible with MySQL 5.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.6 Release Notes</title>
      <link>https://pingcap.com/blog/2018-01-08-106/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2018-01-08-106/</guid>
      <description>On January 08, 2018, TiDB 1.0.6 is released with the following updates:
TiDB:  Support the Alter Table Auto_Increment syntax Fix the bug in Cost Based computation and the Null Json issue in statistics Support the extension syntax to shard the implicit row ID to avoid write hot spot for a single table Fix a potential DDL issue Consider the timezone setting in the curtime, sysdate and curdate functions Support the SEPARATOR syntax in the GROUP_CONCAT function Fix the wrong return type issue of the GROUP_CONCAT function.</description>
    </item>
    
    <item>
      <title>Weekly update (January 01 ~ January 07, 2018)</title>
      <link>https://pingcap.com/weekly/2018-01-08-tidb-weekly/</link>
      <pubDate>Mon, 08 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-08-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 37 PRs in the TiDB repositories.
Added  Support the PACK_KEYS option in the CreateTable statement. Show job&amp;rsquo;s start time in the result of admin show ddl ....  Fixed  Fix a bug when initializing HTTP stats handler. Fix a bug when estimating row count for outdated histograms. Consider time zone for builtin functions curtime/sysdate/curdate.  Improved  Refactor Chunk.AppendRow to handle virtual.</description>
    </item>
    
    <item>
      <title>Weekly update (December 25 ~ December 31, 2017)</title>
      <link>https://pingcap.com/weekly/2018-01-02-tidb-weekly/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2018-01-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 36 PRs in the TiDB repositories.
Added  Add the Iterator interface in Chunk.  Removed  Remove the useless aggregation function during buildQuantifierPlan.  Fixed  Flen and Decimal of TypeNewDecimal should not be -1. To pass sysbench Prepare tests, set Fields for SelectStmt in PrepareExec. Fix the case that fails to split a table. Correct the type inference of the sum and avg functions.</description>
    </item>
    
    <item>
      <title>2017 Reflection and Gratitude</title>
      <link>https://pingcap.com/blog/pingcap-reflection-and-gratitude/</link>
      <pubDate>Sat, 30 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/pingcap-reflection-and-gratitude/</guid>
      <description>In open source, we trust!
2017 has witnessed the growth of PingCAP, from Beijing to Silicon Valley, and the evolution of TiDB, from RC1 to the 1.0 release, and then to the 1.0.5 release. As our CEO Max said in the TiDB 1.0 announcement, &amp;ldquo;because of the hard work and dedication of not just every member of our team, but also every contributor, user, and partner in our open source community.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.5 Release Notes</title>
      <link>https://pingcap.com/blog/2017-12-26-105/</link>
      <pubDate>Tue, 26 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-12-26-105/</guid>
      <description>On December 26, 2017, TiDB 1.0.5 is released with the following updates:
TiDB  Add the max value for the current Auto_Increment ID in the Show Create Table statement. Fix a potential goroutine leak. Support outputting slow queries into a separate file. Load the TimeZone variable from TiKV when creating a new session. Support the schema state check so that the Show Create Tableand Analyze statements process the public table/index only.</description>
    </item>
    
    <item>
      <title>Weekly update (December 18 ~ December 24, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-25-tidb-weekly/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-25-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 48 PRs in the TiDB repositories.
Added  Support the builtin aggregation function bit_or.  Removed  Remove the old JSON type. Remove the HashSemiJoin plan and executor.  Fixed  Support showing the current auto_increment id in the result of show create table. Fix a bug of NewIndexLookUpJoin&#39;s Next(). Fix the trigger condition for AutoAnalyze. Only rebuild the range when using prepared cache.</description>
    </item>
    
    <item>
      <title>Tick or Tock? Keeping Time and Order in Distributed Databases</title>
      <link>https://pingcap.com/blog/Time-in-Distributed-Systems/</link>
      <pubDate>Fri, 22 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/Time-in-Distributed-Systems/</guid>
      <description>Preface At re:Invent 2017, Amazon Web Services (AWS) announced Amazon Time Sync Service, a highly accurate and reliable time reference that is natively accessible from Amazon EC2 instances. It is much like the Google TrueTime published in 2012. Why do Google and AWS both want to make efforts to provide global time service? Is there any inspiration for building distributed database? This topic is important to think about.
Time synchronization remains a hard nut to crack in distributed systems, especially for distributed databases such as TiDB where time is used to confirm the order of the transaction to guarantee the ACID compliance.</description>
    </item>
    
    <item>
      <title>Weekly update (December 11 ~ December 17, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-18-tidb-weekly/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-18-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 46 PRs in the TiDB repositories.
Added  Support SEPARATOR in the group_concat aggregate function. Support the BinaryJSON type. Add a config for the SQL parser to enable parsing syntax for window function. Support the http index MVCC interface.  Fixed  Show the index column length if necessary in show create table statement. Clear the delta info when rolling back a transaction.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.4 Release Notes</title>
      <link>https://pingcap.com/blog/2017-12-11-104/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-12-11-104/</guid>
      <description>TiDB 1.0.4 Release Notes On December 11, 2017, TiDB 1.0.4 is released with the following updates:
TiDB  Speed up the loading of the statistics when starting the tidb-server Improve the performance of the show variables statement Fix a potential issue when using the Add Index statement to handle the combined indexes Fix a potential issue when using the Rename Table statement to move a table to another database Accelerate the effectiveness for the Alter/Drop User statement  TiKV  Fix a possible performance issue when a snapshot is applied  Fix the performance issue for reverse scan after removing a lot of data Fix the wrong encoded result for the Decimal type under special circumstances  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>Weekly update (December 04 ~ December 10, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-11-tidb-weekly/</link>
      <pubDate>Mon, 11 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-11-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 45 PRs in the TiDB repositories.
Added  Add hints to force to choose HashJoin. Provide the HTTP API of table disk usage for tidb-ctl.  Fixed  Fix a bug when updating the JSON field. Delete the auto ID key when renaming the table. Fix a bug in JoinResultGenerator. Fix a bug when backfilling the index with nil. The value of a session variable should not be modified when getting a global variable.</description>
    </item>
    
    <item>
      <title>PingCAP Plants its Seed in Silicon Valley</title>
      <link>https://pingcap.com/blog/Silicon-Valley-Office-Announcement/</link>
      <pubDate>Fri, 08 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/Silicon-Valley-Office-Announcement/</guid>
      <description>PingCAP Plants its Seed in Silicon Valley PingCAP, a cutting-edge distributed Hybrid Transactional/Analytical Processing (HTAP) database company, is excited to announce the opening of its Silicon Valley office, located at the GSV Labs in Redwood City, California. GSV (Global Silicon Valley) Labs is a global innovation platform that houses more than 170 startups, investors, and partners in its 60,000 square foot space in the heart of Silicon Valley. Its member startups work in a wide range of technologies and industries, from Big Data and healthcare, to VR and education.</description>
    </item>
    
    <item>
      <title>Weekly update (November 27 ~ December 03, 2017)</title>
      <link>https://pingcap.com/weekly/2017-12-04-tidb-weekly/</link>
      <pubDate>Mon, 04 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-12-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 43 PRs in the TiDB repositories.
Added  Add an option to disable Chunk. Add the schema info API of the http status server.  Removed  Remove the Align method of IndexRange.  Fixed  Set the priority for IndexLookupExecutor when reading the table. Fix the length metadata of the decimal column returned to the client. Fix the bug about auto-increment key after renaming a table from the old DB to another DB.</description>
    </item>
    
    <item>
      <title>A TiKV Source Code Walkthrough – Raft Optimization</title>
      <link>https://pingcap.com/blog/optimizing-raft-in-tikv/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/optimizing-raft-in-tikv/</guid>
      <description>Paxos or Raft is frequently used to ensure data consistency in the distributed databases. But Paxos is known for its complexity and is rather difficult to understand while Raft is very simple. Therefore, a lot of emerging databases tend to use Raft as the consensus algorithm at its bottom layer. TiKV is no exception.
Simple as Raft is, its performance is not ideal if we follow exactly the way introduced in the Paper.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.3 Release Notes</title>
      <link>https://pingcap.com/blog/2017-11-28-103/</link>
      <pubDate>Tue, 28 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-11-28-103/</guid>
      <description>TiDB  Optimize the performance in transaction conflicts scenario Add the TokenLimit option in the config file Output the default database in slow query logs Remove the DDL statement from query duration metrics Optimize the query cost estimation Fix the index prefix issue when creating tables Support pushing down the expressions for the Float type to TiKV Fix the issue that it is slow to add index for tables with discrete integer primary index Reduce the unnecessary statistics updates Fix a potential issue during the transaction retry  PD  Support adding more types of schedulers using API  TiKV  Fix the deadlock issue with the PD client Fix the issue that the wrong leader value is prompted for NotLeader Fix the issue that the chunk size is too large in the coprocessor  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>Weekly update (November 20 ~ November 26, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 60 PRs in the TiDB repositories.
Added  Support the Create View syntax. Support the PAD_CHAR_TO_FULL_LENGTH sql_mode. Support the PROXY protocol.  Fixed  Fix a bug in retry(). Fix a bug about parse duration when the fsp round overflows 60 seconds. Fix the missing index update about automatic updating for TIMESTAMP. Fix a bug when val &amp;gt; MaxInt32 in the from_unixtime argument.</description>
    </item>
    
    <item>
      <title>Weekly update (November 13 ~ November 19, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-20-tidb-weekly/</link>
      <pubDate>Mon, 20 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 48 PRs in the TiDB repositories.
Removed  Remove redundant ResolveIndices. Remove useless error return.  Fixed  Fix the index recognized as prefix index when the column length is enlarged. Check the MaxInt64 and MinInt64 to avoid range error. Fix the estimation in betweenRowCount. Refine sql_mode no_backslash_escapes. Add deep copies for the update operation. Refine projection elimination when projection is the inner child of an outer join.</description>
    </item>
    
    <item>
      <title>使用 Rust 构建分布式 Key-Value Store</title>
      <link>https://pingcap.com/blog-cn/rust-key-value-store/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/rust-key-value-store/</guid>
      <description>引子 构建一个分布式 Key-Value Store 并不是一件容易的事情，我们需要考虑很多的问题，首先就是我们的系统到底需要提供什么样的功能，譬如：
 一致性：我们是否需要保证整个系统的线性一致性，还是能容忍短时间的数据不一致，只支持最终一致性。
 稳定性：我们能否保证系统 7 x 24 小时稳定运行。系统的可用性是 4 个 9，还有 5 个 9？如果出现了机器损坏等灾难情况，系统能否做的自动恢复。
 扩展性：当数据持续增多，能否通过添加机器就自动做到数据再次平衡，并且不影响外部服务。
 分布式事务：是否需要提供分布式事务支持，事务隔离等级需要支持到什么程度。
  上面的问题在系统设计之初，就需要考虑好，作为整个系统的设计目标。为了实现这些特性，我们就需要考虑到底采用哪一种实现方案，取舍各个方面的利弊等。
后面，我将以我们开发的分布式 Key-Value TiKV 作为实际例子，来说明下我们是如何取舍并实现的。
TiKV TiKV 是一个分布式 Key-Value store，它使用 Rust 开发，采用 Raft 一致性协议保证数据的强一致性，以及稳定性，同时通过 Raft 的 Configuration Change 机制实现了系统的可扩展性。
TiKV 提供了基本的 KV API 支持，也就是通常的 Get，Set，Delete，Scan 这样的 API。TiKV 也提供了支持 ACID 事务的 Transaction API，我们可以使用 Begin 开启一个事务，在事务里面对 Key 进行操作，最后再用 Commit 提交一个事务，TiKV 支持 SI 以及 SSI 事务隔离级别，用来满足用户的不同业务场景。
Rust 在规划好 TiKV 的特性之后，我们就要开始进行 TiKV 的开发。这时候，我们面临的第一个问题就是采用什么样的语言进行开发。当时，摆在我们眼前的有几个选择：</description>
    </item>
    
    <item>
      <title>TiDB 1.0.2 Release Notes</title>
      <link>https://pingcap.com/blog/2017-11-13-102/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-11-13-102/</guid>
      <description>TiDB:
 Optimize the cost estimation of index point query Support the Alter Table Add Column (ColumnDef ColumnPosition) syntax Optimize the queries whose where conditions are contradictory Optimize the Add Index operation to rectify the progress and reduce repetitive operations Optimize the Index Look Join operator to accelerate the query speed for small data size Fix the issue with prefix index judgment  Placement Driver (PD):
 Improve the stability of scheduling under exceptional situations  TiKV:</description>
    </item>
    
    <item>
      <title>Weekly update (November 06 ~ November 12, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB 2017-11-13
Last week, we landed 45 PRs in the TiDB repositories.
Added  Support more SQL modes in TiDB:  the NO_UNSIGNED_SUB sql_mode the REAL_AS_FLOAT sql_mode the PIPES_AS_CONCAT sql_mode the high_not_precedence sql_mode the ONLY_FULL_GROUP_BY sql_mode  Parse more privilege types like RELOAD, EVENT and so on. Support part of window function AST.  Removed  Remove joinBuilder. Remove resolver.go.  Fixed  Return error instead of panic if a subquery in JOIN ON condition.</description>
    </item>
    
    <item>
      <title>Weekly update (October 30 ~ November 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-11-06-tidb-weekly/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-11-06-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 51 PRs in the TiDB repositories.
Added  Provide the command option and log the success/fail information for slow-query.  Removed  Remove the old planner. Remove xeval. Remove the localstore storage engine.  Fixed  Change the selection plan to dual plan directly if the condition is always false. Insert column char(4) with latin1 charset by incorrect padding. Remove the check of initialized auto ID.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.1 Release Notes</title>
      <link>https://pingcap.com/blog/2017-11-01-101/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-11-01-101/</guid>
      <description> TiDB:
 Support canceling DDL Job. Optimize the IN expression. Correct the result type of the Show statement. Support log slow query into a separate log file. Fix bugs.  TiKV:
 Support flow control with write bytes. Reduce Raft allocation. Increase coprocessor stack size to 10MB. Remove the useless log from the coprocessor.   </description>
    </item>
    
    <item>
      <title>Weekly update (October 23 ~ October 29, 2017)</title>
      <link>https://pingcap.com/weekly/2017-10-30-tidb-weekly/</link>
      <pubDate>Mon, 30 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-10-30-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 52 PRs in the TiDB repositories.
Added  Support the window function syntax.  Fixed  Fix an issue when the values builtin function meets the null value. Support the signed field option for the numeric type. Fix an issue of index reader. Fix an issue that the binlog client is not initialized correctly. Correct the schema type of ShowStmt. The default value length for Join should be changed for column pruning.</description>
    </item>
    
    <item>
      <title>Weekly update (October 9 ~ October 22, 2017)</title>
      <link>https://pingcap.com/weekly/2017-10-23-tidb-weekly/</link>
      <pubDate>Mon, 23 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-10-23-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 83 PRs in the TiDB repositories.
Added  Support writing slow query log into separate files. Dummy implementation for the SHOW PROFILES statement. Add metrics for automatic analyzing. Support the operation of cancel DDL jobs. Add a new http status API to get meta regions.  Removed  Remove the self field in baseBuiltinFunc completely. Remove foldable from baseBuiltinFunc.  Fixed  Fix a bug occurred in select sum(float col)*0.</description>
    </item>
    
    <item>
      <title>PingCAP Launches TiDB 1.0</title>
      <link>https://pingcap.com/blog/2017-10-17-announcement/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-10-17-announcement/</guid>
      <description>PingCAP Launches TiDB 1.0, A Scalable Hybrid Database Solution October 16, 2017 - PingCAP Inc., a cutting-edge distributed database technology company, officially announces the release of TiDB 1.0. TiDB is an open source distributed Hybrid Transactional/Analytical Processing (HTAP) database that empowers businesses to meet both workloads with a single database.
In the current database landscape, infrastructure engineers often have to use one database for online transactional processing (OLTP) and another for online analytical processing (OLAP).</description>
    </item>
    
    <item>
      <title>写在 TiDB 1.0 发布之际 | 预测未来最好的方式就是创造未来</title>
      <link>https://pingcap.com/blog-cn/ga-liuqi/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/ga-liuqi/</guid>
      <description>如果只能用一个词来描述此刻的心情，我想说恍如隔世，这样说多少显得有几分矫情，或许内心还是想在能矫情的时候再矫情一次，毕竟当初做这一切的起因是为了梦想。还记得有人说预测未来最好的方式就是创造未来，以前看到这句话总觉得是废话，如今看到这一切在自己身上变成现实的一刻，感受是如此的真切，敲击键盘的手居然有点颤抖，是的，预测未来最好的方式就是创造未来。
还记得刚开始做的时候，只有很少的几个人相信这个事情可以做，毕竟难度比较高，就像有些户外旅行，只有方向，没有路。从零开始到发布 1.0 版本，历时 2 年 6 个月，终于还是做出来了。这是开源精神的胜利，是真正属于工程师们的荣耀。这个过程我们一直和用户保持沟通和密切协作，从最早纯粹的为 OLTP 场景的设计，到后来迭代为 HTAP 的设计，一共经历了 7 次重构，许多看得见的汗水，看不见的心跳，也许这就是相信相信的力量，总有那么一群人顶着世俗的压力，用自己的信念和力量在改变世界。在这个过程中，质疑的声音变少了，越来越多的人从观望，到为我们鼓舞助威，帮助我们快速成长。特别感谢那些从 beta 版本开始一路相随的用户，没有你们的信任，耐心和参与，就没有今天的 PingCAP。
开心的时刻总是特别想对很多帮助和支持我们的童鞋们说声谢谢，没有你们就没有 PingCAP，特别感谢每一位项目的贡献者。也许你已经知道了，我们专门为你们定制了一面荣誉墙，那里的色彩记录了你们的每一次贡献，如果你仍在埋头工作，来不及知道，我想请你过去逛逛，不负好时光。
这个世界还是有人相信未来是可以被创造的。感谢开源精神，让我们这样一个信仰创造未来的团队，可以站在未来的入口，因为相信和努力，获得源源不绝的正向的力量。面对未来，让我们可以摒弃对未知的恐惧和对不完美的妥协。
也感谢那些曾经的诋毁和吐槽，让我们不敢懈怠，砥砺前行。
然而 1.0 版本只是个开始，是新的起点，愿我们一路相扶，不负远途。</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/blog/2017-10-16-ga/</link>
      <pubDate>Mon, 16 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-10-16-ga/</guid>
      <description>On October 16, 2017, TiDB 1.0 is now released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Analyze pushdown Function signature pushdown  Optimize the internal data format to reduce the interim data size Enhance the MySQL compatibility Support the NO_SQL_CACHE syntax and limit the cache usage in the storage engine Refactor the Hash Aggregator operator to reduce the memory usage Support the Stream Aggregator operator  PD:  Support read flow based balancing Support setting the Store weight and weight based balancing  TiKV:  Coprocessor now supports more pushdown functions Support pushing down the sampling operation Support manually triggering data compact to collect space quickly Improve the performance and stability Add a Debug API for debugging TiSpark Beta Release: Support configuration framework Support ThriftSever/JDBC and Spark SQL  Acknowledgement Special thanks to the following enterprises and teams!</description>
    </item>
    
    <item>
      <title>Scale the Relational Database with NewSQL</title>
      <link>https://pingcap.com/blog/2017-10-10-nextcon/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-10-10-nextcon/</guid>
      <description>This is the speech Li SHEN gave at the 3rd NEXTCON: Cloud+Data NEXT Conference Seattle on September 16th, 2017.
 Speaker introduction Why we build a new relational database TiDB Project - Goal Architecture The core components of TiDB  The Storage stack Dynamic Multi-Raft Safe Split ACID Transaction Something we haven&amp;rsquo;t mentioned Placement Driver The SQL Layer What Happens behind a query SQL Layer Overview Cost-Based Optimizer  Tools matter Spark on TiKV Future plans  Speaker introduction Hello everyone, I am glad to be here in this beautiful city and share this talk with you.</description>
    </item>
    
    <item>
      <title>Weekly update (September 25 ~ October 08, 2017)</title>
      <link>https://pingcap.com/weekly/2017-10-09-tidb-weekly/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-10-09-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 62 PRs in the TiDB repositories.
Added  Support the SyncLog Key-Value request option. Support the NotFillCache Key-Value request option. Support the combination SQL modes.  Removed  Close the aggregation pushdown by default and remove the CBO switch. Remove some useless code. Remove the usage of TypeClass completely.  Fixed  Change the like function to be case sensitive. Prepare to enforce errcheck, step 1.</description>
    </item>
    
    <item>
      <title>Why did we choose Rust over Golang or C/C&#43;&#43; to develop TiKV?</title>
      <link>https://pingcap.com/blog/2017-09-26-whyrust/</link>
      <pubDate>Tue, 26 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-26-whyrust/</guid>
      <description>What is Rust Rust is a systems programming language sponsored by Mozilla Research. It moves fast and steady with a 6-week release cycle ever since its 1.0 version in May 2015.
See the following list for some of the features that most attract us:
 The design principles of Rust resemble with C++ in Abstraction without overhead and RAII (Resource acquisition is initialization).
 The minimum runtime and efficient C bindings empower Rust to be as efficient as C and C++, thus making it very suitable for the systems programming field where high performance matters the most.</description>
    </item>
    
    <item>
      <title>Weekly update (September 18 ~ September 24, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-25-tidb-weekly/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-25-tidb-weekly/</guid>
      <description>Weekly update in TiDB 2017-09-25
Last week, we landed 63 PRs in the TiDB repositories.
Added  Use new expression framework by default. Support the DOT explain format. Support the syntax for EXPLAIN FORMAT = stringlit Support the TIME/TIMESTAMP literal  Removed  Remove expression/typeinfer.go entirely. Abandon the selection controller.  Fixed  Roll back the ID allocator when a transaction fails to commit. Fix the returned column length of all the SHOW statements.</description>
    </item>
    
    <item>
      <title>谈谈开源(一)</title>
      <link>https://pingcap.com/blog-cn/talk-about-opensource/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-about-opensource/</guid>
      <description>源码面前，了无秘密 &amp;mdash;- 侯捷
 前言 很多人的『开源』是一个比较时髦且有情怀的词汇，不少公司也把开源当做 KPI 或者是技术宣传的手段。但是在我们看来，大多数人开源做的并不好，大多数开源项目也没有被很好的维护。比如前一段时间微博上流传关于 Tengine 的讨论，一个优秀的开源项目不止是公布源代码就 OK 了，还需要后续大量的精力去维护，包括制定 RoadMap、开发新功能、和社区交流、推动项目在社区中的使用、对使用者提供一定程度的支持，等等。
目前我们在国内没看到什么特别好的文章讲如何运营一个开源项目，或者是如何做一个顶级的开源项目。TiDB 这个项目从创建到现在已经有两年多，从开发之初我们就坚定地走开源路线，陆续开源了 TiDB、TiKV、PD 这三个核心组件，获得了广泛的关注，项目在 GitHub 的 Trending 上面也多次登上首页。在这两年中，我们在这方面积累了一些经验和教训，这里和大家交流一下我们做开源过程中的一些感受，以及参与开源项目（至少是指 TiDB 相关项目）的正确姿势。
什么是开源  Open-source software (OSS) is computer software with its source code made available with a license in which the copyright holder provides the rights to study, change, and distribute the software to anyone and for any purpose.
&amp;mdash;- From Wikipedia
 本文讨论的开源是指开源软件，简而言之，开源就是拥有源代码版权的人，允许其他人在一定许可证所述范围内，访问源代码，并用于一些自己的目的。 最基本的要求就是其他人可以访问源代码，另外获取代码后能做什么，就需要一个专门的许可证来规范（可以是自己写的，也可以用一个别人写好的）。里面一般会规定诸如对修改代码、新增代码、后续工作是否需要开源以及专利相关的事项。 OK，我们写一个 main.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.56】MonetDB/X100 Paper 解读（内附视频）</title>
      <link>https://pingcap.com/meetup/meetup-2017-09-20/</link>
      <pubDate>Wed, 20 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-09-20/</guid>
      <description>上周六，PingCAP Infra Meetup 第 56 期特设论文专场，我司核心工程师张建与大家一起分享并解读了“MonetDB/X100: Hyper-Pipelining Query Execution” 论文。此篇论文作为分析型数据库领域内引用次数最多的论文之一，它为何如此火爆？在今天的文章里你应该可以找到答案。
 精彩视频 精彩现场 在 PingCAP Infra Meetup 第 56 期论文专场，来了很多对 MonetDB/X100 论文感兴趣的小伙伴们。分享一开始，我司联合创始人兼 CEO 刘奇就为何选择 MonetDB/X100 这篇论文分享了自己看法。
刘奇提到:&amp;ldquo;如果大家有阅读近两年新出的一些 Paper，会发现里面引用率最高的一篇文章就是 MonetDB/X100。MonetDB/X100 发表于 2005 年，其实不算新。但读过该论文的人会发现目前主流的 OLAP 系统相关的技术，基本上都能在这篇论文中找到影子，如文中提到了列存、Pipeline，甚至是 JIT。他做 JIT 的思路不一样，都是比较早就有的，所以这是一篇很不错的论文。现在也可以看到很多性能比较的时候，大家新做了一个系统，说我的性能非常好，会拿出来 benchmark 说你看我打败了 MonetDB。
另外还有一些比较创新的项目，多是基于 MonetDB 改造的。一个就是英特尔最近出的一篇论文，他把 MonetDB 改造一下，把正则表达式的搜索，放到 FPGA 里面去。英特尔最近出了一款服务器，这个服务器的 CPU 和 FPGA 是放在一起的，他们得到 Performance 最小提倡是 2.3 倍以上，大概意思上就是说，MonetDB 在这上面做一个简单的改造，就可以适应到更新的硬件。
在 2012年的时候，第一个提供论文、代码的基于 MonetDB 的 GPU 的 Database 也出来了。当时是在 TPCH 的 query 里面，有一些复杂的 query，提升是非常的明显。所以大家可以看到，基于 MonetDB 改造的，在 FPGA 或者 GPU上运行的系统都有，实际上这是一个非常优秀的学术的原形，今年得了十年最佳论文奖。&amp;rdquo;</description>
    </item>
    
    <item>
      <title>Weekly update (September 11 ~ September 17, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-18-tidb-weekly/</link>
      <pubDate>Mon, 18 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-18-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 46 PRs in the TiDB repositories.
Added  Add required tables of MySQLX . Add TOML configuration file support.  Removed  Remove the performance schema instrumentation.  Fixed  Fix show create table with foreign key. Cast values only for modified columns in the update statement to avoid unnecessary check. Fix an OOM issue when analyzing table. Fix a cast (date as datetime) error.</description>
    </item>
    
    <item>
      <title>RocksDB in TiKV</title>
      <link>https://pingcap.com/blog/2017-09-15-rocksdbintikv/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-15-rocksdbintikv/</guid>
      <description>This is the speech Siddon Tang gave at the RocksDB meetup on August 28, 2017.
 Speaker Introduction Agenda Why did we choose RocksDB? How are we using RocksDB?  TiKV Architecture Region Raft InsertWithHint Prefix Iterator Table Property for Region Split Check Table Property for GC Check Ingest the SST File Others  How are we contributing? Future Plans  Speaker Introduction Hi every one, thanks for having me here, the RocksDB team.</description>
    </item>
    
    <item>
      <title>Futures and gRPC in Rust</title>
      <link>https://pingcap.com/blog/2017-09-12-futuresandgrpc/</link>
      <pubDate>Tue, 12 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-12-futuresandgrpc/</guid>
      <description>This is the speech Tang Liu (tl@pingcap.com) gave at the Bay Area Rust Meetup August 2017. See the video.
 Speaker Introduction Async Programming  Why not Sync? Why Async?  Callback Hell Coroutine Makes it Easy Future, Another Way   Futures in Rust  Futures Combinator Synchronization Stream Sink Task  gRPC  Why gRPC? HTTP/2 gRPC based on HTTP/2  Combine Futures and gRPC  C gRPC Keywords Pseudo Flow Unary Client Streaming Server Streaming Duplex Streaming  Unary Future Implementation  Client Unary Unary Future Resolve Future  Benchmark Misc  Speaker Introduction Hi everyone!</description>
    </item>
    
    <item>
      <title>Weekly update (September 04 ~ September 10, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-11-tidb-weekly/</link>
      <pubDate>Mon, 11 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-11-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 49 PRs in the TiDB repositories.
Added  Add the column size limit when creating table. Add the syntax for admin show ddl jobs. SSL/TLS support.  Fixed  Fix an ORDER BY bug. Add entry limit for transactions when doing DDL job. Fix a bug during the limit operator pushdown. Check the default value of the column option in the CREATE TABLE statement.</description>
    </item>
    
    <item>
      <title>How we Hunted a Data Corruption bug in RocksDB</title>
      <link>https://pingcap.com/blog/2017-09-08-rocksdbbug/</link>
      <pubDate>Fri, 08 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-08-rocksdbbug/</guid>
      <description>Data was corrupted. A cluster panicked. The crime scene was compromised. What happened? Detective Huang (huachao@pingcap.com) went all lengths to locate the criminal and solved it once and for all.
Background As a distributed open source HTAP database, TiDB uses TiKV as its storage engine. Inside TiKV, we use RocksDB as the local storage. RocksDB is a great project. It&amp;rsquo;s mature, fast, tunable, and widely used in very large scale production environments.</description>
    </item>
    
    <item>
      <title>【Infra Meetup NO.55】TiDB Pre-GA 版本新特性介绍以及后续功能展望（内附视频）</title>
      <link>https://pingcap.com/meetup/meetup-2017-09-06/</link>
      <pubDate>Wed, 06 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-09-06/</guid>
      <description>上周六，PingCAP Infra Meetup 第 55 期，由我司 Engineering VP 申砾为大家分享《 TiDB Pre-GA 版本新特性介绍以及后续功能展望》。在活动现场，小伙伴们就 TiDB 新特性提出了很多问题，申砾在现场与大家有一番深度的交流与讨论。精彩现场小编立马为你呈现。
 精彩视频 精彩现场 上周，TiDB 正式发布了 Pre-GA 版本。针对 Pre-GA 版本的新特性，PingCAP Infra Meetup 第 55 期特设定 Pre-GA 详解专场。活动当天，现场来了很多关注 TiDB 的粉丝们。
简单开场后，我司 Engineering VP 申砾同学介绍到本期内容主要围绕新版本带来的变化和内部实现细节，以及这种新型的 HTAP 数据库解决的实际问题和典型应用场景等做深度解析。
技术干货节选 TiDB Pre-GA 版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能方面做了大量优化工作。本次分享中，申砾就各个组件的优化做了详解：
TiDB ：
在优化器方面
 RC4 已经从一个假的基于代价产品模型，切换成一个真的基于代价产品模型，也真的是用统计信息去算。在 RC3 版本中，一些代价实际上是有规则算法的，比如说，A 等于 10 设置一个过滤比例，A 大于 10 又算另外一个过滤比例，这都是一些规则，RC4 是基于代价的一个传统模型。 Pre-GA 新特性也主要对代价模型做了一些调整。
 其次，在索引选择上做了优化，可以支持不同类型字段比较的索引选择，这一优化用户反馈查询速度明显变快。
 再者，支持 Join Reorder，对于 OLTP 层面来说，Join Reorder 不太会用到，但对于一些比较复杂的场景，比如说有的用户使用参报表。这个时候有可能会出现 Join 报表，特别是在 TCH 里面，多表 Join 比较常见。下一步计划也将统计信息导入 TiSpark 里，指导 TiSpark 做 Join Reorder 。</description>
    </item>
    
    <item>
      <title>Weekly update (August 28 ~ September 03, 2017)</title>
      <link>https://pingcap.com/weekly/2017-09-04-tidb-weekly/</link>
      <pubDate>Mon, 04 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-09-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 42 PRs in the TiDB repositories.
Added  Add JSON into builtin if function.  Fixed  Fix bugs when doing natural JOIN or JOIN with using clause. Check whether date is zero and returns error when casting int as the time type. Support date time format when parse duration. Fix the issue that SHOW CREATE TABLE COMMENT is not escaped and the issue that FieldType.</description>
    </item>
    
    <item>
      <title>When TiDB Meets Jepsen</title>
      <link>https://pingcap.com/blog/2017-09-01-tidbmeetsjepsen/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-09-01-tidbmeetsjepsen/</guid>
      <description>What is Jepsen? How does Jepsen work?  DB Client Checker Nemesis Generator  Jepsen tests that TiDB goes through  The Bank Test The Set Test The Register Test  Miscellaneous  What is Jepsen? Written by Kyle Kingsbury in Clojure. Jepsen is a test framework for distributed systems verification. Kingsbury has used it to verify the consistency of many famous distributed systems (etcd, ZooKeeper, CockroachDB, etc.) and found multiple bugs in some of these systems.</description>
    </item>
    
    <item>
      <title>When TiDB Meets Spark</title>
      <link>https://pingcap.com/blog-cn/tidb-meets-spark/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-meets-spark/</guid>
      <description>本文整理自 TiSpark 项目发起人马晓宇在 Strata Data Conference 上分享的《When TiDB Meets Spark》演讲实录。
 先介绍我自己，我是 PingCAP 的马晓宇，是 TiDB OLAP 方向的负责人，也是 TiSpark 项目的发起人，主要是做 OLAP 方面的 Feature 和 Product 相关的工作，之前是网易的 Big Data Infra Team Leader，先前的经验差不多都是在 SQL、Hadoop 和所谓大数据相关的一些东西。
今天主要会讲的议程大概这么几项。
首先稍微介绍一下 TiDB 和 TiKV，因为 TiSpark 这个项目是基于它们的，所以你需要知道一下 TiDB 和 TiKV 分别是什么，才能比较好理解我们做的是什么事情。
另外正题是 TiSpark 是什么，然后 TiSpark 的架构，除了 Raw Spark 之外，我们提供了一些什么样的不一样的东西，再然后是 Use Case，最后是项目现在的状态。
首先说什么是 TiDB。你可以认为 TiDB 是现在比较火的 Spanner 的一个开源实现。它具备在线水平扩展、分布式 ACID Transaction、HA、Auto failover 等特性，是一个 NewSQL 数据库。
然后什么是 TiKV，可能我们今天要说很多次了。TiKV 其实是 TiDB 这个产品底下的数据库存储引擎，更形象，更具体一点，这是一个架构图。</description>
    </item>
    
    <item>
      <title>TiDB Pre-GA Release Notes</title>
      <link>https://pingcap.com/blog/2017-08-30-prega/</link>
      <pubDate>Wed, 30 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-08-30-prega/</guid>
      <description>TiDB:
 The SQL query optimizer:  Adjust the cost model Use index scan to handle the where clause with the compare expression which has different types on each side Support the Greedy algorithm based Join Reorder  Many enhancements have been introduced to be more compatible with MySQL Support Natural Join Support the JSON type (Experimental), including the query, update and index of the JSON fields Prune the useless data to reduce the consumption of the executor memory Support configuring prioritization in the SQL statements and automatically set the prioritization for some of the statements according to the query type Completed the expression refactor and the speed is increased by about 30%  Placement Driver (PD):</description>
    </item>
    
    <item>
      <title>Weekly update (August 21 ~ August 27, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-28-tidb-weekly/</link>
      <pubDate>Mon, 28 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-28-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 55 PRs in the TiDB repositories.
Added  Support the &amp;lsquo;SHOW PLUGINS&amp;rsquo; syntax with dummy implementation. Add a system variable to split to-be-deleted data into batches autmatically. Add the date literal. Add the framework of the X protocol, and commond line arguments.  Fixed  Fix a panic when the set statement meets a subquery. Set charset and collation for the union&amp;rsquo;s result.</description>
    </item>
    
    <item>
      <title>【Infra Meetup NO.54】数据库计算存储分离架构分析（内附视频）</title>
      <link>https://pingcap.com/meetup/meetup-2017-08-25/</link>
      <pubDate>Fri, 25 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-08-25/</guid>
      <description>上周六，PingCAP Infra Meetup 第 54 期，我们邀请到了知乎大 V 李凯（知乎 ID：郁白）为大家分享了《数据库计算存储分离架构分析》。在活动现场，郁白老师跟小伙伴们有一番深度的交流与思想碰撞。长话短说，小编带你一起回顾精彩现场。
 精彩视频 精彩现场 PingCAP Infra Meetup 第 54 期的活动现场十分火爆，活动签到时间未开始，小伙伴们就早早来到现场占位置，我想说早来的小伙伴们还是很明智的。因为&amp;hellip;&amp;hellip;
后续到场的小伙伴只能酱婶儿滴扎堆在门口竖起耳朵听了，这场活动简直是一场郁白大神与粉丝的见面会。
说了这么多，先上一张郁白老师的图吧~ 🙂
技术干货节选 大数据下公有云面临的 5 个挑战
谈到存储架构分离，为什么现在会有 Aurora 架构？包括前一阵阿里的 PolarDB 推出来以后，他们也在分析为什么要做这个东西。
郁白老师认为单就公有云来说，现在云数据面临的挑战有以下 5 个：
 跨 AZ 的可用性与数据安全性。 现在都提多 AZ 部署，亚马逊在全球有 40 多个 AZ， 16 个 Region，基本上每一个 Region 之内的那些关键服务都是跨 3 个 AZ。你要考虑整个 AZ 意外宕机或者计划内维护要怎么处理，数据迁移恢复速度怎么样。以传统的 MySQL 为例，比如说一个机器坏了，可能这个机器上存了几十 T、上百 T 的数据，那么即使在万兆网卡的情况下，也要拷个几分钟或者几十分钟都有可能。那么有没有可能加快这个速度。 还有一个就是服务恢复的速度。可能大家广为诟病就是基于 MySQL Binlog 复制。在主机压力非常大的情况下，是有可能在切换到备机以后，这个备机恢复可能需要几分钟甚至几十分钟。关键因素是回放 Binlog 的效率，MySQL 即使最新版本也只能做到 Group Commit 内的并发回放。这是数据库 RTO 指标，能不能在秒级、分钟级把这个服务恢复起来，这是一个在设计系统的时候要考虑的关键问题。</description>
    </item>
    
    <item>
      <title>Linearizability 一致性验证</title>
      <link>https://pingcap.com/blog-cn/linearizability/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/linearizability/</guid>
      <description>上篇文章介绍了 TiDB 如何使用 Jepsen 来进行一致性验证，并且介绍了具体的测试案例，但是并没有对 Jepsen 背后的一致性验证算法做过多介绍。这篇文章将会深入 Jepsen 的核心库 knossos，介绍 knossos 库所涉及的 Linearizability（线性化）一致性验证算法。
Linearizability 一致性模型 什么是一致性模型？ 一致性模型确定了编写系统的程序员与系统之间的某种协议，如果程序员遵守了这种协议，那么这个系统就能提供某种一致性。常见的一致性模型有：
 Strict Consistency Linearizability (Atomic Consistency) Sequential Consistency Casual Consistency Serializability ……  需要注意的是这里的系统指并发系统，分布式系统只是其中的一类。
什么是 Linearizability？ 首先我们需要引入*历史*（history）的概念，*历史*是并发系统中由 invocation 事件和 response 事件组成的有限序列。
  invocation: &amp;lt;x op(args*) A&amp;gt;，x 表示被执行对象的名称；op 表示操作名称，如读和写；args* 表示一系列参数值；A 表示进程的名称
 response：&amp;lt;x term(res*) A&amp;gt;，term 表示结束（termination）状态；res* 表示一系列结果值
 如果 invocation 和 response 的 x（对象）和 A（进程）相同，那么我们认为它们是对应操作，并且 complete（H）表示历史中的最多成对操作
   当我们的历史 H 满足以下条件时我们把它称为*顺序化*（sequential）历史：</description>
    </item>
    
    <item>
      <title>Weekly update (August 14 ~ August 20, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-21-tidb-weekly/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-21-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 57 PRs in the TiDB repositories.
Added  Add the version information in diagnostic messages. Add the Close() method to RawKVClient. Add JSON in fieldTypeMergeRules. Add support to MySQL connector 6.06. Add Git branch name in tidb_version() and the starting log. Add the auto analyze feature for tables.  Fixed  DDL uses the correct method to check whether the context is done.</description>
    </item>
    
    <item>
      <title>The Design and Implementation of Multi-raft</title>
      <link>https://pingcap.com/blog/2017-08-15-multi-raft/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-08-15-multi-raft/</guid>
      <description>(Email: tl@pingcap.com)

 Placement Driver Raftstore  Region RocksDB / Keys Prefix Peer Storage Peer Multi-raft  Summary  Placement Driver Placement Driver (PD), the global central controller of TiKV, stores the metadata information of the entire TiKV cluster, generates Global IDs, and is responsible for the scheduling of TiKV and the global TSO time service.
PD is a critical central node. With the integration of etcd, it automatically supports the distributed scaling and failover as well as solves the problem of single point of failure.</description>
    </item>
    
    <item>
      <title>当 TiDB 遇上 Jepsen</title>
      <link>https://pingcap.com/blog-cn/tidb-jepsen/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-jepsen/</guid>
      <description>本篇文章主要介绍 TiDB 是如何使用分布式一致性验证框架 Jepsen 进行一致性验证的。
什么是 Jepsen Jepsen 是由 Kyle Kingsbury 采用函数式编程语言 Clojure 编写的验证分布式系统一致性的测试框架，作者使用它对许多著名的分布式系统（etcd, cockroachdb&amp;hellip;）进行了“攻击”（一致性验证），并且帮助其中的部分系统找到了 bug。这里一系列的博客展示了作者的验证过程以及对于一致性验证的许多思考。
Jepsen 如何工作 Jepsen 验证系统由 6 个节点组成，一个控制节点（control node），五个被控制节点（默认为 n1, n2, n3, n4, n5），控制节点将所有指令发送到某些或全部被控制节点，这些指令包括底层的 shell 命令到上层的 SQL 语句等等。Jepsen 提供了几个核心 API 用于验证分布式系统：
 DB
DB 封装了所验证的分布式系统下载、部署、启动和关闭命令，核心函数由 setup 和 teardown 组成，在 TiDB 的 Jepsen 测试中，setup 负责下载 TiDB 并且依次启动 Placement Driver、TiKV 和 TiDB；teardown 负责关闭整个 TiDB 系统并且删除日志。
 Client
Client 封装了每一个测试所需要提供的客户，每个 client 提供两个接口：setup 和 invoke，setup 负责对 TiDB 进行连接，而 invoke 则包含了测试中 client 对 TiDB 调用的 sql 语句，具体语句依测试而定。</description>
    </item>
    
    <item>
      <title>Weekly update (August 07 ~ August 13, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-14-tidb-weekly/</link>
      <pubDate>Mon, 14 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-14-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 78 PRs in the TiDB repositories.
Added  Enable pushing down the following operations to TiKV.  the JSON function ifnull minus and multiply  Use the Delete-in-Range feature to speed up the Drop Database/Table/Index operations. Support prioritizing statements.  Fixed  Fix the TimeDiff compatibility issue. Consider charset in Right/Left/Substr. Do not record metrics when running intenal SQL. Fix potential issue of schema validation check.</description>
    </item>
    
    <item>
      <title>How TiDB tackles fast data growth and complex queries for yuanfudao.com</title>
      <link>https://pingcap.com/blog/2017-08-08-tidbforyuanfudao/</link>
      <pubDate>Tue, 08 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-08-08-tidbforyuanfudao/</guid>
      <description>TiDB use case Yuanfudao.com is an online tutoring service targeting the K-12 educational segment in China with the largest number of elementary and secondary school student users. It owns three applications, Yuantiku (猿题库), the online question bank, Xiaoyuansouti (小猿搜题), the application for question search by taking pictures, and yuanfudao.com, an online tutoring service.
So far, the Yuanfudao APPs have more than 1.16 million paying users and provide live tutoring courses of English and Math Olympiad to the elementary users, as well as all the subjects for secondary school students.</description>
    </item>
    
    <item>
      <title>Weekly update (July 31 ~ August 06, 2017)</title>
      <link>https://pingcap.com/weekly/2017-08-07-tidb-weekly/</link>
      <pubDate>Mon, 07 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-08-07-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 54 PRs in the TiDB repositories.
Added  Support natural join. Add a switch for enabling cost-based optimizor. Assign low priority for SQL with full table scan and high priority for SQL with point get. Support \N which is the shotcut of null. Support TIMESTAMP in the get_format function. Add a flag to enable TCP keep-alive. Support DISTINCTROW.  Fixed  Truncate the trailing spaces for &amp;ldquo;CHAR[(M)]&amp;rdquo; types Fix float point parsing with leading dot.</description>
    </item>
    
    <item>
      <title>【Infra Meetup NO.53】知乎数据平台实践</title>
      <link>https://pingcap.com/meetup/meetup-2017-08-05/</link>
      <pubDate>Sat, 05 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-08-05/</guid>
      <description>今天的 Meetup，我们邀请到了知乎数据平台负责人王雨舟为大家做《知乎数据平台实践》的技术分享。
 又是一个美好的周末，勤劳的小蜜蜂们早早出来参加活动了~🙂 今天的活动现场又是爆满~ 感觉要换地儿的节奏啊~
今天 Meetup 的开场，我司联合创始人兼 CTO 黄东旭同学首先为大家分享了 TiDB 项目的最新进展。黄东旭同学好开心的样子，因为就在昨天，TiDB 正式发布 RC4 版 。
开场过后，接下来由知乎数据平台负责人王雨舟（江湖人称宇宙哥）开始为大家做技术分享。
宇宙哥真是 PingCAP 的真爱粉儿~ 穿着我司的文化衫亮相活动现场，超级有气场~
以下是部分技术干货分享，Enjoy~
宇宙哥在演讲开始先介绍了知乎大数据平台的整体架构情况
并讲解了埋点流程及使用 Protobuf 做埋点标准化规范
除此之外，宇宙哥还从以下几点来分析介绍 Druid
在知乎的实践：
 自定义多维分析功能和留存分析功能；
 如何做到实时数据分析；
 自定义指标、维度、报表、文件夹、Dashboard。
  我是花边分割线
这张 PPT 中有眼熟的部分哦😏宇宙哥用“丝般顺滑”总结了自己现在使用 TiDB 的感受，并表达了对 TiSpark 的期待✌️分享结束后，显然大家都还没有尽兴，接下来是一段时长堪比分享环节的 QA。激烈的讨论后现场小伙伴跟宇宙哥都嗨了，还没有嗨够的小伙伴我们下次见~</description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/blog/2017-08-04-rc4/</link>
      <pubDate>Fri, 04 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-08-04-rc4/</guid>
      <description>Highlight:  For performance, the write performance is improved significantly, and the computing task scheduling supports prioritizing to avoid the impact of OLAP on OLTP.
 The optimizer is revised for a more accurate query cost estimating and for an automatic choice of the Join physical operator based on the cost.
 Many enhancements have been introduced to be more compatible with MySQL.
 TiSpark is now released to better support the OLAP business scenarios.</description>
    </item>
    
    <item>
      <title>Weekly update (July 24 ~ July 30, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-31-tidb-weekly/</link>
      <pubDate>Mon, 31 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-31-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 50 PRs in the TiDB repositories.
Added  Add a debugging tool for transaction inspection. Support two JSON syntactic sugars. Support renaming multiple tables in a single statement.  Fixed  Fix a bug in the update statement when doing the alter table after statement. Fix signed integer overflow in the minus unary scalar function. Fix the content in the information_schema for unsigned columns.</description>
    </item>
    
    <item>
      <title>A TiKV Source Code Walkthrough - Raft in TiKV</title>
      <link>https://pingcap.com/blog/2017-07-28-raftintikv/</link>
      <pubDate>Fri, 28 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-28-raftintikv/</guid>
      <description>(Email: tl@pingcap.com)

Table of content  Architecture Raft  Storage Config RawNode   Architecture Below is TiKV’s overall architecture:
Placement Driver: Placement Driver (PD) is responsible for the management scheduling of the whole cluster.
Node: Node can be regarded as an actual physical machine and each Node is responsible for one or more Store.
Store: Store uses RocksDB to implement actual data storage and usually one Store corresponds to one disk.</description>
    </item>
    
    <item>
      <title>TiSpark (Beta) 用户指南</title>
      <link>https://pingcap.com/blog-cn/tispark/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tispark/</guid>
      <description>TiSpark 是 PingCAP 推出的为了解决用户复杂 OLAP 需求的产品。借助 Spark 平台本身的优势，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP （Hybrid Transactional/Analytical Processing）需求。 TiSpark 依赖 TiKV 集群和 PD 的存在。当然，TiSpark 也需要你搭建一个 Spark 集群。本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 相关信息。
一、概述 TiSpark 是将 Spark SQL 直接运行在 TiDB 存储引擎 TiKV 上的 OLAP 解决方案。TiSpark 架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查；
 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。
 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。</description>
    </item>
    
    <item>
      <title>TiDB Best Practices</title>
      <link>https://pingcap.com/blog/2017-07-24-tidbbestpractice/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-24-tidbbestpractice/</guid>
      <description>From Li SHEN: shenli@pingcap.com
See the following blogs (Data Storage, Computing, Scheduling) for TiDB&amp;rsquo;s principles.
Table of Content  Preface Basic Concepts  Raft Distributed Transactions Data Sharding Load Balancing SQL on KV Secondary Indexes  Scenarios and Practices  Deployment Importing Data Write Query Monitoring and Log Documentation Best Scenarios for TiDB   Preface Database is a generic infrastructure system. It is important to, for one thing, consider various user scenarios during the development process, and for the other, modify the data parameters or the way to use according to actual situations in specific business scenarios.</description>
    </item>
    
    <item>
      <title>Weekly update (July 17 ~ July 23, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-24-tidb-weekly/</link>
      <pubDate>Mon, 24 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-24-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 60 PRs in the TiDB repositories.
Added  Add a tidb_version function to get the tidb-server version information. Support the READ COMMITTED isolation level. Support the ENCLOSED BY clause in the Load Data statement. Support creating index using type and comment.  Fixed  Fix a bug when in json_unquote. Fix field name with comment. Fix the wrong offset when using the Primary Key column as the handle.</description>
    </item>
    
    <item>
      <title>【Infra Meetup NO.52】TiDB 自动化运维管理 —— TiDB-Operator</title>
      <link>https://pingcap.com/meetup/meetup-2017-07-22/</link>
      <pubDate>Sat, 22 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-07-22/</guid>
      <description>今天的 Meetup，由我司技术大拿邓栓同学为大家分享《TiDB 自动化运维管理 —— TiDB-Operator》。
 今日的帝都带着一丝凉爽，如此好天气怎能辜负。小伙伴们一清早就来到互动现场，一起来吃“营养早午餐”。
我司技术大拿邓栓同学激情满满的开始为大家做主题分享，主要从 TiDB-Operator 的功能介绍、整体架构、实现细节这几个纬度切入。
邓栓同学开场介绍到：分布式系统由于自身的复杂性，其管理和运维通常是非常困难的事情，借助 TiDB-Operator 我们能够轻松地将 TiDB 集群部署到 Kubernetes 集群之上，并做到自动化运维管理，极大地降低了人力运维成本，现场小伙伴们听呆了～
咦？what&amp;rsquo;wrong ? 黑灯瞎火嘛呢？ 其实是小伙伴们在一起很专注的看 demo 演示~
活动最后，邓栓同学通过 demo 演示了 TiDB-operator bootstrap 一套完整的 TiDB 集群，然后在集群上面执行一个简单的操作就可以轻松实现扩容缩容，并且模拟物理节点挂掉时 TiDB-operator 对集群做自动恢复等各种自动化运维操作流程。
以上为最新前方报道～ enjoy 😁
邓栓，PingCAP SRE 工程师，Kubernetes 爱好者，目前主要负责 TiDB 与各种云平台整合。Rust 中国社区联合创始人。</description>
    </item>
    
    <item>
      <title>TiDB Internal (III) - Scheduling</title>
      <link>https://pingcap.com/blog/2017-07-20-tidbinternal3/</link>
      <pubDate>Thu, 20 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-20-tidbinternal3/</guid>
      <description>From Li SHEN: shenli@pingcap.com
Table of Content  Why scheduling The Requirements of Scheduling The Basic Operations of Scheduling Information Collecting The Policy of Scheduling The implementation of Scheduling Summary  Why scheduling? From the first blog of TiDB internal, we know that TiKV cluster is the distributed KV storage engine of TiDB database. Data is replicated and managed in Regions and each Region has multiple Replicas distributed on different TiKV nodes.</description>
    </item>
    
    <item>
      <title>PAX：一个 Cache 友好高效的行列混存方案</title>
      <link>https://pingcap.com/blog-cn/pax/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pax/</guid>
      <description>今年，Spanner 终于发了另一篇 Paper 「Spanner: Becoming a SQL System」，里面提到 Spanner 使用了一种新的存储格式 - Ressi，用来支持 OLTP 和 OLAP。在 Ressi 里面，使用了 PAX 来组织数据。因为 TiDB 定位就是一个 HTAP 系统，所以我也一直在思考在 TiKV 这层如何更好的存储数据，用来满足 HTAP 的需要，既然 Spanner 使用了 PAX，那么就有研究的必要了。
PAX 的论文可以看看 「Weaving Relations for Cache Performance」 或者 「Data Page Layouts for Relational Databases on Deep Memory Hierarchies」。
NSM and DSM 在谈 PAX 之前，NSM 和 DSM 还是绕不开的话题，NSM 就是通常说的行存，对于现阶段很多偏重 OLTP 的数据，譬如 MySQL 等，都采用的这种方式存储的数据。而 DSM，则是通常的说的列存，几乎所有的 OLAP 系统，都采用的这种方式来存储的底层数据。
NSM 会将 record 依次在磁盘 page 里面存放，每个 page 的末尾会存放 record 的 offset，便于快速的定位到实际的 record。如果我们每次需要得到一行 record，或者 scan 所有 records，这种格式非常的高效。但如果我们的查询，仅仅是要拿到 record 里面的一列数据，譬如 select name from R where age &amp;lt; 40，那么对于每次 age 的遍历，除了会将无用的其他数据一起读入，每次读取 record，都可能会引起 cache miss。</description>
    </item>
    
    <item>
      <title>gRPC-rs：从 C 到 Rust</title>
      <link>https://pingcap.com/blog-cn/grpc-rs/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc-rs/</guid>
      <description>介绍 在上篇文章中，我们讲到 TiKV 为了支持 gRPC，我们造了个轮子 gRPC-rs，这篇文章简要地介绍一下这个库。首先我们来聊聊什么是 gRPC。gRPC 是 Google 推出的基于 HTTP2 的开源 RPC 框架，希望通过它使得各种微服务之间拥有统一的 RPC 基础设施。它不仅支持常规的平台如 Linux，Windows，还支持移动设备和 IoT，现有十几种语言的实现，现在又多了一种语言 Rust。
gRPC 之所以有如此多的语言支持，是因为它有一个 C 写的核心库(gRPC core)，因此只要某个语言兼容 C ABI，那么就可以通过封装，写一个该语言的 gRPC 库。Rust 对 C 有良好的支持，gRPC-rs 就是对 gRPC core ABI 的 Rust 封装。
Core 能异步处理 RPC 请求，在考虑到 Rust 中已有较为成熟的异步框架 Futures，我们决定将 API 设计成 Future 模式。
gRPC-rs 架构图
我们将根据架构图从底向上地讲一下，在上一篇文章中已经讨论过传输层和协议，在这就不再赘述。
gRPC Core Core 中有几个比较重要的对象：
 Call 以及 4 种类型 RPC： Call 代表了一次 RPC，可以派生出四种类型 RPC，
 Unary： 这是最简单的一种 RPC 模式，即一问一答，客户端发送一个请求，服务端返回一个回复，该轮 RPC 结束。 Client streaming： 这类的 RPC 会创建一个客户端到服务端的流，客户端可以通过这个流，向服务端发送多个请求，而服务端只会返回一个回复。 Server streaming： 与上面的类似，不过它会创建一个服务端到客户端的流，服务端可以发送多个回复， Bidirectional streaming： 如果说上面两类是单工，那么这类就是双工了，客户端和服务端可以同时向对方发送消息。   值得一提的是由于 gRPC 基于 HTTP2，它利用了 HTTP2 多路复用特性，使得一个 TCP 连接上可以同时进行多个 RPC，一次 RPC 即为 HTTP2 中的一个 Stream。</description>
    </item>
    
    <item>
      <title>Weekly update (July 10 ~ July 16, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-17-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 51 PRs in the TiDB repositories.
Added  Support setting variables with ON and OFF. Support show stats_histgrams and show stats_buckets for debugging. Support the Scan API for the raw KV interface. Support the Show Charset statement. Support user name without quotes such as root@127.0.0.1.  Fixed  Fix a bug when explicitly inserting the null value into columns with the timestamp type.</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 重构内建函数进度报告</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</guid>
      <description>6 月 22 日，TiDB 发布了一篇如何十分钟成为 TiDB Contributor 系列的第二篇文章，向大家介绍如何为 TiDB 重构 built-in 函数。
截止到目前，得到了来自社区的积极支持与热情反馈，TiDB 参考社区 contributors 的建议，对计算框架进行了部分修改以降低社区同学参与的难度。
本文完成以下2 项工作，希望帮助社区更好的参与进 TiDB 的项目中来:
 对尚未重写的 built-in 函数进行陈列 对继上篇文章后，计算框架所进行的修改，进行详细介绍  一. 尚未重写的 built-in 函数陈列如下： 共计 165 个 在 expression 目录下运行 grep -rn &amp;quot;^\tbaseBuiltinFunc$&amp;quot; -B 1 * | grep &amp;quot;Sig struct {&amp;quot; | awk -F &amp;quot;Sig&amp;quot; &#39;{print $1}&#39; | awk -F &amp;quot;builtin&amp;quot; &#39;{print $3}&#39; &amp;gt; ~/Desktop/func.txt 命令可以获得所有未实现的 built-in 函数
   0 1 2 3 4     Coalesce Uncompress Log10 Default UnaryOp   Greatest UncompressedLength Rand InetAton IsNull   Least ValidatePasswordStrength Pow InetNtoa In   Interval Database Round Inet6Aton Row   CaseWhen FoundRows Conv Inet6Ntoa SetVar   If CurrentUser CRC32 IsFreeLock GetVar   IfNull User Sqrt IsIPv4 Values   NullIf ConnectionID Arithmetic IsIPv4Prefixed BitCount   AesDecrypt LastInsertID Acos IsIPv6 Reverse   AesEncrypt Version Asin IsUsedLock Convert   Compress Benchmark Atan MasterPosWait Substring   Decode Charset Cot NameConst SubstringIndex   DesDecrypt Coercibility Exp ReleaseAllLocks Locate   DesEncrypt Collation PI UUID Hex   Encode RowCount Radians UUIDShort UnHex   Encrypt Regexp Truncate AndAnd Trim   OldPassword Abs Sleep OrOr LTrim   RandomBytes Ceil Lock LogicXor RTrim   SHA1 Floor ReleaseLock BitOp Rpad   SHA2 Log AnyValue IsTrueOp BitLength   Char Format FromDays DayOfWeek Timestamp   CharLength FromBase64 Hour DayOfYear AddTime   FindInSet InsertFunc Minute Week ConvertTz   Field Instr Second WeekDay MakeTime   MakeSet LoadFile MicroSecond WeekOfYear PeriodAdd   Oct Lpad Month Year PeriodDiff   Quote Date MonthName YearWeek Quarter   Bin DateDiff Now FromUnixTime SecToTime   Elt TimeDiff DayName GetFormat SubTime   ExportSet DateFormat DayOfMonth StrToDate TimeFormat   UTCTim ToSeconds TimestampDiff DateArith Extract   UnixTimestamp UTCTimestamp UTCDate Time CurrentTime   ToDays TimestampAdd TimeToSec CurrentDate SysDate    二.</description>
    </item>
    
    <item>
      <title>TiDB Internal (I) - Data Storage</title>
      <link>https://pingcap.com/blog/2017-07-11-tidbinternal1/</link>
      <pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-11-tidbinternal1/</guid>
      <description>From Li SHEN: shenli@pingcap.com 
Table of Content  Foreword Storing data Key-Value RocksDB Raft Region MVCC Transaction Miscellaneous  Foreword: Database, operating system and compiler are known as the three big systems and regarded as the footstone of the whole computer software. Among them, database supports the businesses and is closer to the application layer. After decades of development, progress keeps emerging in this field.
Many people must have used databases of different kinds, but few have the experience of developing one, especially a distributed database.</description>
    </item>
    
    <item>
      <title>TiDB Internal (II) - Computing</title>
      <link>https://pingcap.com/blog/2017-07-11-tidbinternal2/</link>
      <pubDate>Tue, 11 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-07-11-tidbinternal2/</guid>
      <description>From Li SHEN: shenli@pingcap.com
Table of Content  Mapping the Relational Model to the Key-Value Model Metadata Management Architecture of SQL on Key-Value SQL Computing Distributed SQL Operation Architecture of the SQL Layer Summary  My last blog introduces the way that TiDB stores data, which is also the basic concepts of TiKV. In this article, I’ll elaborate on how TiDB uses the bottom layer Key-Value to store data, maps the relational model to the Key-Value model and performs SQL computing.</description>
    </item>
    
    <item>
      <title>TiDB Best Practice</title>
      <link>https://pingcap.com/blog-cn/tidb-best-practice/</link>
      <pubDate>Wed, 05 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-best-practice/</guid>
      <description>本文档用于总结在使用 TiDB 时候的一些最佳实践，主要涉及 SQL 使用、OLAP/OLTP 优化技巧，特别是一些 TiDB 专有的优化开关。 建议先阅读讲解 TiDB 原理的三篇文章(讲存储，说计算，谈调度)，再来看这篇文章。
前言 数据库是一个通用的基础组件，在开发过程中会考虑到多种目标场景，在具体的业务场景中，需要根据业务的实际情况对数据的参数或者使用方式进行调整。
TiDB 是一个兼容 MySQL 协议和语法的分布式数据库，但是由于其内部实现，特别是支持分布式存储以及分布式事务，使得一些使用方法和 MySQL 有所区别。
基本概念 TiDB 的最佳实践与其实现原理密切相关，建议读者先了解一些基本的实现机制，包括 Raft、分布式事务、数据分片、负载均衡、SQL 到 KV 的映射方案、二级索引的实现方法、分布式执行引擎。下面会做一点简单的介绍，更详细的信息可以参考 PingCAP 公众号以及知乎专栏的一些文章。
Raft Raft 是一种一致性协议，能提供强一致的数据复制保证，TiDB 最底层用 Raft 来同步数据。每次写入都要写入多数副本，才能对外返回成功，这样即使丢掉少数副本，也能保证系统中还有最新的数据。比如最大 3 副本的话，每次写入 2 副本才算成功，任何时候，只丢失一个副本的情况下，存活的两个副本中至少有一个具有最新的数据。
相比 Master-Slave 方式的同步，同样是保存三副本，Raft 的方式更为高效，写入的延迟取决于最快的两个副本，而不是最慢的那个副本。所以使用 Raft 同步的情况下，异地多活成为可能。在典型的两地三中心场景下，每次写入只需要本数据中心以及离得近的一个数据中心写入成功就能保证数据的一致性，而并不需要三个数据中心都写成功。但是这并不意味着在任何场景都能构建跨机房部署的业务，当写入量比较大时候，机房之间的带宽和延迟成为关键因素，如果写入速度超过机房之间的带宽，或者是机房之间延迟过大，整个 Raft 同步机制依然无法很好的运转。
分布式事务 TiDB 提供完整的分布式事务，事务模型是在 Google Percolator 的基础上做了一些优化。具体的实现大家可以参考这篇文章。这里只说两点：
 乐观锁
TiDB 的事务模型采用乐观锁，只有在真正提交的时候，才会做冲突检测，如果有冲突，则需要重试。这种模型在冲突严重的场景下，会比较低效，因为重试之前的操作都是无效的，需要重复做。举一个比较极端的例子，就是把数据库当做计数器用，如果访问的并发度比较高，那么一定会有严重的冲突，导致大量的重试甚至是超时。但是如果访问冲突并不十分严重，那么乐观锁模型具备较高的效率。所以在冲突严重的场景下，推荐在系统架构层面解决问题，比如将计数器放在 Redis 中。
 事务大小限制
由于分布式事务要做两阶段提交，并且底层还需要做 Raft 复制，如果一个事务非常大，会使得提交过程非常慢，并且会卡住下面的 Raft 复制流程。为了避免系统出现被卡住的情况，我们对事务的大小做了限制：
 单条 KV entry 不超过 6MB KV entry 的总条数不超过 30w KV entry 的总大小不超过 100MB  在 Google 的 Cloud Spanner 上面，也有类似的限制。</description>
    </item>
    
    <item>
      <title>Weekly update (June 26 ~ July 02, 2017)</title>
      <link>https://pingcap.com/weekly/2017-07-04-tidb-weekly/</link>
      <pubDate>Tue, 04 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-07-04-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 33 PRs in the TiDB repositories.
Added  Support priority options in the select statement. Add the GetOwnerID interface in OwnerManager. Add some columns in mysql.db: Make it compatible with MySQL. Add the IsolationLevel option in the coprocessor request to TiKV. Add the priority option in Key-Value request to TiKV. Support the RenameTable statement without the To keyword.  Fixed  Fix a bug in the update statement like update T set a = 8, b = a.</description>
    </item>
    
    <item>
      <title>【Infra Meetup NO.51】百度统一分布式计算框架 Bigflow</title>
      <link>https://pingcap.com/meetup/meetup-2017-07-01/</link>
      <pubDate>Sat, 01 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-07-01/</guid>
      <description>今天的 Meetup，我们邀请到了滴滴地图事业部专家工程师王聪老师，为大家分享《百度统一分布式计算框架 Bigflow 》。
 王聪，滴滴地图事业部专家工程师，前百度基础架构部工程师，主要工作方向为分布式计算与流式计算，在百度负责计算表示层 Bigflow 与流式计算引擎 Flink。
活动现场听得很专注的小伙伴们，桑拿天也阻止不了大家的学习热情。
王聪老师首先展示了分布式计算在百度的发展例程，他介绍百度在 2003 年建立了自己的分布式搜索系统。08 年引入 hadoop，09 年底搭建了大规模的机器学习平台，当时用的是 MPI。10 年百度自研了两套流式计算引擎，主要用来完成点击流与展现流的 join。
基于多引擎并存、跨引擎成本高、升级困难这几个痛点，最终开发了一款叫做 Bigflow 的计算框架，Bigflow 希望用户使用我们提供的 API 写代码，Bigflow 将作业进行计划的优化和翻译，并提交到计算引擎之上。对于这样的思路，有一种说法“计算机领域的任何问题，都可以通过增加一个额外的中间层来解决”。在这里 Bigflow 就是架在用户与引擎之间的中间层。
以下是新鲜出炉的 PPT 节选，尽情享用~
点击下载 PPT</description>
    </item>
    
    <item>
      <title>Refactoring the Built-in Functions in TiDB</title>
      <link>https://pingcap.com/blog/2017-06-27-refactor-builtin/</link>
      <pubDate>Tue, 27 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-06-27-refactor-builtin/</guid>
      <description>In order to accelerate expression evaluation, we recently refactored its framework. This tutorial will show you how to use the new computational framework to rewrite or add a built-in function in TiDB.
Table of Content  The overall process Example  Take a look at builtin_string.go Refine the existing TestLength() method Test the implementation of LENGTH at the SQL level   Before refactoring&amp;hellip; After refactoring&amp;hellip; Appendix  The overall process   Select any function to your interest from the expression directory, assuming the function is named XX.</description>
    </item>
    
    <item>
      <title>Weekly update (June 19 ~ June 25, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-26-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 35 PRs in the TiDB repositories.
Added  JSON type:  Tiny cleanup. Fix a bug in JSON path_expr. Fix a bug in unquote. Make json_unquote compatiable with MySQL Code cleanup.   Fixed  Fix failed test cases on the ppc64le platform Fix a bug when naming table with the auto_increment column. Use UTC time to compose index key for timestamp column.</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（2）- 火焰图</title>
      <link>https://pingcap.com/blog-cn/tangliu-tool-2/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tangliu-tool-2/</guid>
      <description>在前一篇文章，我们简单提到了 perf，实际 perf 能做的事情远远不止这么少，这里就要好好介绍一下，我们在 TiKV 性能调优上面用的最多的工具 - 火焰图。
火焰图，也就是 FlameGraph，是超级大牛 Brendan Gregg 捣鼓出来的东西，主要就是将 profile 工具生成的数据进行可视化处理，方便开发人员查看。我第一次知道火焰图，应该是来自 OpenResty 的章亦春介绍，大家可以详细去看看这篇文章动态追踪技术漫谈。
之前，我的所有工作在很长一段时间几乎都是基于 Go 的，而 Go 原生提供了很多相关的 profile 工具，以及可视化方法，所以我没怎么用过火焰图。但开始用 Rust 开发 TiKV 之后，我就立刻傻眼了，Rust 可没有官方的工具来做这些事情，怎么搞？自然，我们就开始使用火焰图了。
使用火焰图非常的简单，我们仅仅需要将代码 clone 下来就可以了，我通常喜欢将相关脚本扔到 /opt/FlameGraph 下面，后面也会用这个目录举例说明。
一个简单安装的例子：
wget https://github.com/brendangregg/FlameGraph/archive/master.zip unzip master.zip sudo mv FlameGraph-master/ /opt/FlameGraph CPU 对于 TiKV 来说，性能问题最开始关注的就是 CPU，毕竟这个是一个非常直观的东西。
当我们发现 TiKV CPU 压力很大的时候，通常会对 TiKV 进行 perf，如下：
perf record -F 99 -p tikv_pid -g -- sleep 60 perf script &amp;gt; out.perf 上面，我们对一个 TiKV 使用 99 HZ 的频繁采样 60 s，然后生成对应的采样文件。然后我们生成火焰图：</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 为 TiDB 重构 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function/</guid>
      <description>这是十分钟成为 TiDB Contributor 系列的第二篇文章，让大家可以无门槛参与大型开源项目，感谢社区为 TiDB 带来的贡献，也希望参与 TiDB Community 能为你的生活带来更多有意义的时刻。
为了加速表达式计算速度，最近我们对表达式的计算框架进行了重构，这篇教程为大家分享如何利用新的计算框架为 TiDB 重写或新增 built-in 函数。对于部分背景知识请参考这篇文章，本文将首先介绍利用新的表达式计算框架重构 built-in 函数实现的流程，然后以一个函数作为示例进行详细说明，最后介绍重构前后表达式计算框架的区别。
重构 built-in 函数整体流程  在 TiDB 源码 expression 目录下选择任一感兴趣的函数，假设函数名为 XX
 重写 XXFunctionClass.getFunction() 方法
 该方法参照 MySQL 规则，根据 built-in 函数的参数类型推导函数的返回值类型 根据参数的个数、类型、以及函数的返回值类型生成不同的函数签名，关于函数签名的详细介绍见文末附录  实现该 built-in 函数对应的所有函数签名的 evalYY() 方法，此处 YY 表示该函数签名的返回值类型
 添加测试：
 在 expression 目录下，完善已有的 TestXX() 方法中关于该函数实现的测试 在 executor 目录下，添加 SQL 层面的测试  运行 make dev，确保所有的 test cast 都能跑过
  示例 这里以重写 LENGTH() 函数的 PR 为例，进行详细说明</description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/blog/2017-06-20-rc3/</link>
      <pubDate>Tue, 20 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-06-20-rc3/</guid>
      <description>Highlight:  The privilege management is refined to enable users to manage the data access privileges using the same way as in MySQL.
 DDL is accelerated.
 The load balancing policy and process are optimized for performance.
 TiDB-Ansible is open sourced. By using TiDB-Ansilbe, you can deploy, upgrade, start and shutdown a TiDB cluster with one click.
  Detailed updates: TiDB:  The following features are added or improved in the SQL query optimizer:</description>
    </item>
    
    <item>
      <title>Weekly update (June 12 ~ June 18, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-20-tidb-weekly/</link>
      <pubDate>Tue, 20 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories.
Added  Refactor the optimizer:  Refactor ranger/statistic: calculate the range and row count of non pk column.  JSON type:  Support generated column:](https://github.com/pingcap/tidb/pull/3431) Support the JSON type in the cast expression.  Generated column:  Support basic generated column. Prevent modifying generated column. Add GeneratedExpr in ColumnInfo.  Support using clause in join statement.</description>
    </item>
    
    <item>
      <title>深入了解 gRPC：协议</title>
      <link>https://pingcap.com/blog-cn/grpc/</link>
      <pubDate>Sun, 18 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc/</guid>
      <description>经过很长一段时间的开发，TiDB 终于发了 RC3。RC3 版本对于 TiKV 来说最重要的功能就是支持了 gRPC，也就意味着后面大家可以非常方便的使用自己喜欢的语言对接 TiKV 了。
gRPC 是基于 HTTP/2 协议的，要深刻理解 gRPC，理解下 HTTP/2 是必要的，这里先简单介绍一下 HTTP/2 相关的知识，然后在介绍下 gRPC 是如何基于 HTTP/2 构建的。
HTTP/1.x HTTP 协议可以算是现阶段 Web 上面最通用的协议了，在之前很长一段时间，很多应用都是基于 HTTP/1.x 协议，HTTP/1.x 协议是一个文本协议，可读性非常好，但其实并不高效，笔者主要碰到过几个问题：
Parser 如果要解析一个完整的 HTTP 请求，首先我们需要能正确的读出 HTTP header。HTTP header 各个 fields 使用 \r\n 分隔，然后跟 body 之间使用 \r\n\r\n 分隔。解析完 header 之后，我们才能从 header 里面的 content-length 拿到 body 的 size，从而读取 body。
这套流程其实并不高效，因为我们需要读取多次，才能将一个完整的 HTTP 请求给解析出来，虽然在代码实现上面，有很多优化方式，譬如：
 一次将一大块数据读取到 buffer 里面避免多次 IO read 读取的时候直接匹配 \r\n 的方式流式解析  但上面的方式对于高性能服务来说，终归还是会有开销。其实最主要的问题在于，HTTP/1.</description>
    </item>
    
    <item>
      <title>来自 PingCAP CEO 的信：说在 B 轮融资完成之际</title>
      <link>https://pingcap.com/blog-cn/series-B-funding/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/series-B-funding/</guid>
      <description>平时技术说得多，今天说点走心的。
从决定出来创业到现在，刚好两年多一点，如果把 PingCAP 比喻成一个孩子的话， 刚是过了蹒跚学步的时期，前方有更大更美好的世界等我们去探索。这两年时间，在一片质疑声之中 ，TiDB 还算顽强的从无到有成长了起来。其实这一切的初心也很简单，最开始只不过是几个不愿妥协的分布式系统工程师对心目中&amp;rsquo;完美&amp;rsquo;的数据库的探索。很欣喜的看到 TiDB 的日渐成熟，周边工具和社区渐渐壮大，我感到由衷的自豪，在这个过程中，也一次又一次的挑战着技术和各自能力的边界，很庆幸能和自己的产品一起成长。
坚持做正确的事，哪怕这看起来是一条更困难的路。TiDB 从诞生的第一天起便决定开源，虽然更多的是商业上的考量，不过里面也有一点点读书人兼济天下的情怀和对传统 Hacker 精神的贯彻。在我们之前，很多人认为分布式 OLTP 和 OLAP 融合几乎是不可能的事情，也有无数的人，其中不乏亲朋好友，劝我们说在国内做这个事情几乎难于登天，而且没有成功的先例。不过我们还是相信一个朴素道理，有价值的技术一定会有它的舞台，另外，任何事情如果没有尝试就打退堂鼓也不是我们的风格。如果没有成功的先例，那就一起来创造先例，做开创者是我们每个人的梦想。说实话，从技术上来说，这个领域是一个非常前沿的领域，大多数时候我们面前是无人区，也很幸运，目前看来技术上和预想的没有出现大的偏差，整个产品和团队也在稳步的前进。
整个团队也从一开始的 3 个人，到今天 63 个志同道合的伙伴结伴前行，又一次很幸运，能凑齐这么一个具有很强战斗力和国际视野的团队，挑战计算机领域最困难和最前沿的课题之一，前方还有无数个迷人的问题等待着被解决，有时候也只能摸索着前进，不过这正是这个事情有意思的地方。谢谢你们，和你们一同工作，是我的荣幸。
到今天，我们很自豪的宣布，已经有数十家客户将 TiDB 使用在各自的生产环境中解决问题，感谢我们早期的铁杆用户和可爱的社区开发者，是你们让 TiDB 一点点的变得更加稳定成熟，随着社区的不断变大，TiDB 正以惊人的速度正向迭代，这就是开源的力量。
最后，PingCAP 也刚顺利的完成了 1500 万美金的 B 轮融资，感谢这轮的领投方华创资本，以及跟投方经纬中国，云启资本，峰瑞资本，险峰华兴。我们的征途是星辰大海，感谢有你们的一路支持。
刘奇、黄东旭、崔秋
PingCAP
2017-6-13</description>
    </item>
    
    <item>
      <title>Weekly update (June 06 ~ June 11, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-12-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 52 PRs in the TiDB repositories.
Added  Refactor the optimizer:
 Add an statsProfile interface to propagate statistic information among plans. Implement the statsProfile interface for the Join plan.  JSON type:
 Suport json_set, json_insert, json_replace and json_merge. Support the JSON type in the cast expression.  Use gRPC between TiDB and TiKV.
 Refactor the Analyze executor.
 Add the SubDuration function in util package.</description>
    </item>
    
    <item>
      <title>使用 Ansible 安装部署 TiDB</title>
      <link>https://pingcap.com/blog-cn/deployment-by-ansible/</link>
      <pubDate>Thu, 08 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/deployment-by-ansible/</guid>
      <description>背景知识 TiDB 作为一个分布式数据库，在多个节点分别配置安装服务会相当繁琐，为了简化操作以及方便管理，使用自动化工具来批量部署成为了一个很好的选择。
Ansible 是基于 Python 研发的自动化运维工具，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能，而且使用简单，仅需在管理工作站上安装 Ansible 程序配置被管控主机的 IP 信息，被管控的主机无客户端。基于以上原因，我们选用自动化工具 Ansible 来批量的安装配置以及部署 TiDB。
下面我们来介绍如何使用 Ansible 来部署 TiDB。
TiDB 安装环境配置如下 操作系统使用 CentOS7.2 或者更高版本，文件系统使用 EXT4。
 说明：低版本的操作系统(例如 CentOS6.6 )和 XFS 文件系统会有一些内核 Bug，会影响性能，我们不推荐使用。
    IP Services     192.168.1.101 PD Prometheus Grafana Pushgateway Node_exporter   192.168.1.102 PD TiDB Node_exporter   192.168.1.103 PD TiDB Node_exporter   192.168.1.104 TiKV Node_exporter   192.168.1.105 Tikv Node_exporter   192.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 谈调度</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-3/</link>
      <pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-3/</guid>
      <description>为什么要进行调度 先回忆一下第一篇文章提到的一些信息，TiKV 集群是 TiDB 数据库的分布式 KV 存储引擎，数据以 Region 为单位进行复制和管理，每个 Region 会有多个 Replica（副本），这些 Replica 会分布在不同的 TiKV 节点上，其中 Leader 负责读/写，Follower 负责同步 Leader 发来的 raft log。了解了这些信息后，请思考下面这些问题：
 如何保证同一个 Region 的多个 Replica 分布在不同的节点上？更进一步，如果在一台机器上启动多个 TiKV 实例，会有什么问题？ TiKV 集群进行跨机房部署用于容灾的时候，如何保证一个机房掉线，不会丢失 Raft Group 的多个 Replica？ 添加一个节点进入 TiKV 集群之后，如何将集群中其他节点上的数据搬过来? 当一个节点掉线时，会出现什么问题？整个集群需要做什么事情？如果节点只是短暂掉线（重启服务），那么如何处理？如果节点是长时间掉线（磁盘故障，数据全部丢失），需要如何处理？ 假设集群需要每个 Raft Group 有 N 个副本，那么对于单个 Raft Group 来说，Replica 数量可能会不够多（例如节点掉线，失去副本），也可能会 过于多（例如掉线的节点又回复正常，自动加入集群）。那么如何调节 Replica 个数？ 读/写都是通过 Leader 进行，如果 Leader 只集中在少量节点上，会对集群有什么影响？ 并不是所有的 Region 都被频繁的访问，可能访问热点只在少数几个 Region，这个时候我们需要做什么？ 集群在做负载均衡的时候，往往需要搬迁数据，这种数据的迁移会不会占用大量的网络带宽、磁盘 IO 以及 CPU？进而影响在线服务？  这些问题单独拿出可能都能找到简单的解决方案，但是混杂在一起，就不太好解决。有的问题貌似只需要考虑单个 Raft Group 内部的情况，比如根据副本数量是否足够多来决定是否需要添加副本。但是实际上这个副本添加在哪里，是需要考虑全局的信息。整个系统也是在动态变化，Region 分裂、节点加入、节点失效、访问热点变化等情况会不断发生，整个调度系统也需要在动态中不断向最优状态前进，如果没有一个掌握全局信息，可以对全局进行调度，并且可以配置的组件，就很难满足这些需求。因此我们需要一个中心节点，来对系统的整体状况进行把控和调整，所以有了 PD 这个模块。</description>
    </item>
    
    <item>
      <title>Weekly update (May 22 ~ June 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-06-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-06-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 53 PRs in the TiDB repositories.
Added  Support using After and First to specify column position in the Alter Table Statement.
 Support the password builtin function.
 Support the inet6_ntoa builtin function.
 Support the Extract and Unquote function for Json.
 Support json_{set/insert/replace} and json_merge for Json.
 Support batched Index Lookup Join.
  Fixed  Fix a goroutine leak problem.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.49】TiDB Best Practice</title>
      <link>https://pingcap.com/meetup/meetup-2017-06-03/</link>
      <pubDate>Sat, 03 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-06-03/</guid>
      <description>今日的 Meetup，我司 Engineering VP 申砾同学亲自上阵，为大家分享了《TiDB Best Practice 》，好多使用经验及背后技术实现原理都是首次揭秘（当然，包括彩蛋）。
 本期讲师：申砾，PingCAP Engineering VP，前网易有道词典服务器端核心开发，前奇虎 360 新闻推荐系统 / 地图基础数据与检索系统 Tech Lead。
TiDB 是一个分布式数据库，支持 MySQL 协议以及语法，在一些场景中都可以无缝替换 MySQL，以获得分布式的好处。但是分布式数据库有其自身的特点，想要在业务中用好需要遵循一些实践原则。
本次分享申砾同学首先介绍了 TiDB 的一些关键部分的实现原理，理解这些内部实现有利于理解 TiDB 的外在表现。然后与大家讨论了应用数据库时的典型操作的最佳实践以及要注意的事项，并对 TiDB 的适用场景进行了讲解。
PPT 很干，一点水都挤不出来&amp;hellip;随便放几张你们感受下┑(￣Д ￣)┍
最后，申砾同学还分享了 TiDB 最近的一些项目进展，并首次公开披露 PingCAP 最新动向：独立研发的 TiDB 专用的 Spark Connector 即将上线。
Spark 是当下最流行的大数据分析系统，拥有活跃的社区。PingCAP 希望能够将 TiDB 与 Spark 相结合，通过 Spark 对 TiDB 中存储的数据做实时分析，以融入这个生态。为了保证这个连接过程尽可能的高效，所以除了基本的 JDBC Connector 之外，便有了 TiDB 专用的 Spark Connector。
彩蛋来啦
Demo of Spark on TiDB 即将上线，敬请期待～</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（1）</title>
      <link>https://pingcap.com/blog-cn/tangliu-tool-1/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tangliu-tool-1/</guid>
      <description>使用 iostat 定位磁盘问题 在一个性能测试集群，我们选择了 AWS c3.4xlarge 机型，主要是为了在一台机器的两块盘上面分别跑 TiKV。在测试一段时间之后，我们发现有一台 TiKV 响应很慢，但是 RocksDB 并没有相关的 Stall 日志，而且慢查询也没有。
于是我登上 AWS 机器，使用 iostat -d -x -m 5 命令查看，得到如下输出：
Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util xvda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 xvdb 8.00 12898.00 543.00 579.00 31.66 70.15 185.84 51.93 54.39 7.03 98.79 0.60 66.80 xvdc 0.00 0.00 206.00 1190.</description>
    </item>
    
    <item>
      <title>Rust in TiKV</title>
      <link>https://pingcap.com/blog/2017-05-27-rust-in-tikv/</link>
      <pubDate>Sat, 27 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-05-27-rust-in-tikv/</guid>
      <description>This is the speech Siddon Tang gave at the 1st Rust Meetup in Beijing on April 16, 2017.
(Email: tl@pingcap.com)
Table of Content 
 What&amp;rsquo;s TiKV We need a language with&amp;hellip; Why not C++? Why not Go? So we turned to Rust&amp;hellip; TiKV Timeline TiKV Architecture Multi-Raft Scale out A simple write flow Key technologies Future plan  Hello everyone, today I will talk about how we use Rust in TiKV.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说计算</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-2/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-2/</guid>
      <description>关系模型到 Key-Value 模型的映射 在这我们将关系模型简单理解为 Table 和 SQL 语句，那么问题变为如何在 KV 结构上保存 Table 以及如何在 KV 结构上运行 SQL 语句。 假设我们有这样一个表的定义：
CREATE TABLE User { ID int, Name varchar(20), Role varchar(20), Age int, PRIMARY KEY (ID)， Key idxAge (age) }; SQL 和 KV 结构之间存在巨大的区别，那么如何能够方便高效地进行映射，就成为一个很重要的问题。一个好的映射方案必须有利于对数据操作的需求。那么我们先看一下对数据的操作有哪些需求，分别有哪些特点。
对于一个 Table 来说，需要存储的数据包括三部分：
 表的元信息 Table 中的 Row 索引数据  表的元信息我们暂时不讨论，会有专门的章节来介绍。 对于 Row，可以选择行存或者列存，这两种各有优缺点。TiDB 面向的首要目标是 OLTP 业务，这类业务需要支持快速地读取、保存、修改、删除一行数据，所以采用行存是比较合适的。
对于 Index，TiDB 不止需要支持 Primary Index，还需要支持 Secondary Index。Index 的作用的辅助查询，提升查询性能，以及保证某些 Constraint。查询的时候有两种模式，一种是点查，比如通过 Primary Key 或者 Unique Key 的等值条件进行查询，如 select name from user where id=1; ，这种需要通过索引快速定位到某一行数据；另一种是 Range 查询，如 select name from user where age &amp;gt; 30 and age &amp;lt; 35;，这个时候需要通过idxAge索引查询 age 在 20 和 30 之间的那些数据。Index 还分为 Unique Index 和 非 Unique Index，这两种都需要支持。</description>
    </item>
    
    <item>
      <title>A Brief Introduction of TiDB</title>
      <link>https://pingcap.com/blog/2017-05-23-perconalive17/</link>
      <pubDate>Tue, 23 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-05-23-perconalive17/</guid>
      <description>This is the speech Edward Huang gave at Percona Live - Open Source Database Conference 2017.
The slides are here.
 Speaker introduction What would you do when… TiDB Project - Goal Sofware Stack Safe Split Scale Out ACID Transaction Distributed SQL TiDB SQL Layer Overview What Happens behind a query Distributed Join (HashJoin) Tools Matter Use Cases Sysbench Roadmap  Speaker introduction  As one of the three co-founders of PingCAP, I feel honored that PingCAP was once again invited to the Percona Live Conference.</description>
    </item>
    
    <item>
      <title>Migration from MySQL to TiDB to handle tens of millions of rows of data per day</title>
      <link>https://pingcap.com/blog/2017-05-22-Comparison-between-MySQL-and-TiDB-with-tens-of-millions-of-data-per-day/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-05-22-Comparison-between-MySQL-and-TiDB-with-tens-of-millions-of-data-per-day/</guid>
      <description>TiDB use case Table of content  Background MySQL, our first choice Look for new solutions TiDB, give it a go Feedbacks from TiDB  Background GAEA is a mobile gaming provider and aims to develop high-quality games for international players. GAEA uses its GaeaAD system to support the cross-platform real-time advertising system. GaeaAD performs a real-time match between the advertising data and the information reported by the game SDK.</description>
    </item>
    
    <item>
      <title>Weekly update (May 15 ~ May 21, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-22-tidb-weekly/</link>
      <pubDate>Mon, 22 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-22-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 31 PRs in the TiDB repositories.
Added  Use etcd to elect DDL job leader.
 Support Load Data with specified column list.
 Add the following builtin functions:
 umcompress and uncompressdlength convert_tz period-diff  Support the Json type and Json data encoding/decoding.
 Add a Jenkins CI in Pull Request.
 Add the EvalDuration and EvalTime interface for expressions.</description>
    </item>
    
    <item>
      <title>Weekly update (May 08 ~ May 14, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-15-tidb-weekly/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-15-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Add builtin function uncompress and uncompressdlength, convert_tz, period-diff
 Fill data into information_schema.key_column_usage.
 Add Open interface for Executor.
 Show warnings for Load Data statement.
 Support Json type and functions in parser.
 Support top-n operator in new planner.
  Fixed  Consider session variable time_zone for timestamp datum.
 Fix data race problem in IndexLookup Executor.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说存储</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-1/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-1/</guid>
      <description>引言 数据库、操作系统和编译器并称为三大系统，可以说是整个计算机软件的基石。其中数据库更靠近应用层，是很多业务的支撑。这一领域经过了几十年的发展，不断的有新的进展。
很多人用过数据库，但是很少有人实现过一个数据库，特别是实现一个分布式数据库。了解数据库的实现原理和细节，一方面可以提高个人技术，对构建其他系统有帮助，另一方面也有利于用好数据库。
研究一门技术最好的方法是研究其中一个开源项目，数据库也不例外。单机数据库领域有很多很好的开源项目，其中 MySQL 和 PostgreSQL 是其中知名度最高的两个，不少同学都看过这两个项目的代码。但是分布式数据库方面，好的开源项目并不多。 TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于分布式数据库自身的复杂性，很多人并不能很好的理解整个项目，所以我希望能写一些文章，自顶向上，由浅入深，讲述 TiDB 的一些技术原理，包括用户可见的技术以及大量隐藏在 SQL 界面后用户不可见的技术点。
保存数据 数据库最根本的功能是能把数据存下来，所以我们从这里开始。
保存数据的方法很多，最简单的方法是直接在内存中建一个数据结构，保存用户发来的数据。比如用一个数组，每当收到一条数据就向数组中追加一条记录。这个方案十分简单，能满足最基本，并且性能肯定会很好，但是除此之外却是漏洞百出，其中最大的问题是数据完全在内存中，一旦停机或者是服务重启，数据就会永久丢失。
为了解决数据丢失问题，我们可以把数据放在非易失存储介质（比如硬盘）中。改进的方案是在磁盘上创建一个文件，收到一条数据，就在文件中 Append 一行。OK，我们现在有了一个能持久化存储数据的方案。但是还不够好，假设这块磁盘出现了坏道呢？我们可以做 RAID （Redundant Array of Independent Disks），提供单机冗余存储。如果整台机器都挂了呢？比如出现了火灾，RAID 也保不住这些数据。我们还可以将存储改用网络存储，或者是通过硬件或者软件进行存储复制。到这里似乎我们已经解决了数据安全问题，可以松一口气了。But，做复制过程中是否能保证副本之间的一致性？也就是在保证数据不丢的前提下，还要保证数据不错。保证数据不丢不错只是一项最基本的要求，还有更多令人头疼的问题等待解决：
 能否支持跨数据中心的容灾？ 写入速度是否够快？ 数据保存下来后，是否方便读取？ 保存的数据如何修改？如何支持并发的修改？ 如何原子地修改多条记录？  这些问题每一项都非常难，但是要做一个优秀的数据存储系统，必须要解决上述的每一个难题。 为了解决数据存储问题，我们开发了 TiKV 这个项目。接下来我向大家介绍一下 TiKV 的一些设计思想和基本概念。
Key-Value 作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。TiKV 的选择是 Key-Value 模型，并且提供有序遍历方法。简单来讲，可以将 TiKV 看做一个巨大的 Map，其中 Key 和 Value 都是原始的 Byte 数组，在这个 Map 中，Key 按照 Byte 数组总的原始二进制比特位比较顺序排列。 大家这里需要对 TiKV 记住两点：
 这是一个巨大的 Map，也就是存储的是 Key-Value pair 这个 Map 中的 Key-Value pair 按照 Key 的二进制顺序有序，也就是我们可以 Seek 到某一个 Key 的位置，然后不断的调用 Next 方法以递增的顺序获取比这个 Key 大的 Key-Value  讲了这么多，有人可能会问了，这里讲的存储模型和 SQL 中表是什么关系？在这里有一件重要的事情要说四遍：</description>
    </item>
    
    <item>
      <title>基于 Tile 连接 Row-Store 和 Column-Store</title>
      <link>https://pingcap.com/blog-cn/tile-row-store/</link>
      <pubDate>Sun, 14 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tile-row-store/</guid>
      <description>在之前的 Kudu 的文章里面，我已经提到过，行列混存是一个非常有意思的研究方向，因为不同的存储方式有不同的针对应用场景，但作为技术人员，折腾是天性，所以大家都在研究如何融合行存和列存，让一个服务能尽量满足大部分应用需求，而这也是 TiDB 在努力的方向。
在 Kudu Paper 里面说到，Kudu 首先在 mem 里面使用行存，但刷到硬盘之后，则使用的是列存，这当然是一个可以尝试的方式，但我觉得应该还有更多种的解决方式，于是找到了 CMU 的 Peloton 以及相关的 Paper，觉得有必要研究记录一下。
Storage Model 很多时候，我喜欢用行存和列存，但看 Paper 的时候，发现都喜欢使用 NSM 和 DSM 来说明，这里就简单说明一下。
NSM NSM 是 N-ary storage model 的简称，当然就是通常的行存了。NSM 主要针对 OLTP 场景，因为需要高性能的随机写入，NSM 的存储方式如下：
NSM 不适用需要读取大量数据，并分析特定 column 的场景，因为 NSM 需要把整个 record 给读出来，在拿到对应的 column 数据分析，数据数据量很大，整个开销会很大。
DSM DSM 是 decomposition storage model 的简称，也就是列存。DSM 主要针对 OLAP 场景，因为需要对一些特定的 column 进行快速扫描分析，DSM 的存储方式如下：
DSM 当然就不适用与需要频繁随机更新的情况，因为任何写入，DSM 需要将 record 分开写入到不同的地方，写开销会很大。
FSM 为了解决这个问题，就有了一个 FSM flexible storage model 来融合 NSM 和 DSM，在 Peloton 里面，它把这套系统叫做 HTAP (Hybrid Transactional/Analytical Processing)，</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.48】分布式对象存储面临的挑战</title>
      <link>https://pingcap.com/meetup/meetup-2017-05-13/</link>
      <pubDate>Sat, 13 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-05-13/</guid>
      <description>今天的 Meetup，我们请到了来自白山云的张炎泼老师，为大家分享《分布式对象存储面临的挑战》。
 讲师介绍：张炎泼 (xp)，30 年软件开发经验，物理系背叛者，设计师眼中的美工，bug maker，vim 死饭，悬疑片脑残粉。曾就职新浪，美团。现在白山云，不是白云山。
在本次分享中，张炎泼老师从：海量小文件如何存储、如何节省存储成本、如何实现数据的自动恢复，三个方面，为大家进行了详细讲解。
以下是本期 PPT 节选
点击 下载本期 PPT</description>
    </item>
    
    <item>
      <title>Kudu - 一个融合低延迟写入和高性能分析的存储系统</title>
      <link>https://pingcap.com/blog-cn/kudu/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/kudu/</guid>
      <description>Kudu 是一个基于 Raft 的分布式存储系统，它致力于融合低延迟写入和高性能分析这两种场景，并且能很好的嵌入到 Hadoop 生态系统里面，跟其他系统譬如 Cloudera Impala，Apache Spark 等对接。
Kudu 很类似 TiDB。最开始，TiDB 是为了 OLTP 系统设计的，但后来发现我们 OLAP 的功能也越来越强大，所以就有了融合 OLTP 和 OLAP 的想法，当然这条路并不是那么容易，我们还有很多工作要做。因为 Kudu 的理念跟我们类似，所以我也很有兴趣去研究一下它，这里主要是依据 Kudu 在 2015 发布的 paper，因为 Kudu 是开源的，并且在不断的更新，所以现在代码里面一些实现可能还跟 paper 不一样了，但这里仅仅先说一下我对 paper 的理解，实际的代码我后续研究了在详细说明。
为什么需要 Kudu？ 结构化数据存储系统在 Hadoop 生态系统里面，通常分为两类：
 静态数据，数据通常都是使用二进制格式存放到 HDFS 上面，譬如 Apache Avro，Apache Parquet。但无论是 HDFS 还是相关的系统，都是为高吞吐连续访问数据这些场景设计的，都没有很好的支持单独 record 的更新，或者是提供好的随机访问的能力。
 动态数据，数据通常都是使用半结构化的方式存储，譬如 Apache HBase，Apache Cassandra。这些系统都能低延迟的读写单独的 record，但是对于一些像 SQL 分析这样需要连续大量读取数据的场景，显得有点捉紧见拙。
  上面的两种系统，各有自己的侧重点，一类是低延迟的随机访问特定数据，而另一类就是高吞吐的分析大量数据。之前，我们并没有这样的系统可以融合上面两种情况，所以通常的做法就是使用 pipeline，譬如我们非常熟悉的 Kafka，通常我们会将数据快速写到 HBase 等系统里面，然后通过 pipeline，在导出给其它分析系统。虽然我们在一定层面上面，我们其实通过 pipeline 来对整个系统进行了解耦，但总归要维护多套系统。而且数据更新之后，并不能直接实时的进行分析处理，有延迟的开销。所以在某些层面上面，并不是一个很好的解决方案。</description>
    </item>
    
    <item>
      <title>Weekly update (May 01 ~ May 07, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-08-tidb-weekly/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-08-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 33 PRs in the TiDB repositories.
Added  Add builtin function is_ipv4_mapped, makedate, utc_time
 Enable privilege checking by default. You could also disable privilege checking through --privilege=false.
 Support Analyze Index statement: after adding an index, we could run this statement to analyze the newly added index.
 Add Trigger_priv column in mysql.user system table.
 Add coveralls in CI.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.47】分布式定时任务中间件架构 Elastic-Job 的两种实现</title>
      <link>https://pingcap.com/meetup/meetup-2017-05-06/</link>
      <pubDate>Sat, 06 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-05-06/</guid>
      <description>今天的 Meetup ，我们请到了当当架构部负责人张亮，大家分享了《分布式定时任务中间件架构 Elastic-Job 的两种实现》。
 本期讲师：张亮
当当架构部负责人，主要负责分布式中间件以及私有云平台的搭建。致力于开源，目前主导两个开源项目 elastic-job 和 sharding-jdbc。擅长以 java 为主分布式架构以及以 Mesos 为主的云平台方向，推崇优雅代码，对如何写出具有展现力的代码有较多研究。
今日帝都依然大风，但小伙伴们学习的热情丝毫未减哦~
在本次分享中，张亮老师从分布式定时任务中间件的适用场景，轻量级去中心化架构方案以及基于 Mesos 的中心化架构方案，三个方面为大家进行了详细讲解。
在互联网应用中，各式各样的定时任务存于系统的各个角落，我们希望由一个平台统一将这些作业管理起来。然而，一旦平台中运行大量的作业，发现异常作业并手动处理难免会感到繁琐，同时人工处理还会带来很多其他的额外成本。如何最大限度的减少人工干预？
高可用可以让作业在被系统发现宕机之后能自动切换。而弹性化可以认为是高可用的进阶版本，在高可用的同时还能够提升效率和充分利用资源。对于动态的扩容和缩容，通常采用分片的方式实现。
去中心化架构是指所有的作业节点都是对等的，优点是轻量级，部署成本低；缺点则是，如果各作业服务器时钟不一致会产生同一作业的不同分片运行有先有后，缺乏统一调度，并且不能跨语言。
中心化架构将系统分为调度节点和执行节点，可以解决服务器时间差以及跨语言的问题；缺点是部署和运维稍复杂。
Elastic-Job 最初的版本分离于当当内部的应用框架 ddframe，是一个纯 Java 实现的分布式方案，参照 dubbo 的方式，提供无中心化解决方案。
如今，Elastic-Job 已开源近 2 年，截止目前已更新发布18 次，GitHub Star 数近 2000，成绩出色。更有多个开源产品衍生自 Elastic-Job。
应小伙伴们的强烈要求，张亮老师临时加场 Demo 演示。 最后，还有超多第一手爆料，是属于现场听讲小伙伴们的专属福利 ✌️ 很心动？下周六，老时间，老地点，PingCAP 第 48 期 Infra Meetup 等你呦！</description>
    </item>
    
    <item>
      <title>Weekly update (April 24 ~ April 30, 2017)</title>
      <link>https://pingcap.com/weekly/2017-05-02-tidb-weekly/</link>
      <pubDate>Tue, 02 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-05-02-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 49 PRs in the TiDB repositories.
Added  Add builtin function truncate, makedate, utc_time
 Add pre-commit hook.
 Add a plan for Analyze.
 Add a check list about the things that contributors should think about before sending a PR.
 Support ENGINE option with partition option in table definition.
 Add code review guide.
  Fixed  Fix bug in converting string to hex/bit.</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.46】MySQL 5.7 的特性及实践</title>
      <link>https://pingcap.com/meetup/meetup-2017-04-22/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-04-22/</guid>
      <description>今天的 Meetup，我们邀请到了熊猫直播 DBA 杨尚刚老师，为大家分享《MySQL 5.7 的特性及实践》~
 本期讲师：杨尚刚
熊猫直播高级 DBA，负责后端数据库平台建设和架构设计。前新浪高级数据库工程师，负责新浪微博核心数据库架构改造优化，以及数据库相关的服务器存储选型设计。
2015 年最重磅的当属 MySQL 5.7 GA 的发布，号称 160 万只读 QPS，大有赶超 NoSQ L趋势。
不过官方的硬件测试环境是很高的，所以这个 160 万 QPS 对于大家测试来说，可能还比较遥远，所以实际测试的结果可能会失望。但是，至少我们看到了基于同样测试环境，MySQL 5.7 在性能上的改进，对于多核利用的改善。
本次分享中，杨老师讲解了 MySQL 5.7 在运维、优化器 Server 层、InnoDB 层等方面的优化，以及 MySQL 未来的发展趋势。
运维方面  动态修改 Buffer Pool
 MySQL redo log大小
 innodb_file_per_table
 query cache
 SQL_Mode
 binlog_rows_query_log_events
 max_execution_time
 replication info in tables
 innodb_numa_interleave
 动态修改 replication filter</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：Cloud-Native 的分布式数据库架构与实践</title>
      <link>https://pingcap.com/blog-cn/talk-cloud-native/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-cloud-native/</guid>
      <description>4 月 19 日，我司 CTO 黄东旭同学在全球云计算开源大会上，发表了《Cloud-Native 的分布式数据库架构与实践》主题演讲，以下为演讲实录。
实录 大家好，今天我的题目是 Cloud-Native 与分布式数据库的实践。先简单的介绍一下自己，我是 PingCAP 的联合创始人和 CTO，过去一直在做基础软件领域的工程师，基本上做的所有的东西都是开源。在分享之前我想说一下为什么现在各行各业或者整个技术软件社区一直在重复的再造数据库，现在数据库到底怎么了，为什么这么百花齐放？
 首先随着业务的多种多样，还有不管是传统行业还是互联网行业，业务的迭代速度越来越互联网化，使得整个数据量其实是一直在往上走的；
 第二就是随着 IOT 的设备还有包括像手机、移动互联网蓬勃的发展，终端其实也不再仅仅是传统的 PC 客户端的数据的接入；
 第三方面随着现在 AI 或者大数据分析一些模型或者理论上的突破，使得在大数据上进行计算的手段越来越多样，还有在物理上一些硬件的新的带有保护的内存，各种各样新的物理的设备，越来越多的硬件或者物理上的存储成本持续的降低，使得我们的数据库需要要面对更多的挑战。
  关联数据库理论是上世纪七十年代做出来的东西，现在四十年过去不管是物理的环境还是计算模型都是完全不一样的阶段，还抱着过去这种观念可能并不是一个面向未来的设计。而且今天我的题目是 Cloud-Native，有一个比较大胆的假设，大家在过去三十年的计算平台基本都是在一台 PC 或者一个服务器或者一个手机这样的独立的计算平台，但是未来我觉得一切的服务都应该是分布式的。因为我觉得摩尔定律已经失效了，所以未来的操作系统会是一个大规模分布式的操作系统，在上面跑的任何的进程，任何的服务都应该是分布式的，在这个假设下怎么去做设计，云其实是这个假设最好的载体。怎么在这个假设上去设计面向云的技术软件，其实是最近我一直在思考的一个问题。其实在这个时代包括面向云的软件，对业务开发来说尽量还是不要太多的改变过去的开发习惯。你看最近大数据的发展趋势，从最传统的关系数据库到过去十年相比，整个改变了用户的编程模型，但是改变到底是好的还是不好的，我个人觉得其实并不是太好。最近这两年大家会看到整个学术圈各种各样的论文都在回归，包括 DB 新时代的软件都会把扩展性和分布式放在第一个要素。
大家可能听到主题会有点蒙，叫 Cloud-Native，Cloud-Native 是什么？其实很早的过去也不是没有人做过这种分布式系统的尝试，最早是 IBM 提出面向服务的软件架构设计，最近热门的 SOA、Micro Service 把自己的服务拆分成小的服务，到现在谷歌一直对外输出一个观点就是 Cloud-Native，就是未来大家的业务看上去的分布式会变成一个更加透明的概念，就是你怎么让分布式的复杂性消失在云的基础设施后，这是 Cloud-Native 更加关心的事情。
这个图是 CNCF 的一个基金会，也是谷歌支持的基金会上扒过来的图。这里面有一个简单的定义，就是 SCALE 作为一等公民，面向 Cloud-Native 的业务必须是弹性伸缩的，不仅能伸也得能缩；第二就是在对于这种 Cloud-Native 业务来说是面向 Micro service 友好；第三就是部署更加的去人工化。
最近大家可能也看到很多各种各样容器化的方案，背后代表的意义是什么？就是整个运维和部署脱离人工，大家可以想象过去十几二十年来，一直以来运维的手段是什么样的。我找了一个运维，去买服务器，买服务器装系统，在上面部署业务。但是现在 Cloud-Native 出现变得非常的自动化，就相当于把人的功能变得更低，这是很有意义的，因为理想中的世界或者未来的世界应该怎么样，一个业务可能会有成百上千的物理节点，如果是人工的去做运维和部署是根本不可能做得到的，所以其实构建整个 Cloud-Native 的基础设施的两个条件：第一个就是存储本身的云化；第二就是运维要和部署的方式必须是云化的。
我就从这两个点说一下我们 TiDB 在上面的一些工作和一些我的思考。
存储本身的云化有几个基本条件，大家过去认为是高可用，主要停留在双活。其实仔细去思考的话，主备的方案是很难保证数据在完全不需要人工的介入情况下数据的一致性可用性的，所以大家会发现最近这几年出来的分布式存储系统的可用性的协议跟复制协议基本都会用类似 Raft/Paxos 基于选取的一致性算法，不会像过去做这种老的复制的方案。
第二就是整个分片的策略，作为分布式系统数据一定是会分片的，数据分片是来做分布式存储唯一的思路，自动分片一定会取代传统的人工分片来去支撑业务。比如传统分片，当你的数据量越来越大，你只能做分库分表或者用中间件，不管你分库分表还是中间件都必须制订自己人工的分辨规则，但是其实在一个真正面向 Cloud 的数据库设计里，任何一种人的介入的东西都是不对的。</description>
    </item>
    
    <item>
      <title>Weekly update (April 10 ~ April 16, 2017)</title>
      <link>https://pingcap.com/weekly/2017-04-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-04-17-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 26 PRs in the TiDB repositories.
Added  Update etcd client in vendor.
 Add builtin function time-to-sec
 Add definition for builtin functions: bit_count, to_base64, right
  Fixed  Fix the error message for data overflow.
 Fix a panic.
 Fix a bug in top-n pushdown.
 Fix a data race bug in session context.
 Fix a bug in name resolver for GroupBy clause.</description>
    </item>
    
    <item>
      <title>今天这里有一场国内最大的 Rust 爱好者聚会～✌️</title>
      <link>https://pingcap.com/meetup/meetup-2017-04-16/</link>
      <pubDate>Sun, 16 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-04-16/</guid>
      <description>今天这里有一场国内最大的 Rust 爱好者聚会～✌️ 原创
2017-04-16 PingCAP PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (March 27 ~ April 09, 2017)</title>
      <link>https://pingcap.com/weekly/2017-04-10-tidb-weekly/</link>
      <pubDate>Mon, 10 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-04-10-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 74 PRs in the TiDB repositories.
Added  Support Index Nest Lookup Join operator.#2834, #2945
 Add many builtin functions: quote, is_ipv4, compress, inet_aton, format, bin, random-bytes, sin, inet_ntoa, cos, from_base64, tan, cot, to_days, timestampadd
 Check privileges for show databases/tables statement.
 Calculate distinct information in statistic module.#2947, #2966
 Add a switcher to split large inset transaction into multiple small transactions automatically.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 44 期 Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-04-08/</link>
      <pubDate>Sat, 08 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-04-08/</guid>
      <description>COISF 专场|PingCAP 第 44 期 Meetup 2017-04-08 徐磊 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (March 20 ~ March 26, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 40 PRs in the TiDB repositories.
Added  Support Sort Merge Join operator.
 Add many builtin functions: degree, insert, instr, any_value, elt, uuid, ord, sin, inet_ntoa, maketime, sha2, quarter
 Add a command line flag to start TiDB without authentication function.
 Support use special comment /*+ */ for optimizer hint.
 Make index serial scan concurrency configurable with system variable.</description>
    </item>
    
    <item>
      <title>如何从零开始参与大型开源项目</title>
      <link>https://pingcap.com/blog-cn/how-to-contribute/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-contribute/</guid>
      <description>写在前面的话 上世纪 70 年代，IBM 发明了关系型数据库。但是随着现在移动互联网的发展，接入设备越来越多，数据量越来越大，业务越来越复杂，传统的数据库显然已经不能满足海量数据存储的需求。虽然目前市场上也不乏分布式数据库模型，但没有品位的文艺青年不是好工程师，我们觉得，不，这些方案都不是我们想要的，它们不够美，鲜少能够把分布式事务与弹性扩展做到完美。
受 Google Spanner/F1 的启发，一款从一开始就选择了开源道路的 TiDB 诞生了。 它是一款代表未来的新型分布式 NewSQL 数据库，它可以随着数据增长而无缝水平扩展，只需要通过增加更多的机器来满足业务增长需求，应用层可以不用关心存储的容量和吞吐，用东旭的话说就是「他自己会生长」。
在开源的世界里，TiDB 和 TiKV 吸引了更多的具有极客气质的开发者，目前已经拥有超过 9000 个 star 和 100 个 contributor，这已然是一个世界顶级开源项目的水准。而成就了这一切的，则是来自社区的力量。
最近我们收到了很多封这样的邮件和留言，大家说：
 谢谢你们，使得旁人也能接触大型开源项目。本身自己是DBA，对数据库方面较干兴趣，也希望自己能逐步深入数据库领域，深入TiDB，为 TiDB 社区贡献更多、更有价值的力量。
 我是一个在校学生，刚刚收到邮件说我成为了 TiDB 的 Contributor，这让我觉得当初没听父母的话坚持了自己喜欢的计算机技术，是个正确的选择，但我还需要更多的历练，直到能完整地展现、表达我的思维。
  这让我感触颇多，因为，应该是我们感谢你们才是啊，没有社区，一个开源项目就成不了一股清泉甚至一汪海洋。 公司的小姑娘说，她觉得还有很多的人想要参与进来的，可工程师团队欠缺平易近人的表达，这个得改。
于是便有了这篇文章以及未来的多篇文章和活动，我们欢迎所有的具有气质的开发者能和 TiDB 一起成长，一起见证数据库领域的革新，改变世界这事儿有时候也不那么难。
我要重点感谢今天这篇文章的作者，来自社区的朱武（GitHub ID:viile ）、小卢（GitHub ID:lwhhhh ）和杨文（GitHub ID: yangwenmai），当在 TiDB Contributor Club 里提到想要做这件事的时候，是他们踊跃地加入了 TiDB Tech Writer 的队伍，高效又专业地完成了下文的编辑，谢谢你们。
一个典型的开源项目是由什么组成的 The Community（社区）  一个项目经常会有一个围绕着它的社区，这个社区由各个承担不同角色的用户组成。
 项目的拥有者：在他们账号中创建项目并拥有它的用户或者组织。
 维护者和合作者：主要做项目相关的工作和推动项目发展，通常情况下拥有者和维护者是同一个人，他们拥有仓库的写入权限。
 贡献者：发起拉取请求 (pull request) 并且被合并到项目里面的人。</description>
    </item>
    
    <item>
      <title>RocksDB 专场分享|PingCAP 第 43 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-25/</link>
      <pubDate>Sat, 25 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-25/</guid>
      <description>RocksDB 专场分享|PingCAP 第 43 期 NewSQL Meetup 2017-03-25 宋昭&amp;amp;赵安安 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (March 13 ~ March 19, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-20-tidb-weekly/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-20-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 33 PRs in the TiDB repositories.
Added  Add system table mysql.stats_meta: used for storing statistic information.
 Add a Restful API to get region info from pd.
 Add a system variable to control the behavior of unfolding subquery in in expression.
 Add many builtin functions: acos, asin, atan, make_set, oct, pi, lpad, radians, exp, ip_v6
  Fixed  Check truncated UTF8 string when casting value.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 42 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-18/</link>
      <pubDate>Sat, 18 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-18/</guid>
      <description>COISF 专场|PingCAP 第 42 期 NewSQL Meetup 2017-03-18 梁堰波 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>十分钟成为 TiDB Contributor 系列 | 添加內建函数</title>
      <link>https://pingcap.com/blog-cn/add-a-built-in-function/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/add-a-built-in-function/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后首先会经过 parser，从文本 parse 成为 AST（抽象语法树），通过 Query Optimizer 生成执行计划，得到一个可以执行的 plan，通过执行这个 plan 即可得到结果，这期间会涉及到如何获取 table 中的数据，如何对数据进行过滤、计算、排序、聚合、滤重以及如何对表达式进行求值。 对于一个 builtin 函数，比较重要的是进行语法解析以及如何求值。其中语法解析部分需要了解如何写 yacc 以及如何修改 TiDB 的词法解析器，较为繁琐，我们已经将这部分工作提前做好，大多数 builtin 函数的语法解析工作已经做完。 对 builtin 函数的求值需要在 TiDB 的表达式求值框架下完成，每个 builtin 函数被认为是一个表达式，用一个 ScalarFunction 来表示，每个 builtin 函数通过其函数名以及参数，获取对应的函数类型以及函数签名，然后通过函数签名进行求值。 总体而言，上述流程对于不熟悉 TiDB 的朋友而言比较复杂，我们对这部分做了些工作，将一些流程性、较为繁琐的工作做了统一处理，目前已经将大多数未实现的 buitlin 函数的语法解析以及寻找函数签名的工作完成，但是函数实现部分留空。换句话说，只要找到留空的函数实现，将其补充完整，即可作为一个 PR。
添加 builtin 函数整体流程  找到未实现的函数 在 TiDB 源码中的 expression 目录下搜索 errFunctionNotExists，即可找到所有未实现的函数，从中选择一个感兴趣的函数，比如 SHA2 函数：
func (b *builtinSHA2Sig) eval(row []types.Datum) (d types.Datum, err error) { return d, errFunctionNotExists.GenByArgs(&amp;#34;SHA2&amp;#34;) } 实现函数签名 接下来要做的事情就是实现 eval 方法，函数的功能请参考 MySQL 文档，具体的实现方法可以参考目前已经实现函数。</description>
    </item>
    
    <item>
      <title>Weekly update (March 06 ~ March 12, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories.
Added  Add context in exector: prepare for canceling execution.
 Support the KILL statement.
 Support string literal with in the national character set N&#39;literal&#39;.
 Check privilege when running create user statement.
 Add a session variable to prevent eager aggregation.
  Fixed  Clean up pending task when close executor: fix memory leak.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 41 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-11/</link>
      <pubDate>Sat, 11 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-11/</guid>
      <description>COISF 专场|PingCAP 第 41 期 NewSQL Meetup 2017-03-11 杨建军&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Raft 的优化</title>
      <link>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</link>
      <pubDate>Tue, 07 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</guid>
      <description>在分布式领域，为了保证数据的一致性，通常都会使用 Paxos 或者 Raft 来实现。但 Paxos 以其复杂难懂著称，相反 Raft 则是非常简单易懂，所以现在很多新兴的数据库都采用 Raft 作为其底层一致性算法，包括我们的 TiKV。
当然，Raft 虽然简单，但如果单纯的按照 Paper 的方式去实现，性能是不够的。所以还需要做很多的优化措施。本文假定用户已经熟悉并了解过 Raft 算法，所以对 Raft 不会做过多说明。
Simple Request Flow 这里首先介绍一下一次简单的 Raft 流程：
 Leader 收到 client 发送的 request。 Leader 将 request append 到自己的 log。 Leader 将对应的 log entry 发送给其他的 follower。 Leader 等待 follower 的结果，如果大多数节点提交了这个 log，则 apply。 Leader 将结果返回给 client。 Leader 继续处理下一次 request。  可以看到，上面的流程是一个典型的顺序操作，如果真的按照这样的方式来写，那性能是完全不行的。
Batch and Pipeline 首先可以做的就是 batch，大家知道，在很多情况下面，使用 batch 能明显提升性能，譬如对于 RocksDB 的写入来说，我们通常不会每次写入一个值，而是会用一个 WriteBatch 缓存一批修改，然后在整个写入。 对于 Raft 来说，Leader 可以一次收集多个 requests，然后一批发送给 Follower。当然，我们也需要有一个最大发送 size 来限制每次最多可以发送多少数据。</description>
    </item>
    
    <item>
      <title>Weekly update (February 27 ~ March 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-03-06-tidb-weekly/</link>
      <pubDate>Mon, 06 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-03-06-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 21 PRs in the TiDB repositories.
Added  Add metrics for related region count for a transaction.
 Record sql_mode in session context.
 Support Show Processlist.
 Add an empty Triggers table in information_schema database.
 Support ANSI_QUOTES sql_mode in parser.
 Support use wildcard as user hostname in grant statement.
 Support the MD5 builtin function.
 Support the SHA/SHA1 builtin function.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 40 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-03-04/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-03-04/</guid>
      <description>COISF 专场|PingCAP 第 40 期 NewSQL Meetup 2017-03-04 吴晓飞&amp;amp;韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiDB 的正确使用姿势</title>
      <link>https://pingcap.com/blog-cn/how-to-use-tidb/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-use-tidb/</guid>
      <description>最近这几个月，特别是 TiDB RC1 发布后，越来越多的用户已经开始测试起来，也有很多朋友已经在生产环境中使用，我们这边也陆续的收到了很多用户的测试和使用反馈。非常感谢各位小伙伴和早期用户的厚爱，而且看了这么多场景后，也总结出了一些 TiDB 的使用实践 (其实 Spanner 的最佳实践大部分在 TiDB 中也是适用的，MySQL 最佳实践也是），也是借着 Google Cloud Spanner 发布的东风，看了一下 Spanner 官方的一些最佳实践文档，写篇文章讲讲 TiDB 以及分布式关系型数据库的一些正确的使用姿势，当然，时代也在一直发展，TiDB 也在不停的进化，这篇文章基本上只代表近期的一些观察。
 首先谈谈 Schema 设计的一些比较好的经验。由于 TiDB 是一个分布式的数据库，可能在表结构设计的时候需要考虑的事情和传统的单机数据库不太一样，需要开发者能够带着「这个表的数据会分散在不同的机器上」这个前提，才能做更好的设计。
和 Spanner 一样，TiDB 中的一张表的行（Rows）是按照主键的字节序排序的（整数类型的主键我们会使用特定的编码使其字节序和按大小排序一致），即使在 CREATE TABLE 语句中不显式的创建主键，TiDB 也会分配一个隐式的。 有四点需要记住： 1. 按照字节序的顺序扫描的效率是比较高的； 2. 连续的行大概率会存储在同一台机器的邻近位置，每次批量的读取和写入的效率会高； 3. 索引是有序的（主键也是一种索引），一行的每一列的索引都会占用一个 KV Pair，比如，某个表除了主键有 3 个索引，那么在这个表中插入一行，对应在底层存储就是 4 个 KV Pairs 的写入：数据行以及 3 个索引行。 4. 一行的数据都是存在一个 KV Pair 中，不会被切分，这点和类 BigTable 的列式存储很不一样。
表的数据在 TiDB 内部会被底层存储 TiKV 切分成很多 64M 的 Region（对应 Spanner 的 Splits 的概念），每个 Region 里面存储的都是连续的行，Region 是 TiDB 进行数据调度的单位，随着一个 Region 的数据量越来越大和时间的推移，Region 会分裂/合并，或者移动到集群中不同的物理机上，使得整个集群能够水平扩展。</description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/blog/2017-03-01-rc2/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-03-01-rc2/</guid>
      <description>We have great efforts to improve the compatibility with MySQL, SQL query optimizer, system stability and performance in this version. What’s more, a new + of permission management is added and users can control data access rights in the same way of MySQL privilege management system.
TiDB:  Query optimizer
 Collect column/index statistics and use them in the query optimizer
 Optimize the correlated subquery
 Optimize the Cost Based Optimizer (CBO) framework</description>
    </item>
    
    <item>
      <title>Weekly update (February 19 ~ February 26, 2017)</title>
      <link>https://pingcap.com/weekly/2017-02-27-tidb-weekly/</link>
      <pubDate>Mon, 27 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-02-27-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 39 PRs in the TiDB repositories.
Added  Support Revoke statement.
 Add rules in parser and empty implementation for unsupported builtin functions: #2667, #2677, #2679
 Support wildcard chars in username or host in Grant statement.
 Add a context arggument for distsql/kv interface: We will use the context to cancel running jobs.
 Support Create Table ... Like statement.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 39 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-02-25/</link>
      <pubDate>Sat, 25 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-02-25/</guid>
      <description>COISF 专场|PingCAP 第 39 期 NewSQL Meetup 2017-02-25 郝立飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Spanner - CAP, TrueTime and Transaction</title>
      <link>https://pingcap.com/blog-cn/spanner-tangliu/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/spanner-tangliu/</guid>
      <description>最近非常关注的一件事情就是 Google Spanner Cloud 的发布，这应该算是 NewSQL 又一个里程碑的事件。NewSQL 的概念应该就是在 12 年 Google Spanner 以及 F1 的论文发表之后，才开始慢慢流行，然后就开始有企业尝试根据 paper 做自己的 NewSQL，譬如国外的 CockroachDB 以及国内我们 PingCAP。
Spanner 的论文在很早就发布了，国内也有很多中文翻译，这里笔者只是想聊聊自己对 Spanner 的理解，以及 Spanner 的一些关键技术的实现，以及跟我们自己的 TiDB 的相关对比。
CAP 在分布式领域，CAP 是一个完全绕不开的东西，大家应该早就非常熟悉，这里笔者只是简单的再次说明一下：
 C：一致性，也就是通常说的线性一致性，假设在 T 时刻写入了一个值，那么在 T 之后的读取一定要能读到这个最新的值。 A：完全 100% 的可用性，也就是无论系统发生任何故障，都仍然能对外提供服务。 P：网络分区容忍性。  在分布式环境下面，P 是铁定存在的，也就是只要我们有多台机器，那么网络隔离分区就一定不可避免，所以在设计系统的时候我们就要选择到底是设计的是 AP 系统还是 CP 系统，但实际上，我们只要深入理解下 CAP，就会发现其实有时候系统设计上面没必要这么纠结，主要表现在：
 网络分区出现的概率很低，所以我们没必要去刻意去忽略 C 或者 A。多数时候，应该是一个 CA 系统。 CAP 里面的 A 是 100% 的可用性，但实际上，我们只需要提供 high availability，也就是仅仅需要满足 99.99% 或者 99.999% 等几个 9 就可以了。  Spanner 是一个 CP + HA 系统，官方文档说的可用性是优于 5 个 9 ，稍微小于 6 个 9，也就是说，Spanner 在系统出现了大的故障的情况下面，大概 31s+ 的时间就能够恢复对外提供服务，这个时间是非常短暂的，远远比很多外部的系统更加稳定。然后鉴于 Google 强大的自建网络，P 很少发生，所以 Spanner 可以算是一个 CA 系统。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Lease Read</title>
      <link>https://pingcap.com/blog-cn/lease-read/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/lease-read/</guid>
      <description>Raft log read TiKV 是一个要保证线性一致性的分布式 KV 系统，所谓线性一致性，一个简单的例子就是在 t1 的时间我们写入了一个值，那么在 t1 之后，我们的读一定能读到这个值，不可能读到 t1 之前的值。
因为 Raft 本来就是一个为了实现分布式环境下面线性一致性的算法，所以我们可以通过 Raft 非常方便的实现线性 read，也就是将任何的读请求走一次 Raft log，等这个 log 提交之后，在 apply 的时候从状态机里面读取值，我们就一定能够保证这个读取到的值是满足线性要求的。
当然，大家知道，因为每次 read 都需要走 Raft 流程，所以性能是非常的低效的，所以大家通常都不会使用。
我们知道，在 Raft 里面，节点有三个状态，leader，candidate 和 follower，任何 Raft 的写入操作都必须经过 leader，只有 leader 将对应的 raft log 复制到 majority 的节点上面，我们才会认为这一次写入是成功的。所以我们可以认为，如果当前 leader 能确定一定是 leader，那么我们就可以直接在这个 leader 上面读取数据，因为对于 leader 来说，如果确认一个 log 已经提交到了大多数节点，在 t1 的时候 apply 写入到状态机，那么在 t1 之后后面的 read 就一定能读取到这个新写入的数据。
那么如何确认 leader 在处理这次 read 的时候一定是 leader 呢？在 Raft 论文里面，提到了两种方法。</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 38 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-02-18/</link>
      <pubDate>Sat, 18 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-02-18/</guid>
      <description>COISF 专场|PingCAP 第 38 期 NewSQL Meetup 2017-02-18 刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (February 06 ~ February 12, 2017)</title>
      <link>https://pingcap.com/weekly/2017-02-13-tidb-weekly/</link>
      <pubDate>Mon, 13 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-02-13-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 25 PRs in the TiDB repositories.
Added  Support basic privilege framework: #2423, #2557, #2603, #2607,
 Support ALTER [COLUMN] col_name SET DEFAULT statement.
 Validate column default value when creating table.
 Support ALTER TABLE ... DROP DEFAULT statement.
 Support changing default value and comment in alter table statement.
  Fixed  Fix build on i386.
 Fix output format of prometheus interval log.</description>
    </item>
    
    <item>
      <title>Weekly update (January 23 ~ February 05, 2017)</title>
      <link>https://pingcap.com/weekly/2017-02-05-tidb-weekly/</link>
      <pubDate>Sun, 05 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-02-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 43 PRs in the TiDB repositories.
Added  Support information_schema.table_constraints.
 Support the UTC_TIMESTAMP builtin function
 Increase transaction entry count limit.
 Add logs for expensive query and big transaction: 2536, 2545, 2546
  Fixed  Fix GC lifetime metrics.
 Fix primary key name parsing.
 Fix a bug of left outer semi join.
 Fix a bug of exists sub query.</description>
    </item>
    
    <item>
      <title>Weekly update (January 09 ~ January 22, 2017)</title>
      <link>https://pingcap.com/weekly/2017-01-24-tidb-weekly/</link>
      <pubDate>Tue, 24 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-01-24-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last two weeks, we landed 87 PRs in the TiDB repositories.
Added  Support statistic on index data
 Support file sort operator
 Add key prefix length limitation on index
 Support the TIMESTAMPDIFF built-in function.
 Support the CONV built-in function.
 Support the SUBSTR built-in function.
 Support the SIGN built-in function.
 Support the FROM_DAYS built-in function.
 Support the FIELD built-in function.</description>
    </item>
    
    <item>
      <title>TiKV 源码浅析 - PD Scheduler</title>
      <link>https://pingcap.com/blog-cn/pd-scheduler/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pd-scheduler/</guid>
      <description>在前面的文章里面，我们介绍了 PD 一些常用功能，以及它是如何跟 TiKV 进行交互的，这里，我们重点来介绍一下 PD 是如何调度 TiKV 的。
介绍 假设我们只有一个 TiKV，那么根本就无需调度了，因为数据只可能在这一台机器上面，client 也只可能跟这一个 TiKV 进行交互。但我们知道，在分布式存储领域，这样的情况不可能一直持续，因为数据量的增量一定会超过当前机器的物理存储极限，必然我们需要将一部分数据迁移到其他机器上面去。
在之前的文章里面，我们介绍过，TiKV 是通过 range 的方式将数据进行切分的。我们使用 Region 来表示一个数据 range，每个 Region 有多个副本 peer，通常为了安全，我们会使用至少三个副本。
最开始系统初始化的时候，我们只有一个 region，当数据量持续增大，超过了 Region 设置的最大 size（64MB） 阈值的时候，region 就会分裂，生成两个新的 region。region 是 PD 调度 TiKV 的基本单位。当我们新增加一个 TiKV 的时候，PD 就会将原来TiKV 里面的一些 Region 调度到这个新增的 TiKV 上面，这样就能保证整个数据均衡的分布在多个 TiKV 上面。因为一个 Region 通常是 64MB，其实将一个 Region 从一个 TiKV 移动到另一个 TiKV，数据量的变更其实不大，所以我们可以直接使用 Region 的数量来大概的做数据的平衡。譬如，现在假设有六个 TiKV，我们有一百个 region，每个 Region 三个副本 peer，总共三百个 Region peer，我们只要保证每个 TiKV 有五十个左右的 Region peer，就大概知道数据是平衡了。</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 37 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-01-14/</link>
      <pubDate>Sat, 14 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-01-14/</guid>
      <description>COISF 专场|PingCAP 第 37 期 NewSQL Meetup 2017-01-14 杨策&amp;amp;黄华超 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - Placement Driver</title>
      <link>https://pingcap.com/blog-cn/placement-driver/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/placement-driver/</guid>
      <description>介绍 Placement Driver (后续以 PD 简称) 是 TiDB 里面全局中心总控节点，它负责整个集群的调度，负责全局 ID 的生成，以及全局时间戳 TSO 的生成等。PD 还保存着整个集群 TiKV 的元信息，负责给 client 提供路由功能。
作为中心总控节点，PD 通过集成 etcd ，自动的支持 auto failover，无需担心单点故障问题。同时，PD 也通过 etcd 的 raft，保证了数据的强一致性，不用担心数据丢失的问题。
在架构上面，PD 所有的数据都是通过 TiKV 主动上报获知的。同时，PD 对整个 TiKV 集群的调度等操作，也只会在 TiKV 发送 heartbeat 命令的结果里面返回相关的命令，让 TiKV 自行去处理，而不是主动去给 TiKV 发命令。这样设计上面就非常简单，我们完全可以认为 PD 是一个无状态的服务（当然，PD 仍然会将一些信息持久化到 etcd），所有的操作都是被动触发，即使 PD 挂掉，新选出的 PD leader 也能立刻对外服务，无需考虑任何之前的中间状态。
初始化 PD 集成了 etcd，所以通常，我们需要启动至少三个副本，才能保证数据的安全。现阶段 PD 有集群启动方式，initial-cluster 的静态方式以及 join 的动态方式。
在继续之前，我们需要了解下 etcd 的端口，在 etcd 里面，默认要监听 2379 和 2380 两个端口。2379 主要是 etcd 用来处理外部请求用的，而 2380 则是 etcd peer 之间相互通信用的。</description>
    </item>
    
    <item>
      <title>Weekly update (January 02 ~ January 08, 2017)</title>
      <link>https://pingcap.com/weekly/2017-01-08-tidb-weekly/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-01-08-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 38 PRs in the TiDB repositories.
Added  Add nested loop join.
 Support the UNIX_TIMESTAMP built-in function.
 Support the INTERVAL built-in function.
 Support the FIND_IN_SET built-in function.
 Support the DATEDIFF built-in function.
 Enable pushing down IF expr to TiKV coprocessor
  Fixed  In prepared statement, limit and offset could be parameter marker.
 When creating table, index option could be a list.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 36 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2017-01-07/</link>
      <pubDate>Sat, 07 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2017-01-07/</guid>
      <description>COISF 专场|PingCAP 第 36 期 NewSQL Meetup 2017-01-07 蔡杰明&amp;amp;袁进辉 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>About the TiDB Source Code</title>
      <link>https://pingcap.com/blog/2017-01-06-about-the-tidb-source-code/</link>
      <pubDate>Fri, 06 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2017-01-06-about-the-tidb-source-code/</guid>
      <description>The target audience of this document is the contributors in the TiDB community. The document aims to help them understand the TiDB project. It covers the system architecture, the code structure, and the execution process.
Table of content  System architecture Overview of the code structure The protocol layer The SQL layer The optimizer The executor The distributed executor  System architecture As is shown in the architecture diagram, the TiDB Server is between the Load Balancer (or Application) and the storage engine layer at the bottom.</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - multi-raft 设计与实现</title>
      <link>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</link>
      <pubDate>Tue, 03 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</guid>
      <description>概述 本文档主要面向 TiKV 社区开发者，主要介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读文档之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本文档并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。
Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。
Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。
Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region 会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>Weekly update (December 26 ~ January 01, 2017)</title>
      <link>https://pingcap.com/weekly/2017-01-01-tidb-weekly/</link>
      <pubDate>Sun, 01 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2017-01-01-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 28 PRs in the TiDB repositories.
Added  Support the CHAR_LENGTH built-in function.
 Support the CRC32 built-in function.
 Support the LEAST built-in function.
  Fixed  Fix a bug in Add Column with invalid default value.
 Fix a bug about parsing string to float.
 Fix a bug when using int and uint as join key.
 Fix a bug in MySQL Protocol layer about prepared statement.</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - 如何使用 Raft</title>
      <link>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</guid>
      <description>本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本系列文章并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
 架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。 Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。 Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。 Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>Weekly update (December 19 ~ December 25, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-26-tidb-weekly/</guid>
      <description>New Release TiDB RC1 is released!
Weekly update in TiDB Last week, we landed 34 PRs in the TiDB repositories.
Added  Support the RPAD built-in function..
 Support the show keys from table from database statement.
  Fixed  Retry infinite times if the commit primary key times out.
 Do not push aggregation down to the memory tables.
 Fix a bug about the alter table statement.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 35 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-24/</link>
      <pubDate>Sat, 24 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-24/</guid>
      <description>COISF 专场|PingCAP 第 35 期 NewSQL Meetup 2016-12-24 张頔&amp;amp;黄梦龙 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/blog/2016-12-23-rc1/</link>
      <pubDate>Fri, 23 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-12-23-rc1/</guid>
      <description>The TiDB RC1 is now released. See the following updates in this release:
TiKV:  The write speed has been improved. The disk space usage is reduced. Hundreds of TBs of data can be supported.
 The stability is improved and TiKV can support a cluster with 200 nodes. Supports the Raw KV API and the Golang client.  Placement Driver (PD): + The scheduling strategy framework is optimized and now the strategy is more flexible and reasonable.</description>
    </item>
    
    <item>
      <title>Adding Built-in Functions</title>
      <link>https://pingcap.com/blog/2016-12-19-adding-built-in-function/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-12-19-adding-built-in-function/</guid>
      <description>This document describes how to add built-in functions to TiDB.
 Background The procedure to add a built-in function Example  Background How is the SQL statement executed in TiDB?
The SQL statement is parsed to an abstract syntax tree (AST) by the parser first and then uses the optimizer to generate an execution plan. The plan can then be executed to get the result. This process involves how to access the data in the table, and how to filter, calculate, sort, aggregate, and distinct the data, etc.</description>
    </item>
    
    <item>
      <title>Weekly update (December 12 ~ December 18, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-19-tidb-weekly/</link>
      <pubDate>Mon, 19 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-19-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 32 PRs in the TiDB repositories.
Added  Add the FlagIgnoreTruncate/FlagTruncateAsWarning flag to control the behavior of truncated errors.
 Add the prompt text flag.
 Add the rawkv metrics to profile the rawkv API performance.
 Add a comparable varint encoding/decoding method to make encoded data smaller.
 Support the timediff built-in function.
 Support the following built-in functions: ln(), log(), log2(), log10().</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 34 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-17/</link>
      <pubDate>Sat, 17 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-17/</guid>
      <description>COISF 专场|PingCAP 第 34 期 NewSQL Meetup 2016-12-17 覃左言&amp;amp;申砾 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Weekly update (December 05 ~ December 11, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-12-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 41 PRs in the TiDB repositories.
Added  Support the built-in function: str_to_date. 
 Support built-in function schema().
 Support pushing the case-when expression to TiKV.
 Support changing the type and name of a column.
 Add the `session_variablesandplugins` of memory table to infoschema.
 Make the union all operator run parallelly.
 Support explaining the union statement.
  Fixed  A bug that causes infinite loop.</description>
    </item>
    
    <item>
      <title>COISF 专场|PingCAP 第 33 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-10/</link>
      <pubDate>Sat, 10 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-10/</guid>
      <description>COISF 专场|PingCAP 第 33 期 NewSQL Meetup 2016-12-10 王康&amp;amp;李康 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型</description>
    </item>
    
    <item>
      <title>Subquery Optimization in TiDB</title>
      <link>https://pingcap.com/blog/2016-12-07-Subquery-Optimization-in-TiDB/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-12-07-Subquery-Optimization-in-TiDB/</guid>
      <description>MathJax.Hub.Config({ extensions: [&#34;tex2jax.js&#34;], jax: [&#34;input/TeX&#34;, &#34;output/HTML-CSS&#34;], tex2jax: { inlineMath: [ [&#39;$&#39;,&#39;$&#39;], [&#34;\\(&#34;,&#34;\\)&#34;] ], displayMath: [ [&#39;$$&#39;,&#39;$$&#39;], [&#34;\\[&#34;,&#34;\\]&#34;] ], processEscapes: true }, &#34;HTML-CSS&#34;: { availableFonts: [&#34;TeX&#34;] } });    Introduction to subqueries Subquery is a query within another SQL query. A common subquery is embedded within the FROM clause, for example：
SELECT ID FROM (SELECT * FROM SRC) AS T The subexpressions in the FROM clauses can be processed very well by the general SQL optimizers.</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 信心的毁灭与重建</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-3/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-3/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为下篇。
 -接中篇- ScyllaDB 有一个开源的东西，是专门用来给文件系统做 Failure Injection 的, 名字叫做 CharybdeFS。如果你想测试你的系统，就是文件系统在哪不断出问题，比如说写磁盘失败了，驱动程序分配内存失败了，文件已经存在等等，它都可以测模拟出来。
CharybdeFS: A new fault-injecting file system for software testing
Simulate the following errors:
 disk IO error (EIO) driver out of memory error (ENOMEM) file already exists (EEXIST) disk quota exceeded (EDQUOT)  再来看看 Cloudera，下图是整个 Cloudera 的一个 Failure Injection 的结构。
一边是 Tools，一边是它的整个的 Level 划分。比如说整个 Cluster， Cluster 上面有很多 Host，Host 上面又跑了各种 Service，整个系统主要用于测试 HDFS， HDFS 也是很努力的在做有效的测试。然后每个机器上部署一个 AgenTEST，就用来注射那些可能出现的错误。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——信心的毁灭与重建</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-07/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-07/</guid>
      <description></description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——信心的毁灭与重建</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-12-07/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-12-07/</guid>
      <description>ScyllaDB 有一个开源的东西，是专门用来给文件系统做 Failure Injection 的, 名字叫做 CharybdeFS。如果你想测试你的系统，就是文件系统在哪不断出问题，比如说写磁盘失败了，驱动程序分配内存失败了，文件已经存在等等，它都可以测模拟出来。
 CharybdeFS: A new fault-injecting file system for software testing
Simulate the following errors:
 disk IO error (EIO)
 driver out of memory error (ENOMEM)
 file already exists (EEXIST)
 disk quota exceeded (EDQUOT)
   再来看看 Cloudera，下图是整个 Cloudera 的一个 Failure Injection 的结构。
一边是 Tools，一边是它的整个的 Level 划分。比如说整个 Cluster， Cluster 上面有很多 Host，Host 上面又跑了各种 Service，整个系统主要用于测试 HDFS， HDFS 也是很努力的在做有效的测试。然后每个机器上部署一个 AgenTEST，就用来注射那些可能出现的错误。
看一下它们作用有多强大。
 Cloudera: Simulate the following errors:</description>
    </item>
    
    <item>
      <title>Weekly update (November 28 ~ December 04, 2016)</title>
      <link>https://pingcap.com/weekly/2016-12-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-12-05-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 48 PRs in the TiDB repositories and 6 PRs in the TiDB docs repositories.
Added  Support the built-in function: str_to_date. 
 Refactor the time structure: Introduce a TimeInternal interface to replace the go time representation.
 Add the raw Key-Value API  and make TiKV a raw Key-Value engine.
 Add a bench tool for the raw Key-Value API.</description>
    </item>
    
    <item>
      <title>【现场】COISF 专场 Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-12-03/</link>
      <pubDate>Sat, 03 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-12-03/</guid>
      <description>【现场】COISF 专场 Meetup 2016-12-03 COISF PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
COISF Meetup
今天是一期人数爆满的 Meetup。😊 作为 COISF 专场，感谢众多小伙伴与我们一起见证 COISF 的首次亮相。当然，
首场参与是一定会有福利滴。这一期，我们邀请到了一位女神级讲师&amp;ndash;
百度网页搜索部工程师
雷丽媛，为大家讲解
百度文件系统的架构设计；
另外，PingCAP 联合创始人崔秋也有出台，为大家深情
回顾 TiDB 的发展历程 :)
▌开场：COISF Opening Talk
在本环节中，PingCAP
Co-Founde
r 崔秋，百度搜索基础架构团队技术负责人颜世光，以及奇虎 360 基础架构组存储负责人陈宗志
共同为大家介绍了 COISF 的由来和使命，并对目前基金会内的顶级项目进行了简单介绍。
COISF（China Open Infrastructure Software Foundation ）：
中国开放基础软件基金会，其核心技术委员会由 PingCAP、百度、奇虎 360、小米（排名不分先后）等公司的基础软件项目团队组成，致力于促进和发展中国的新一代开源基础软件。目前基金会项目包括：Baidu/BFS、Baidu/Tera、PingCAP/TiDB、PingCAP/TiKV、Qihoo360/Zeppelin 等。
我们认为，一方面开源是软件开发的未来，能更好地促进创新与合作；另一方面未来几十年中国的基础软件必将蓬勃发展，并在世界范围内扮演重要角色。但当前国内有很多优秀的开源软件, 因为文化和语言的藩篱没能融入西方社区, 无法获得足够的关注与支持，导致发展缓慢。我们通过建设中国统一的基础软件开发社区，甄选优秀的项目加入，集中优势资源促进这些项目的快速发展与成熟。
COISF 的使命是：促进中国下一代开源基础软件生态系统的发展。
▌Topic 1
：百度文件系统－面向实时应用的分布式文件系统</description>
    </item>
    
    <item>
      <title>Weekly update (November 21 ~ November 27, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-28-tidb-weekly/</link>
      <pubDate>Mon, 28 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-28-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 44 PRs in the TiDB repositories and 3 PRs in the TiDB docs repositories.
Added  Support creating anonymous index.
 Add the mailing list for TiDB users.
 Support the show events syntax.
  Fixed  Enlarge the Time To Live (TTL)for large transactions.
 Parse float literal using the decimal parser.
 Prevent panic for malformed packets.
 Fix the behavior in the aggregate operator: for the select a, c from t groupby t.</description>
    </item>
    
    <item>
      <title>PingCAP 第 31 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-26/</link>
      <pubDate>Sat, 26 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-26/</guid>
      <description>PingCAP 第 31 期 NewSQL Meetup 2016-11-26 黄华超&amp;amp;邓栓 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 31 期 Meetup，
主题是黄华超分
享的《PD 的实现和演进》以及邓栓分享的《从容器和微服务的发展看基础架构变迁》。
▌Topic 1：
PD 的实现和演进
Lecturer：
黄华超，PingCAP 工程师，曾就职于微信、好赞科技，从事分布式存储相关工作，现负责 PingCAP PD 研发工作。
Content：
本次分享首先介绍了 PD 在 TiDB 集群的作用，以及集群是如何动态扩容缩容的。然后分别讲解了 PD 的各个功能是如何实现的，其中，着重分享了集群调度的相关设计和思考，以及新的标签调度功能。
▌Topic 2
：从容器和微服务的发展看基础架构变迁
Lecturer：
邓栓（Tennix），Rust 中文社区管理员，PingCAP SRE 工程师，负责 TiDB 与 Kubernetes 一体化整合部署方案。
Content：
近些年来容器和微服务的概念变得特别火热，越来越多的互联网公司开始尝试将以前的单体服务迁移到微服务，并且在实践中使用容器来部署服务，容器和微服务也催生了 DevOps，CaaS，Immutable infrastructure，Service orchestration 等概念。今天主要从容器和微服务角度谈了新技术应用和实践给开发者带来了哪些便利和挑战，基础架构发生了哪些改变，并尝试探讨了未来的应用服务会是什么样的架构。</description>
    </item>
    
    <item>
      <title>Percolator 和 TiDB 事务算法</title>
      <link>https://pingcap.com/blog-cn/percolator-and-txn/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/percolator-and-txn/</guid>
      <description>本文先概括的讲一下 Google Percolator 的大致流程。Percolator 是 Google 的上一代分布式事务解决方案，构建在 BigTable 之上，在 Google 内部 用于网页索引更新的业务，原始的论文在此。原理比较简单，总体来说就是一个经过优化的二阶段提交的实现，进行了一个二级锁的优化。TiDB 的事务模型沿用了 Percolator 的事务模型。 总体的流程如下：
读写事务 1) 事务提交前，在客户端 buffer 所有的 update/delete 操作。 2) Prewrite 阶段:
首先在所有行的写操作中选出一个作为 primary，其他的为 secondaries。
PrewritePrimary: 对 primaryRow 写入 L 列(上锁)，L 列中记录本次事务的开始时间戳。写入 L 列前会检查:
 是否已经有别的客户端已经上锁 (Locking)。 是否在本次事务开始时间之后，检查 W 列，是否有更新 [startTs, +Inf) 的写操作已经提交 (Conflict)。  在这两种种情况下会返回事务冲突。否则，就成功上锁。将行的内容写入 row 中，时间戳设置为 startTs。
将 primaryRow 的锁上好了以后，进行 secondaries 的 prewrite 流程:
 类似 primaryRow 的上锁流程，只不过锁的内容为事务开始时间及 primaryRow 的 Lock 的信息。 检查的事项同 primaryRow 的一致。  当锁成功写入后，写入 row，时间戳设置为 startTs。</description>
    </item>
    
    <item>
      <title>TiKV 的 MVCC（Multi-Version Concurrency Control）机制</title>
      <link>https://pingcap.com/blog-cn/mvcc-in-tikv/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mvcc-in-tikv/</guid>
      <description>并发控制简介 事务隔离在数据库系统中有着非常重要的作用，因为对于用户来说数据库必须提供这样一个“假象”：当前只有这么一个用户连接到了数据库中，这样可以减轻应用层的开发难度。但是，对于数据库系统来说，因为同一时间可能会存在很多用户连接，那么许多并发问题，比如数据竞争（data race），就必须解决。在这样的背景下，数据库管理系统（简称 DBMS）就必须保证并发操作产生的结果是安全的，通过可串行化（serializability）来保证。
虽然 Serilizability 是一个非常棒的概念，但是很难能够有效的实现。一个经典的方法就是使用一种两段锁（2PL）。通过 2PL，DBMS 可以维护读写锁来保证可能产生冲突的事务按照一个良好的次序（well-defined) 执行，这样就可以保证 Serializability。但是，这种通过锁的方式也有一些缺点：
 读锁和写锁会相互阻滞（block）。 大部分事务都是只读（read-only）的，所以从事务序列（transaction-ordering）的角度来看是无害的。如果使用基于锁的隔离机制，而且如果有一段很长的读事务的话，在这段时间内这个对象就无法被改写，后面的事务就会被阻塞直到这个事务完成。这种机制对于并发性能来说影响很大。  *多版本并发控制（Multi-Version Concurrency Control, 以下简称 MVCC）*以一种优雅的方式来解决这个问题。在 MVCC 中，每当想要更改或者删除某个数据对象时，DBMS 不会在原地去删除或这修改这个已有的数据对象本身，而是创建一个该数据对象的新的版本，这样的话同时并发的读取操作仍旧可以读取老版本的数据，而写操作就可以同时进行。这个模式的好处在于，可以让读取操作不再阻塞，事实上根本就不需要锁。这是一种非常诱人的特型，以至于在很多主流的数据库中都采用了 MVCC 的实现，比如说 PostgreSQL，Oracle，Microsoft SQL Server 等。
TiKV 中的 MVCC 让我们深入到 TiKV 中的 MVCC，了解 MVCC 在 TiKV 中是如何实现的。
Timestamp Oracle(TSO) 因为TiKV 是一个分布式的储存系统，它需要一个全球性的授时服务，下文都称作 TSO（Timestamp Oracle），来分配一个单调递增的时间戳。 这样的功能在 TiKV 中是由 PD 提供的，在 Google 的 Spanner 中是由多个原子钟和 GPS 来提供的。
Storage 从源码结构上来看，想要深入理解 TiKV 中的 MVCC 部分，src/storage 是一个非常好的入手点。 Storage 是实际上接受外部命令的结构体。
pub struct Storage { engine: Box&amp;lt;Engine&amp;gt;, sendch: SendCh&amp;lt;Msg&amp;gt;, handle: Arc&amp;lt;Mutex&amp;lt;StorageHandle&amp;gt;&amp;gt;, } impl Storage { pub fn start(&amp;amp;mut self, config: &amp;amp;Config) -&amp;gt; Result&amp;lt;()&amp;gt; { let mut handle = self.</description>
    </item>
    
    <item>
      <title>Weekly update (November 14 ~ November 20, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-21-tidb-weekly/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-21-tidb-weekly/</guid>
      <description>Weekly update in TiDB Last week, we landed 30 PRs in the TiDB repositories, 3 PRs in the TiDB docs repositories.
Added  Add a session variable to skip unique constraint check: This could be used when migrating data.
 More metrics for statement counter.
  Fixed  Use reserved keywords as the table/column name.
 Add missing comments in the show table status result.
 Fix a bug that gets duplicate auto_inc ID after truncating table.</description>
    </item>
    
    <item>
      <title>解析 TiDB 在线数据同步工具 Syncer</title>
      <link>https://pingcap.com/blog-cn/tidb-syncer/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-syncer/</guid>
      <description>TiDB 是一个完全分布式的关系型数据库，从诞生的第一天起，我们就想让它来兼容 MySQL 语法，希望让原有的 MySQL 用户 (不管是单机的 MySQL，还是多机的 MySQL Sharding) 都可以在基本不修改代码的情况下，除了可以保留原有的 SQL 和 ACID 事务之外，还可以享受到分布式带来的高并发，高吞吐和 MPP 的高性能。
对于用户来说，简单易用是他们试用的最基本要求，得益于社区和 PingCAP 小伙伴们的努力，我们提供基于 Binary 和 基于 Kubernetes 的两种不同的一键部署方案来让用户可以在几分钟就可以部署起来一个分布式的 TiDB 集群，从而快速地进行体验。 当然，对于用户来说，最好的体验方式就是从原有的 MySQL 数据库同步一份数据镜像到 TiDB 来进行对于对比测试，不仅简单直观，而且也足够有说服力。实际上，我们已经提供了一整套的工具来辅助用户在线做数据同步，具体的可以参考我们之前的一篇文章:TiDB 作为 MySQL Slave 实现实时数据同步, 这里就不再展开了。后来有很多社区的朋友特别想了解其中关键的 Syncer 组件的技术实现细节，于是就有了这篇文章。
首先我们看下 Syncer 的整体架构图, 对于 Syncer 的作用和定位有一个直观的印象。
从整体的架构可以看到，Syncer 主要是通过把自己注册为一个 MySQL Slave 的方式，和 MySQL Master 进行通信，然后不断读取 MySQL Binlog，进行 Binlog Event 解析，规则过滤和数据同步。从工程的复杂度上来看，相对来说还是非常简单的，相对麻烦的地方主要是 Binlog Event 解析和各种异常处理，也是容易掉坑的地方。
为了完整地解释 Syncer 的在线同步实现，我们需要有一些额外的内容需要了解。
###MySQL Replication 我们先看看 MySQL 原生的 Replication 复制方案，其实原理上也很简单：</description>
    </item>
    
    <item>
      <title>通过 raft 的 leader lease 来解决集群脑裂时的 stale read 问题</title>
      <link>https://pingcap.com/blog-cn/stale-read/</link>
      <pubDate>Sun, 20 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/stale-read/</guid>
      <description>问题： 当 raft group 发生脑裂的情况下，老的 raft leader 可能在一段时间内并不知道新的 leader 已经被选举出来，这时候客户端在老的 leader 上可能会读取出陈旧的数据（stale read）。 比如，我们假想一个拥有 5 个节点的 raft group:
其中 Node 5 是当前的 raft leader，当出现网络分区时，在 Node 5 的 raft lease 任期还没结束的一段时间内，Node 5 仍然认为自己是当前 term 的 leader，但是此时，另外一边分区已经在新的 term 中选出了新的 leader。
如果此时，客户端在新的 leader 上更新了某个值 x，此时是可以更新成功的（因为还是可以复制到多数派）。但是在分区的另一端，此时一个客户端去读取 x 的值，Node 5 还会返回老的值，这样就发生了 stale read。
解决方案
引入一个新的概念, region leader。region leader 是一个逻辑上的概念, 任意时刻对于某一个 region 来说, 一定只拥有一个 region leader, 每个 region leader 在任期之内尝试每隔 t 时间间隔, 在 raft group 内部更新一下 region leader 的 lease.</description>
    </item>
    
    <item>
      <title>PingCAP 第 30 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-19/</link>
      <pubDate>Sat, 19 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-19/</guid>
      <description>PingCAP 第 30 期 NewSQL Meetup 2016-11-19 刘锦龙&amp;amp;刘寅 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 30 期 Meetup，
主题是墨迹天气气象算法负责人刘锦龙分享的《深度学习，众包数据与短时临近预报系统》以及刘寅分享的《谈谈 TiDB-Binlog 的设计》。
▌Topic 1：深度学习，众包数据与短时临近预报系统
Lecturer：
刘锦龙，北大理论物理博士，墨迹天气气象算法负责人，负责墨迹相关天气预测算法的研发工作，主要方向为机器学习和深度学习。
Content：
深入介绍如何将深度学习的最新技术用于革新传统气象预测的一些研究和应用，以及如何处理从用户获取的众包反馈数据并进而改进天气预报的精准度。
▌Topic 2：
谈谈 TiDB-Binlog 的设计
Lecturer：
刘寅，PingCAP engineer，现负责 TiDB 商业产品开发和自动化运维。
Content：
随着
TiDB
的不断稳定和完善
，
我们也逐步开发了很多
TiDB
周边工具。今天主要介绍了
TiDB-Binlog
设计上的一些考量和实现细节。
TiDB-Binlog 可
实时记录
TiDB
的一切数据变化
，
可以用来做集群的实时备份和恢复
，</description>
    </item>
    
    <item>
      <title>MVCC in TiKV</title>
      <link>https://pingcap.com/blog/2016-11-17-mvcc-in-tikv/</link>
      <pubDate>Thu, 17 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-11-17-mvcc-in-tikv/</guid>
      <description>MVCC Introduction to concurrency control Transaction isolation is important for database management system. Because database should provide an illusion that the user is the only one who connects to the database, which greatly simplifies application development. But, the concurrency controlling problems like data races must be resolved since there will be a lot of connections to the database. Due to this background, the database management system (DBMS) ensures that the resulting concurrent access patterns are safe, ideally by serializablity.</description>
    </item>
    
    <item>
      <title>MPP and SMP in TiDB</title>
      <link>https://pingcap.com/blog-cn/mpp-smp-tidb/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mpp-smp-tidb/</guid>
      <description>今天主要是想把我们 TiDB 做 SQL 性能优化的一些经验和一些思考，就此跟大家探讨一下。题目写的比较大，但是内容还是比较简单。我们做 TiDB 的 SQL 层时，一开始做的很简单，就是通过最简单的 KV 接口(Get/Set/Seek)去存数据、取数据，做一些非常直白、简单的计算。然而后来我们发现，这个方案在性能上不可接受，可能行不通，我们就重新思考了这个事情。
TiDB 的目标是做一个 NewSQL 的 database ，什么是 NewSQL？从 Wikipedia 上我们看到 NewSQL 的定义『NewSQL is a class of modern relational database management systems that seek to provide the same scalable performance of NoSQL systems for online transaction processing (OLTP) read-write workloads while still maintaining the ACID guarantees of a traditional database system.』。首先NewSQL Database 需要能存储海量数据，这点就像一些 NoSQL 数据库一样。然后，能够提供事务的功能。所以 NewSQL 中的计算，主要有两个特点。第一个，就是数据是海量的，这跟 MySQL 传统数据有可能不一样，他们当然可以通过一些 sharding 的方式来进行处理，但是 sharding 之后会损失，比如说你不能跨节点做 Join，没有跨节点事务等。二是，在海量数据情况下，我们还需要对数据进行随时的取用，因为数据存在那，你算不出来就是对用户没有价值、没有意义的，所以我们需要在海量数据的前提下，能够随时把它计算出来。</description>
    </item>
    
    <item>
      <title>MPP and SMP in TiDB</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-11-15/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-11-15/</guid>
      <description>本篇文章整理自第 21 期 PingCAP NewSQL Meetup 上申砾分享的《MPP and SMP in TiDB》内容。干货很多，全文阅读预计需要 20 分钟。
 今天主要是想把我们 TiDB 做 SQL 性能优化的一些经验和一些思考，就此跟大家探讨一下。题目写的比较大，但是内容还是比较简单。我们做 TiDB 的 SQL 层时，一开始做的很简单，就是通过最简单的 KV 接口(Get/Set/Seek)去存数据、取数据，做一些非常直白、简单的计算。然而后来我们发现，这个方案在性能上不可接受，可能行不通，我们就重新思考了这个事情。
TiDB 的目标是做一个 NewSQL 的 database ，什么是 NewSQL？从 Wikipedia 上我们看到 NewSQL 的定义『NewSQL is a class of modern relational database management systems that seek to provide the same scalable performance of NoSQL systems for online transaction processing (OLTP) read-write workloads while still maintaining the ACID guarantees of a traditional database system.</description>
    </item>
    
    <item>
      <title>Travelling Back in Time and Reclaiming the Lost Treasures</title>
      <link>https://pingcap.com/blog/2016-11-15-Travelling-Back-in-Time-and-Reclaiming-the-Lost-Treasures/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-11-15-Travelling-Back-in-Time-and-Reclaiming-the-Lost-Treasures/</guid>
      <description>About the History Read feature in TiDB Data is the core and is a matter of life and death for every business. So ensuring the data safety is the top priority of every database. From a macro point of view, the safety of data is not only about whether a database is stable enough that no data is lost, but also about whether a sufficient and convenient solution is in place when data is lost because of the business or human errors, for example, to solve the anti-cheat problem in the game industry or to meet the audit requirements in the financing business.</description>
    </item>
    
    <item>
      <title>Weekly update (November 07 ~ November 13, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-14-tidb-weekly/</link>
      <pubDate>Mon, 14 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-14-tidb-weekly/</guid>
      <description>Last week, we landed 25 PRs in the TiDB repositories and 5 PRs in the TiDB docs repositories.
Weekly update in TiDB Added  Support the Alter table modify column statement.
 Support the Drop view statement: parsed but ignored.
 Add metrics for the transaction size.
 A tool for testing the SQL performance.
  Fixed  A bug in the show create table statement.
 A few bugs in optimizer: #1962, #1963, #1966, #1975, #1977.</description>
    </item>
    
    <item>
      <title>PingCAP 第 29 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-12/</link>
      <pubDate>Sat, 12 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-12/</guid>
      <description>PingCAP 第 29 期 NewSQL Meetup 2016-11-12 王振涛&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 29 期 Meetup，主题是映客服务端架构师王振涛分享的《映客直播服务端架构优化之路》以及张金鹏分享的《MySQL 与 TiDB 的事务机制》。
▌ ****
T
o
pic 1：映客直播服务端架构优化之路
Lecture：
王振涛，南开大学计算机硕士毕业，曾先后供职于腾讯、搜狗等互联网公司，拥有多年的服务端研发、面向服务体系结构设计经验，专注于解决海量数据存储和计算带来的分布式、高并发、强一致性等技术难题和挑战。2016 年初加入映客直播，担任服务端架构师，主要负责映客基础平台架构设计、评审和用户体系的研发工作，经历了映客业务快速发展、构建高可用大容量基础服务体系的过程，对分布式计算、微服务、分布式数据库架构、高可用高并发系统设计等方面都有较深刻的理解和实践经验。
Content：
1、介绍了映客服务端架构演进历程；
2、关于服务端技术选型的探索和思考；
3、移动直播典型应用场景分析。
▌ ****
T
o
pi
c 2：MySQL 与 TiDB 的事务机制
Lecture：
张金鹏，PingCAP 核心成员，前百度资深研发工程师／京东数据库专家，《MariaDB 原理和实现》作者。
Content：
在 MySQL 的 InnoDB 存储引擎中，进行写操作时，会将数据修改前的状态纪录在 Undo Log 中，一旦事务，失败利用 Undo Log 来进行回滚，保证事务的原子性。同时 InnoDB 利用 Undo Log 实现了多版本并发控制，InnoDB 的读取操作是不加锁的，事务只能读取到事务开始时已提交的纪录。由于 MySQL 是单机数据库，所有很方便的纪录所有活跃的事务 ID，Purge 线程根据当前活跃的事务情况来定期清理 Undo Log 中过期版本的数据。InnoDB 的事务支持 read uncommitted、read committed、repeatable read、serializable 四种事务隔离级别，InnoDB 通过 next-key lock 来解决 repeatable read 隔离级别下的幻读现象。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 错误注入</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-2/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-2/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为中篇。
 -接上篇- 当然测试可能会让你代码变得没有那么漂亮，举个例子：
这是知名的 Kubernetes 的代码，就是说它有一个 DaemonSetcontroller，这 controller 里面注入了三个测试点，比如这个地方注入了一个 handler ，你可以认为所有的注入都是 interface。比如说你写一个简单的 1+1=2 的程序，假设我们写一个计算器，这个计算器的功能就是求和，那这就很难注入错误。所以你必须要在你正确的代码里面去注入测试逻辑。再比如别人 call 你的这个 add 的 function，然后你是不是有一个 error？这个 error 的问题是它可能永远不会返回一个 error，所以你必须要人肉的注进去，然后看应用程序是不是正确的行为。说完了加法，再说我们做一个除法。除法大家知道可能有处理异常，那上面是不是能正常处理呢？上面没有，上面写着一个比如说 6 ÷ 3，然后写了一个 test，coverage 100%，但是一个除零异常，系统就崩掉了，所以这时候就需要去注入错误。大名鼎鼎的 Kubernetes 为了测试各种异常逻辑也采用类似的方式，这个结构体不算长，大概是十几个成员，然后里面就注入了三个点，可以在里面注入错误。
那么在设计 TiDB 的时候，我们当时是怎么考虑 test 这个事情的？首先一个百万级的 test 不可能由人肉来写，也就是说你如果重新定义一个自己的所谓的 SQL 语法，或者一个 query language，那这个时候你需要构建百万级的 test，即使全公司去写，写个两年都不够，所以这个事情显然是不靠谱的。但是除非说我的 query language 特别简单，比如像 MongoDB 早期的那种，那我一个“大于多少”的这种，或者 equal 这种条件查询特别简单的，那你确实是不需要构建这种百万级的 test。但是如果做一个 SQL 的 database 的话，那是需要构建这种非常非常复杂的 test 的。这时候这个 test 又不能全公司的人写个两年，对吧？所以有什么好办法呢？MySQL 兼容的各种系统都是可以用来 test 的，所以我们当时兼容 MySQL 协议，那意味着我们能够取得大量的 MySQL test。不知道有没有人统计过 MySQL 有多少个 test，产品级的 test 很吓人的，千万级。然后还有很多 ORM， 支持 MySQL 的各种应用都有自己的测试。大家知道，每个语言都会 build 自己的 ORM，然后甚至是一个语言的 ORM 都有好几个。比如说对于 MySQL 可能有排第一的、排第二的，那我们可以把这些全拿过来用来测试我们的系统。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——错误注入</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-10/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-10/</guid>
      <description></description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——错误注入</title>
      <link>https://pingcap.com/meetup/memoir/meetup-20160-11-10/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-20160-11-10/</guid>
      <description>当然测试可能会让你代码变得没有那么漂亮，举个例子：
这是知名的 Kubernetes 的代码，就是说它有一个 DaemonSetcontroller，这 controller 里面注入了三个测试点，比如这个地方注入了一个 handler ，你可以认为所有的注入都是 interface。比如说你写一个简单的 1+1=2 的程序，假设我们写一个计算器，这个计算器的功能就是求和，那这就很难注入错误。所以你必须要在你正确的代码里面去注入测试逻辑。再比如别人 call 你的这个 add 的 function，然后你是不是有一个 error？这个 error 的问题是它可能永远不会返回一个 error，所以你必须要人肉的注进去，然后看应用程序是不是正确的行为。说完了加法，再说我们做一个除法。除法大家知道可能有处理异常，那上面是不是能正常处理呢？上面没有，上面写着一个比如说 6 ÷ 3，然后写了一个 test，coverage 100%，但是一个除零异常，系统就崩掉了，所以这时候就需要去注入错误。大名鼎鼎的 Kubernetes 为了测试各种异常逻辑也采用类似的方式，这个结构体不算长，大概是十几个成员，然后里面就注入了三个点，可以在里面注入错误。
那么在设计 TiDB 的时候，我们当时是怎么考虑 test 这个事情的？首先一个百万级的 test 不可能由人肉来写，也就是说你如果重新定义一个自己的所谓的 SQL 语法，或者一个 query language，那这个时候你需要构建百万级的 test，即使全公司去写，写个两年都不够，所以这个事情显然是不靠谱的。但是除非说我的 query language 特别简单，比如像 MongoDB 早期的那种，那我一个“大于多少”的这种，或者 equal 这种条件查询特别简单的，那你确实是不需要构建这种百万级的 test。但是如果做一个 SQL 的 database 的话，那是需要构建这种非常非常复杂的 test 的。这时候这个 test 又不能全公司的人写个两年，对吧？所以有什么好办法呢？MySQL 兼容的各种系统都是可以用来 test 的，所以我们当时兼容 MySQL 协议，那意味着我们能够取得大量的 MySQL test。不知道有没有人统计过 MySQL 有多少个 test，产品级的 test 很吓人的，千万级。然后还有很多 ORM， 支持 MySQL 的各种应用都有自己的测试。大家知道，每个语言都会 build 自己的 ORM，然后甚至是一个语言的 ORM 都有好几个。比如说对于 MySQL 可能有排第一的、排第二的，那我们可以把这些全拿过来用来测试我们的系统。</description>
    </item>
    
    <item>
      <title>A Deep Dive into TiKV</title>
      <link>https://pingcap.com/blog/2016-11-09-Deep-Dive-into-TiKV/</link>
      <pubDate>Wed, 09 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-11-09-Deep-Dive-into-TiKV/</guid>
      <description>Table of Content  About TiKV Architecture Protocol Raft Placement Driver (PD) Transaction Coprocessor Key processes analysis  Key-Value operation Membership Change Split   About TiKV TiKV (The pronunciation is: /&amp;lsquo;taɪkeɪvi:/ tai-K-V, etymology: titanium) is a distributed Key-Value database which is based on the design of Google Spanner, F1, and HBase, but it is much simpler without dependency on any distributed file system.
Architecture  Placement Driver (PD): PD is the brain of the TiKV system which manages the metadata about Nodes, Stores, Regions mapping, and makes decisions for data placement and load balancing.</description>
    </item>
    
    <item>
      <title>Weekly update (October 31 ~ November 06, 2016)</title>
      <link>https://pingcap.com/weekly/2016-11-07-tidb-weekly/</link>
      <pubDate>Mon, 07 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-11-07-tidb-weekly/</guid>
      <description>Weekly update (October 31 ~ November 06, 2016) Last week, we landed 42 PRs in the TiDB repositories and 29 PRs in the TiKV repositories.
New release TiDB Beta 4 Weekly update in TiDB Added  The aggregation info to the explain statement.
 Support the show processlist syntax. TiDB supports mydumper now.
 Support the show create database statement.
 Support the buildin function from_unixtime.
 Push down the aggregation operator to the position before join.</description>
    </item>
    
    <item>
      <title>PingCAP 第 28 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-11-05/</link>
      <pubDate>Sat, 05 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-11-05/</guid>
      <description>PingCAP 第 28 期 NewSQL Meetup 2016-11-05 时延军&amp;amp;韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第
28 期 Meetup，主题是 TalkingData 数据经理时延军分享的《Spark 架构设计要点剖析》以及韩飞分享的《Performing group-by before join》。
▌ ****
T
opi
c 1：Spark 架构设计要点剖析
Lecture：
时延军，TalkingData 数据经理，负责领域工程数据平台架构和研发，曾在 COMODO 中国负责基础数据平台建设，在车语传媒考拉 FM 负责后端数据平台架构（支持离线+实时分析处理）。推崇工程师文化，热爱开源，乐于分享，兴趣广泛，熟悉大数据技术生态，擅长软件系统架构、分布式计算系统设计。
Content：
1、RDD 特性，RDD 是如何抽象数据集的；
2、详解 Spark 基本架构；
3、Spark 内部核心组件及其交互；
4、逻辑执行计划与物理执行计划；
5、Spark 资源管理与任务调度。
▌ ****
T
opic
2：Performing group-by before join</description>
    </item>
    
    <item>
      <title>TiDB 作为 MySQL Slave 实现实时数据同步</title>
      <link>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</guid>
      <description>由于 TiDB 本身兼容绝大多数的 MySQL 语法，所以对于绝大多数业务来说，最安全的切换数据库方式就是将 TiDB 作为现有数据库的从库接在主 MySQL 库的后方，这样对业务方实现完全没有侵入性下使用 TiDB 对现有的业务进行备份，应对未来数据量或者并发量增长带来的单点故障风险，如需上线 TiDB，也只需要简单的将业务的主 MySQL 地址指向 TiDB 即可。
下面我们详细介绍了如何将 MySQL 的数据迁移到 TiDB，并将 TiDB 作为 MySQL 的 Slave 进行数据同步。
这里我们假定 MySQL 以及 TiDB 服务信息如下:
+------------------+-------------+----------------------------------------+ | Name | Address | Port | User | Password | +------------------+-------------+----------------------------------------+ | MySQL | 127.0.0.1 | 3306 | root | | | TiDB | 127.0.0.1 | 4000 | root | | +------------------+-------------+--------+-----------+-------------------+ 使用 checker 进行 Schema 检查 在迁移之前，我们可以使用 TiDB 的 checker 工具，checker 是我们开发的一个小工具，用于检测目标 MySQL 库中的表的表结构是否支持无缝的迁移到 TiDB，TiDB 支持绝大多数的 MySQL 常用的原生数据类型，所以大多数情况 checker 的返回应该是 ok。如果 check 某个 table schema 失败，表明 TiDB 当前并不支持，我们不能对该 table 里面的数据进行迁移。checker 包含在 TiDB 工具集里面，我们可以直接下载。</description>
    </item>
    
    <item>
      <title>How to write a good commit message</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-11-01-1/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-11-01-1/</guid>
      <description>Why a good commit message matters  Speed up the review process.
 Help the future maintaners establish the content of the change. The future maintaner could be you yourself several months later.
 Help to build a good release notes.
  Why a good formatted commit message matters  Allow filtering commits
For example, you can get new features in this release:
$ git log HEAD &amp;ndash;grep feature</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 理念</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-1/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-1/</guid>
      <description>本话题系列文章整理自 PingCAP NewSQL Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为上篇。
 今天主要是介绍分布式系统测试。对于 PingCAP 目前的现状来说，我们是觉得做好分布式系统测试比做一个分布式系统更难。就是你把它写出来不是最难的，把它测好才是最难的。大家肯定会觉得有这么夸张吗？那我们先从一个最简单的、每个人都会写的 Hello world 开始。
A simple “Hello world” is a miracle We should walk through all of the bugs in:
 Compiler Linker VM (maybe) OS  其实这个 Hello world 能够每次都正确运行已经是一个奇迹了，为什么呢？首先，编译器得没 bug，链接器得没 bug ；然后我们可能跑在 VM 上，那 VM 还得没 bug；并且 Hello world 那还有一个 syscall，那我们还得保证操作系统没有 bug；到这还不算吧，我们还得要硬件没有 bug。所以一个最简单程序它能正常运行起来，我们要穿越巨长的一条路径，然后这个路径里面所有的东西都不能出问题，我们才能看到一个最简单的 Hello world。
但是分布式系统里面呢，就更加复杂了。比如大家现在用的很典型的微服务。假设你提供了一个微服务，然后在微服务提供的功能就是输出一个 Hello world ，然后让别人来 Call。
A RPC “Hello world” is a miracle We should walk through all of the bugs in:</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿——理念</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-11-01/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-11-01/</guid>
      <description>本话题系列文章整理自 PingCAP NewSQL Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为上篇。
 今天主要是介绍分布式系统测试。对于 PingCAP 目前的现状来说，我们是觉得做好分布式系统测试比做一个分布式系统更难。就是你把它写出来不是最难的，把它测好才是最难的。大家肯定会觉得有这么夸张吗？那我们先从一个最简单的、每个人都会写的 Hello world 开始。
 A simple “Hello world” is a miracle
We should walk through all of the bugs in:
 Compiler Linker VM (maybe) OS   其实这个 Hello world 能够每次都正确运行已经是一个奇迹了，为什么呢？首先，编译器得没 bug，链接器得没 bug ；然后我们可能跑在 VM 上，那 VM 还得没 bug；并且 Hello world 那还有一个 syscall，那我们还得保证操作系统没有 bug；到这还不算吧，我们还得要硬件没有 bug。所以一个最简单程序它能正常运行起来，我们要穿越巨长的一条路径，然后这个路径里面所有的东西都不能出问题，我们才能看到一个最简单的 Hello world。
但是分布式系统里面呢，就更加复杂了。比如大家现在用的很典型的微服务。假设你提供了一个微服务，然后在微服务提供的功能就是输出一个 Hello world ，然后让别人来 Call。
 A RPC “Hello world” is a miracle</description>
    </item>
    
    <item>
      <title>Weekly update (October 24 ~ October 30, 2016)</title>
      <link>https://pingcap.com/weekly/2016-10-31-tidb-weekly/</link>
      <pubDate>Mon, 31 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-10-31-tidb-weekly/</guid>
      <description>Weekly update (October 24 ~ October 30, 2016) Last week, we landed 24 PRs in the TiDB repositories and 28 PRs in the TiKV repositories.
Notable changes to TiDB  Support coalesce/case when pushing down on local storage。
 Support showing indexes in the table syntax.
 Split eval.go into some smaller files to make code cleaner.
 Fix a bug about truncating data.
 Fix the mysql version number format.</description>
    </item>
    
    <item>
      <title>PingCAP 第 27 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-10-29/</link>
      <pubDate>Sat, 29 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-10-29/</guid>
      <description>PingCAP 第 27 期 NewSQL Meetup 2016-10-29 付力力&amp;amp;刘寅 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 27 期 Meetup，主题是
神策数
据联合创始人&amp;amp;首席架构师付力力分享的《Impala 在用户行为分析中的应用与优化》以及刘寅分享的《How we build CI/CD for TiDB at scale》。
▌ ****
T
opic 1
：
Impala 在用户行为分析中的应用与优化
多冷的天都不能阻止技术童鞋们浓厚的求知欲 :-D
Lecture：
付力力，神策数据联合创始人&amp;amp;首席架构师，曾任百度、豌豆荚资深研发工程师，熟悉大规模数据处理、数据仓库、OLAP 数据库等领域。
Content：
 介绍用户行为分析的典型应用场景；
 简单介绍 Impala 的架构和实现；
 使用 Impala 进行用户行为分析的基本做法；
 针对特定场景对 Impala 进行的一些优化和改造。</description>
    </item>
    
    <item>
      <title>Weekly update (October 17 ~ October 23, 2016)</title>
      <link>https://pingcap.com/weekly/2016-10-24-tidb-weekly/</link>
      <pubDate>Mon, 24 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-10-24-tidb-weekly/</guid>
      <description>Weekly update (October 17 ~ October 23, 2016) Last week, we landed 30 PRs in the TiDB repositories and 26 PRs in the TiKV repositories.
Notable changes to TiDB  Set the concurrency for the SQL executor using the Set statement
 Convert the Limit+Sort operator to the TopN operator on local storage
 Fix the gotouinue leak problem
 Support the logic/bitwise operator on local storage
 Support creating user without password</description>
    </item>
    
    <item>
      <title>PingCAP 第 26 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-10-22/</link>
      <pubDate>Sat, 22 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-10-22/</guid>
      <description>PingCAP 第 26 期 NewSQL Meetup 2016-10-22 张成远&amp;amp;刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 26 期 Meetup，主题是
开源项目 speedy 作者
张成远分享的《京东分布式数据库实践》以及刘奇分享的《深度探索分布式系统测试》。 我司 CEO 亲自出台，现场不时传来三观碎一地的声音
┑(￣Д ￣)┍
另外，本周初次试水直播 (✿◡‿◡)
▌ ****
T
opic 1
：
京东分布式数据库实践
Lecture：
张成远，《Mariadb 原理与实现》作者，开源项目 speedy 作者。目前就职于京东数据库系统研发团队，负责京东分布式数据库系统架构与研发工作，主导了京东分布式数据库系统在公司的落地及大规模推广。擅长高性能服务器开发，擅长分布式数据库/存储/缓存等大规模分布式系统架构。
Content：
 介绍京东分布式数据库的设计与实现；
 介绍去 oracle 的发展历程以及遇到的一些坑；
 如何做到高效的运维监控等。
  ▌ ****
T</description>
    </item>
    
    <item>
      <title>Building a Reliable Large-Scale Distributed Database - Principles and Practice</title>
      <link>https://pingcap.com/blog-cn/talk-principles-practice/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-principles-practice/</guid>
      <description>大家好，我叫申砾，是 PingCAP Tech Leader，负责 TiDB 技术相关的工作。我曾就职网易有道、360 搜索，主要在做垂直搜索相关的事情，现在主要关注分布式计算/存储领域。过去的一年半时间我在 PingCAP 做分布式关系数据库 TiDB。目前我们的整个项目已经开源了大概一年时间，获得了不少关注。在 Github 上 Star 数量超过 5k，并且 Contributor 数量为 50+，拥有一个活跃的社区，在国内和国际上都有一定的知名度。 今天主要想和大家分享一下我们在做一款开源的分布式数据库产品过程中得到的一些经验和体会，包括技术上、产品上以及开源社区方面的内容，不会涉及太多技术上的细节。
数据库现状 近年来，随着移动互联网、物联网、人工智能等技术的兴起，我们已经进入了一个信息爆炸的大数据时代，需要处理和分析的数据越来越多，这些数据如何保存、如何应用是一个重要的问题。
传统的 SQL 数据库一般通过中间件、分库分表等方案获得 Scale 的能力。但是这些方案仍然很难做到对应用透明且保证数据均匀分布，同时也无法支持一致性的跨节点事务、JOIN 等操作。在进行扩容的时候往往需要人工介入，随着集群规模的增大，维护和扩展的复杂度呈指数级上升。
以 Google 的 BigTable 论文为开端，涌现出了一大批 NoSQL 方案。这些方案致力于解决扩展性，而牺牲一致性。如果采用 NoSQL 方案替换原有关系型数据库，往往要涉及大规模的业务重构，这相当于将数据库层的计算逻辑复杂度转嫁给业务层，同时还要损失掉事务等特性。
以上两种方案都没有完美地解决高可用的问题，跨机房多活、故障恢复、扩容经常都需要繁重的人工介入。
最近几年，人们希望有一种既有 SQL/NoSQL 的优点，又能避免他们的不足的新型数据库，于是提出了 NewSQL 的概念。Google 发布的 Spanner/F1，算是第一个真正在大规模业务上验证过的分布式数据库，向业界证明了 NewSQL 这条道路的正确性。TiDB 作为 Google Spanner/F1 的开源实现，正是业界盼望已久的 NewSQL 开源数据库。
什么是 NewSQL 并不是所有号称 NewSQL 的数据库都是 NewSQL。我们认为作为 NewSQL 数据库需要有下面几点特性：
首先是 Scale。这点上我想大家都深有体会，不管什么数据解决方案，最基本的要求就是能有足够的能力，保存用户所有的数据。
第二是事务。ACID Transaction，这个东西如果业务不需要，就感觉不到；一旦你的业务有这种需求，就能体会到它的重要性了。事实证明这个需求是广泛存在的，Google 的 BigTable 没有提供事务，结果内部很多业务都有需求，于是各个组造了一堆轮子，Jeff Dean 看不下去，出来说他最大的错误就是没有给 BigTable 提供事务。</description>
    </item>
    
    <item>
      <title>回到过去，找回遗失的珍宝 - TiDB 的历史读功能</title>
      <link>https://pingcap.com/blog-cn/time-travel/</link>
      <pubDate>Wed, 19 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/time-travel/</guid>
      <description>数据作为业务的核心，关系着整个业务的生死，所以对于数据库来说，数据的安全性是放在首位的，从宏观角度来看，安全性不仅仅在于的数据库本身足够稳定不会主动的丢失数据，有的时候更是对业务本身甚至人为失误造成损失是否有足够且便捷的应对方案，例如在游戏行业中经常遇到的反作弊(作弊玩家回档)问题，对于金融业务的审计需求等等，如果在数据库层面上提供相关机制，会让业务开发的工作量和复杂度减少很多。
传统的方案会定期备份数据，几天一次，甚至一天一次，把数据全量备份。当意外发生的时候，可以用来还原。但是用备份数据还原，代价还是非常大的，所有备份时间点后的数据都会丢失，你绝对不希望走到这一步。另外全量备份带来的存储和计算资源的额外开销，对于企业来说也是一笔不小的成本。
可是这种事情是无法完全避免的，我们所有的人都会犯错。对于一个快速迭代的业务，应用的代码不可能做到全面充分的测试，很可能因为应用逻辑的 Bug 导致数据写错，或者被恶意用户找到 bug，当你发现问题时，可以立即把应用回滚到旧版本，但是写错的数据却会一直留在数据库里。
出现这种问题的时候，你该怎么办？你只知道有些数据不对了，但是对的数据是什么，你不知道。如果能回到过去，找回之前的数据该多好。
TiDB 针对这样的需求和场景支持历史版本的读取，所以可以将错误的版本之前的数据取出来，将损失降到最低。
如何使用 TiDB 的历史读功能 使用这个功能非常简单，只需要执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;2016-10-10 09:30:11.123&amp;quot;
这个 session variable 的名字是 TiDB 里定义的 tidb_snapshot, 值是一个时间的字符串，精确到毫秒，执行了这个语句之后，之后这个客户端发出的所有读请求，读到的都是这个时间点看到的数据，这时是不能进行写操作的，因为历史是无法改变的。如果想退出历史读模式，读取最新数据，只需要再次执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;&amp;quot;
把 tidb_snapshot 设置成空字符串就可以了。
即使在那个历史时间点后，发生了 Schema 更改也没有关系，TiDB 会使用当时的 Schema 执行 SQL 请求。
TiDB 历史读功能和其他数据库的比较 这个功能 MySQL 并不支持，但是在其他的数据库里，比如 Oracle, PostgreSQL 里有类似的功能，叫做历史表(Temporial Table)，是一个SQL 标准。使用的方法是需要你用特殊的建表语法，额外创建一张历史表，历史表比原表多了两个系统定义的字段，代表有效时间，这多出的两个字段是系统维护的。当原表更新数据的时候，系统会把旧版本数据插入到历史表里，当你查询历史数据时，需要用一个特殊的语法指定历史时间，得到需要的结果。
TiDB 和其他数据库的历史表功能相比，主要有以下两个优势：
1，系统默认支持
如果不是默认的行为，我们通常不会特意去建一张历史表，到真正需要用到的时候，你会发现历史表没有创建。
2，使用方便
不需要额外建一张表，不需要用特殊的语法查询。
3，全局视角，而不是以表为单位
TiDB 即使执行了 Drop Table, Drop Database 这样的操作，也可以读到旧的数据。</description>
    </item>
    
    <item>
      <title>How we build TiDB</title>
      <link>https://pingcap.com/blog/2016-10-17-how-we-build-tidb/</link>
      <pubDate>Mon, 17 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/2016-10-17-how-we-build-tidb/</guid>
      <description>This is the speech Max Liu gave at Percona Live Open Source Database Conference 2016. 
The slides are here.
 Speaker introduction Why another database? What to build? How to design?  The principles or the philosophy  Disaster recovery Easy to use The community and ecosystem  Loose coupling – the logical architecture The alternatives  How to develop  The architecture TiKV core technologies  TiKV software stack Placement Driver Raft MVCC Transaction  TiDB core technologies  Mapping table data to Key-Value store Predicate push-down Schema changes   How to test?</description>
    </item>
    
    <item>
      <title>Weekly update (October 01 ~ October 16, 2016)</title>
      <link>https://pingcap.com/weekly/2016-10-17-tidb-weekly/</link>
      <pubDate>Mon, 17 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-10-17-tidb-weekly/</guid>
      <description>Weekly update (October 01 ~ October 16, 2016) Last week, we landed 27 PRs in the TiDB repositories and 32 PRs in the TiKV repositories.
Notable changes to TiDB  Support projection elimination so that the executor can run faster when it is not necessary to have a projection layer.
 Write DDL binlog to file.
 Convert sort and limit to top-n in the query planning phrase.
 Support reading history data even if the schema changes.</description>
    </item>
    
    <item>
      <title>PingCAP 第 25 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-10-15/</link>
      <pubDate>Sat, 15 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-10-15/</guid>
      <description>PingCAP 第 25 期 NewSQL Meetup 2016-10-15 武毅&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 25 期 Meetup，顶着帝都的大雾霾，依然来了很多小伙伴。这一次我们有换新场地噢，但不变的是分享内容依然满满干货。本周的主题分别是
百分点
集团高级架构师武毅分享的《分布式数据处理在个性化系统的应用》以及张金鹏分享的《TiKV 性能优化》。
▌ ****
T
opic 1
：
分布式数据处理在个性化系统的应用
Lecture：
武毅，现任百分点集团高级架构师，负责大数据平台基础架构的设计与研发，曾参与个性化推荐系统等多个大型系统的设计和开发。Linux 爱好者，活跃于 GitHub，Ubuntu 等社区，重点关注分布式技术，平台技术。
Content：
相信大家也都在各自的领域用到过不同的分布式存储／计算开源工具，本周我们分享了一些在运营个性化系统时使用分布式存储／计算工具遇到的坑和经验。
▌ ****
T
opic 2
：
TiKV 性能优化
Content：
RocksDB 的 Column Families 之间会共享 WAL，但是又有各自的 memtables 和 sst files，共享 WAL 使得实现跨 CF 的 atomic 操作变成可能，不同 CF 的 memtables 和 sst files 是分离开的，这样我们可以将不同类型的数据分别存放在不同的 CF 内，根据数据的性质给 CF 定制不同配置，使数据的写入和访问达到最佳状态。</description>
    </item>
    
    <item>
      <title>How do we build TiDB</title>
      <link>https://pingcap.com/blog-cn/how-do-we-build-tidb/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-do-we-build-tidb/</guid>
      <description>首先我们聊聊 Database 的历史，在已经有这么多种数据库的背景下我们为什么要创建另外一个数据库；以及说一下现在方案遇到的困境，说一下 Google Spanner 和 F1，TiKV 和 TiDB，说一下架构的事情，在这里我们会重点聊一下 TiKV。因为我们产品的很多特性是 TiKV 提供的，比如说跨数据中心的复制，Transaction，auto-scale。
再聊一下为什么 TiKV 用 Raft 能实现所有这些重要的特性，以及 scale，MVCC 和事务模型。东西非常多，我今天不太可能把里面的技术细节都描述得特别细，因为几乎每一个话题都可以找到一篇或者是多篇论文。但讲完之后我还在这边，所以详细的技术问题大家可以单独来找我聊。
后面再说一下我们现在遇到的窘境，就是大家常规遇到的分布式方案有哪些问题，比如 MySQL Sharding。我们创建了无数 MySQL Proxy，比如官方的 MySQL proxy，Youtube 的 Vitess，淘宝的 Cobar、TDDL,以及基于 Cobar 的 MyCAT，金山的 Kingshard，360 的 Atlas，京东的 JProxy，我在豌豆荚也写了一个。可以说，随便一个大公司都会造一个MySQL Sharding的方案。
为什么我们要创建另外一个数据库？ 昨天晚上我还跟一个同学聊到，基于 MySQL 的方案它的天花板在哪里，它的天花板特别明显。有一个思路是能不能通过 MySQL 的 server 把 InnoDB 变成一个分布式数据库，听起来这个方案很完美，但是很快就会遇到天花板。因为 MySQL 生成的执行计划是个单机的，它认为整个计划的 cost 也是单机的，我读取一行和读取下一行之间的开销是很小的，比如迭代 next row 可以立刻拿到下一行。实际上在一个分布式系统里面，这是不一定的。
另外，你把数据都拿回来计算这个太慢了，很多时候我们需要把我们的 expression 或者计算过程等等运算推下去，向上返回一个最终的计算结果，这个一定要用分布式的 plan，前面控制执行计划的节点，它必须要理解下面是分布式的东西，才能生成最好的 plan，这样才能实现最高的执行效率。
比如说你做一个 sum，你是一条条拿回来加，还是让一堆机器一起算，最后给我一个结果。 例如我有 100 亿条数据分布在 10 台机器上，并行在这 10 台 机器我可能只拿到 10 个结果，如果把所有的数据每一条都拿回来，这就太慢了，完全丧失了分布式的价值。聊到 MySQL 想实现分布式，另外一个实现分布式的方案是什么，就是 Proxy。但是 Proxy 本身的天花板在那里，就是它不支持分布式的 transaction，它不支持跨节点的 join，它无法理解复杂的 plan，一个复杂的 plan 打到 Proxy 上面，Proxy 就傻了，我到底应该往哪一个节点上转发呢，如果我涉及到 subquery sql 怎么办？所以这个天花板是瞬间会到，在传统模型下面的修改，很快会达不到我们的要求。</description>
    </item>
    
    <item>
      <title>Weekly update (September 26 ~ September 30, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-30-tidb-weekly/</link>
      <pubDate>Fri, 30 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-30-tidb-weekly/</guid>
      <description>Weekly update (September 26 ~ September 30, 2016) Last week, we landed 17 PRs in the TiDB repositories and 13 PRs in the TiKV repositories.
Notable changes to TiDB  Make the GC alive time configurable so that users can keep the deleted data as long as they want. Add the metrics for all kinds of statements to provide more information for insights. Improve the kv package test coverage. Record the processed row count during DDL so that users can track the progress of DDL.</description>
    </item>
    
    <item>
      <title>Weekly update (September 19 ~ September 25, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-26-tidb-weekly/</link>
      <pubDate>Mon, 26 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-26-tidb-weekly/</guid>
      <description>Weekly update (September 19 ~ September 25, 2016) Last week, we landed 20 PRs in the TiDB repositories and 24 PRs in the TiKV repositories.
Notable changes to TiDB  Support DML binlog. Support reading the history data. Add more metrics to distsql, DDL, and store. Replace the vendor tool with glide. Improve test coverage. Code cleanup. Improve the test code by splitting a big test file into smaller files.</description>
    </item>
    
    <item>
      <title>PingCAP 第 24 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-09-24/</link>
      <pubDate>Sat, 24 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-09-24/</guid>
      <description>PingCAP 第 24 期 NewSQL Meetup 2016-09-24 杜川&amp;amp;杨哲 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 24 期 Meetup，主题是阿里云 ODPS 研发工程师杜川分享的《LLVM 简介及其在大规模 OLAP 中的应用》以及来自小米云平台的杨哲分享的《阻塞访问数据库的相关问题》。
▌ ****
T
opic 1
：LLVM 简介及其在大规模 OLAP 中的应用
Lecture：
杜川，阿里云 ODPS 研发工程师，分布式数据库爱好者，重点关注 SQL 运行时优化以及 Code Generation 技术。
Content：
LLVM 是一个开源的编译器框架及生态链，已在工业界得到广泛的应用（著名的 Clang 编译器就是基于LLVM实现的）。因其前后端分离，模块化等优势，近年来被引入数据库领域，作为 JIT Code Generation 的工具，并吸引了越来越多的关注。本次分享介绍了 LLVM，及其在大规模 OLAP 中的应用。
▌ ****</description>
    </item>
    
    <item>
      <title>Weekly update (September 12 ~ September 18, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-19-tidb-weekly/</link>
      <pubDate>Mon, 19 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-19-tidb-weekly/</guid>
      <description>Weekly update (September 12 ~ September 18, 2016) Last week, we landed 18 PRs in the TiDB repositories and 26 PRs in the TiKV repositories.
Notable changes to TiDB  Add the Prometheus metrics and support push. Support the streaming aggregation operator. Rename xapi to distsql to improve readability. Add git hash to the TiDB server status API. Improve test coverage in the abstract syntax tree (AST). Enable the division operator for the distributed SQL statements.</description>
    </item>
    
    <item>
      <title>Weekly update (September 05 ~ September 11, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-12-tidb-weekly/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-12-tidb-weekly/</guid>
      <description>Weekly update (September 05 ~ September 11, 2016) Last week, we landed 20 PRs in the TiDB repositories and 32 PRs in the TiKV repositories..
Notable changes to TiDB  Support mydumper Use MySQL standard error code in the DDL execution results Use heap sort operator to handle the statements with Limit and Orderby Add support for the CLIENT_CONNECT_ATTRS Add the constant propagation support to the SQL optimizer Optimize the index scan executor to improve the performance Optimize the distributed SQL API protocol to improve the performance Fix several bugs.</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：分布式数据库模式与反模式</title>
      <link>https://pingcap.com/blog-cn/talk-tidb-pattern/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-tidb-pattern/</guid>
      <description>我叫黄东旭，是 PingCAP 的联合创始人兼 CTO，也是本场论坛的主持人。我原来在 MSRA，后来到了网易、豌豆荚。跟在座的大部分数据分析师不太一样的是，我是一个数据库开发，虽然是 CTO，但是还在写代码。
同时，我也是一些用的比较广泛的分布式的开源软件的作者。比如说我们做的 TiDB、TiKV 这些大型的分布式关系型数据库的项目。
我们现在正在做一个 OLTP 的数据库，主要 focus 在大数据的关系型数据库的存储和可扩展性，还有关系的模型，以及在线交易型数据库上的应用。
所以，今天整个数据库的模式和反模式，我都会围绕着如何在一个海量的并发，海量的数据存储的容量上，去做在线实时的数据库业务的一些模式来讲。并从数据库的开发者角度，来为大家分享怎样写出更加适合数据库的一些程序。
基础软件的发展趋势 一开始我先简单介绍一下，现在我认为的一些基础软件上的发展趋势。
开源 第一点，开源是一个非常大的趋势。大家可以看到一些比较著名的基础软件，基本都是开源的，比如 Docker，比如 k8s。甚至在互联网公司里面用的非常多的软件，像 MySQL、Hadoop 等这种新一代的大数据处理的数据库等基础软件，也大多是开源的。其实这背后的逻辑非常简单：在未来其实你很难去将你所有的技术软件都用闭源, 因为开源会慢慢组成一个生态，而并不是被某一个公司绑定住。比如国家经常说去 IOE，为什么？很大的原因就是基本上你的业务是被基础软件绑死的，这个其实是不太好的一个事情。而且现在跟过去二十年前不一样，无论是开源软件的质量，还是社区的迭代速度，都已经是今非昔比，所以基本上开源再也不是低质低量的代名词，在互联网公司已经被验证很多次了。
分布式 第二，分布式会渐渐成为主流的趋势。这是为什么？这个其实也很好理解，因为随着数据量越来越大，大家可以看到，随着现在的硬件发展，我感觉摩尔定律有渐渐失效的趋势。所以单个节点的计算资源或者计算能力，它的增长速度是远比数据的增长速度要慢的。在这种情况下，你要完成业务，存储数据，要应对这么大的并发，只有一种办法就是横向的扩展。横向的扩展，分布式基本是唯一的出路。scale-up 和 scale-out 这两个选择其实我是坚定的站在 scale-out 这边。当然传统的关系数据库都会说我现在用的 Oracle，IBM DB2，他们现在还是在走 scale-up 的路线，但是未来我觉得 scale-out 的方向会渐渐成为主流。 碎片化
碎片化 第三，就是整个基础软件碎片化。现在看上去会越来越严重。但是回想在十年前、二十年前，大家在写程序的时候，我上面一层业务，下面一层数据库。但是现在你会发现，随着可以给你选择的东西越来越多，可以给你在开源社区里面能用到的组件越来越多，业务越来越复杂，你会发现，像缓存有一个单独的软件，比如 redis，队列又有很多可以选择的，比如说 zeromq, rabbitmq, celery 各种各样的队列；数据库有 NoSQL、HBase，关系型数据库有 MySQL 、PG 等各种各样的基础软件都可以选。但是就没有一个非常好东西能够完全解决自己的问题。所以这是一个碎片化的现状。
微服务 第四，是微服务的模式兴起。其实这个也是最近两年在软件架构领域非常火的一个概念。这个概念的背后思想，其实也是跟当年的 SOA 是一脉相承的。就是说一个大的软件项目，其实是非常难去 handle 复杂度的，当你业务变得越来越大以后，维护成本和开发成本会随着项目的代码量呈指数级别上升的。所以现在比较流行的就是，把各个业务之间拆的非常细，然后互相之间尽量做到无状态，整个系统的复杂度可以控制，是由很多比较简单的小的组件组合在一起，来对外提供服务的。
这个服务看上去非常美妙，一会儿会说有什么问题。最典型的问题就是，当你的上层业务都拆成无状态的小服务以后，你会发现原有的逻辑需要有状态的存储服务的时候你是没法拆的。我所有的业务都分成一小块，每一小块都是自己的数据库或者数据存储。比如说一个简单的 case，我每一个小部分都需要依赖同一个用户信息服务，这个信息服务会变成整个系统的一个状态集中的点，如果这个点没有办法做弹性扩展或者容量扩展的话，就会变成整个系统很致命的单点。
所以现在整个基础软件的现状，特别在互联网行业是非常典型的几个大的趋势。我觉得大概传统行业跟互联网行业整合，应该在三到五年，这么一个时间。所以互联网行业遇到的今天，可能就是传统行业，或者其他的行业会遇到的明天。所以，通过现在整个互联网里面，在数据存储、数据架构方面的一些比较新的思想，我们就能知道如何去做这个程序的设计，应对明天数据的量级。
现有存储系统的痛点 其实今天主要的内容是讲存储系统，存储系统现在有哪些痛点？其实我觉得在座的各位应该也都能切身的体会到。
弹性扩展 首先，大数据量级下你如何实现弹性扩展？因为我们今天主要讨论的是 OLTP ，是在线的存储服务，并不是离线分析的服务。所以在线的存储服务，它其实要做到的可用性、一致性，是要比离线的分析业务强得多的。但是在这种情况下，你们怎样做到业务无感知的弹性扩展，你的数据怎么很好的满足现有的高并发、大吞吐，还有数据容量的方案。
可用性 第二，在分布式的存储系统下，你的应用的可用性到底是如何去定义，如何去保证？其实这个也很好理解，因为在大规模的分布式系统里面，任何一个节点，任何一个数据中心或者支架都有可能出现硬件的故障，软件的故障，各种各样的故障，但这个时候你很多业务是并没有办法停止，或者并没有办法去容忍 Down time 的。所以在一个新的环境之下，你如何对你系统的可用性做定义和保证，这是一个新的课题。一会儿我会讲到最新的研究方向和成果。</description>
    </item>
    
    <item>
      <title>PingCAP 第 23 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-09-10/</link>
      <pubDate>Sat, 10 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-09-10/</guid>
      <description>PingCAP 第 23 期 NewSQL Meetup 2016-09-10 金坤&amp;amp;黄华超 PingCAP PingCAP
PingCAP
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 Ping
CAP 第 23 期 Meetup，主题是金坤分享的《How to write a good commit message》以及黄华超分享的《QuorumKV：微信分布式 KV 存储系统》。
【T
opic 1】
How to write a good commit message
Content：
This talk about writing good commit messages aims to act as the beginning of a series of talks about writing quality technical content.</description>
    </item>
    
    <item>
      <title>Weekly update (August 29 ~ September 04, 2016)</title>
      <link>https://pingcap.com/weekly/2016-09-05-tidb-weekly/</link>
      <pubDate>Mon, 05 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-09-05-tidb-weekly/</guid>
      <description>Weekly update (August 29 ~ September 04, 2016) Last week, we landed 29 PRs in the TiDB repositories and 24 PRs in the TiKV repositories.
Notable changes to TiDB  Support the unhex and the ceiling/ceil functions Improve the Parser to handle \r\n. Solve the potential concurrency issues Support Load Data Use the Pipeline model to filter data through indexes to improve the performance Improve the code to reduce memory allocation and improve the performance Fix several bugs.</description>
    </item>
    
    <item>
      <title>PingCAP 第 22 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-09-03/</link>
      <pubDate>Sat, 03 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-09-03/</guid>
      <description>PingCAP 第 22 期 NewSQL Meetup 2016-09-03 宋昭&amp;amp;张帅 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 22 期 Meetup，主题是
360 基础架构组研发工程师
宋昭
分享的《360 开发的大容量 redis -pika》以及 美团云工程师
张帅
分享的《分布式对象存储系统设计介绍》。
▌ ****
T
opic 1：36
0 开发的大容量 redis -pika
Lecture：
宋昭，360 基础架构组研发工程师。专注于分布式存储领域，目前负责 360 开源项目 pika 相关的设计和开发工作。
Content：
目前 pika 在 360 内部大量使用，有 300 多实例，主要解决大容量的 redis（400G,800G）场景；在外部，被微博、美团、万达电商、garena、apus 等使用于线上核心系统中。本次分享主要介绍 pika 的系统设计和实现。</description>
    </item>
    
    <item>
      <title>TiKV 事务模型概览，Google Spanner 开源实现</title>
      <link>https://pingcap.com/blog-cn/tidb-transaction-model/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-transaction-model/</guid>
      <description>随着时代的发展，应用和数据的规模越来越大。然而在这个一切都可以水平扩展的时代，你会发现，大多数应用的最下层的关系型数据库，竟然难以找到一个优雅易用的水平扩展解决方案，一直以来不得不依赖静态 Sharding ，牺牲掉事务，然后在业务层各种 Workarounds。作为后端开发者应该深有体会。
层出不穷的 NoSQL 看似解决了数据水平扩展的问题，但是由于跨行事务的缺失和接口的局限，在很多业务中落地还是需要付出很多代价的。最近 Google 基础设施的神人 Jeff Dean 在一次采访中回顾自己作为工程师最大的后悔是什么的问题时提到，他最后悔的事情是没有在 BigTable 中加入跨行事务模型，以至于后来各种各样的团队尝试在 BigTable 上不停的造事务的轮子，但其实这个特性应该是由 BigTable 提供。同样的观点也在他后来的论文中反复提到过。
Google 2012 年在 OSDI 上发表了 Spanner，作为 BigTable 的下一代产品，最主要的特性就是支持跨行事务和在分布式场景上实现 Serializable 的事务隔离级别。我们在2015年底从零开始按照论文做 Spanner 的开源实现 TiKV，于近期开源，和 Spanner 一样，也是一个支持分布式事务和水平扩展的 KV 数据库。一个分布式数据库涉及的技术面非常广泛，今天我们主要探讨的是 TiKV 的 MVCC（多版本并发控制） 和 Transaction 实现。
MVCC 其实并不是一个老的概念了，在传统的单机关系型数据库使用 MVCC 技术来规避大量的悲观锁的使用，提高并发事务的读写性能。值得注意的是 MVCC 只是一个思想，并不是某个特定的实现，它表示每条记录都有多个版本的，互相不影响，以一个 kv 数据库为例从逻辑上的一行的表示就并不是
Record := {key, value} 而是
Record := {key, value, version} 支持分布式 MVCC 在 KV 系统中比较著名的应该是在 BigTable。在 TiKV 中我们的整个事务模型是构建在一个分布式 MVCC 的基础之上：
可以看到，整个 TiKV 的底层本地存储是依赖了 RocksDB，RocksDB 是一个单机的嵌入式 KV 数据库，是一个 LSM Tree的实现，是 Facebook 基于 LevelDB 的修改版本，其特点是写入性能特别好，数据存储是有序的 KV Pairs，对于有序 key 的迭代的场景访问效率较高。</description>
    </item>
    
    <item>
      <title>Weekly update (August 22 ~ August 28, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-29-tidb-weekly/</link>
      <pubDate>Mon, 29 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-29-tidb-weekly/</guid>
      <description>Weekly update (August 22 ~ August 28, 2016) Last week, we landed 26 PRs in the TiDB repositories and 26 PRs in the TiKV repositories.
Notable changes to TiDB  Support the MySQL SetOption Command and Multiple Statements. Support filter push-down for the Time/Decimal type. Support converting OuterJoin to InnerJoin by using Null Reject. Support multiple-thread Hash Join. Support Garbage Collector. Optimize the code to improve the Performance. Fix several bugs.</description>
    </item>
    
    <item>
      <title>PingCAP 第 21 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-27/</link>
      <pubDate>Sat, 27 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-27/</guid>
      <description>PingCAP 第 21 期 NewSQL Meetup 2016-08-27 韩飞&amp;amp;申砾 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 21 期 Meetup，主题是韩飞分享的《An Introduction to Join-Reorder in TiDB》以及申砾分享的《MPP and SMP in TiDB》。
▌ ****
Topic 1
：
An Introduction to Join-Reorder in TiDB
Content：
本次分享详细介绍了 TiDB 中 Join-Reorder 的流程。包括 Join-Reorder 的动机，outer-join 的 reorder 局限性和解决办法。为了解决某些 outer join re-association 的问题，我们可以引入的新算子 Generalized outerJoin。最后介绍了通过为 Join Query 建立 Query Graph 进行启发式搜索和动态规划的</description>
    </item>
    
    <item>
      <title>Weekly update (August 13 ~ August 21, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-22-tidb-weekly/</link>
      <pubDate>Mon, 22 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-22-tidb-weekly/</guid>
      <description>Weekly update (August 13 ~ August 21, 2016) Last week, we landed 26 PRs in the TiDB repositories and 15 PRs in the TiKV repositories.
Notable changes to TiDB  Upgrade the query optimizer. Upgrade the lexer. Replace golang protobuf with gogo protobuf. Optimize the distributed executor. Repair the Time and Decimal types to improve the compatibility with MySQL. Support the Set names binary statement. Support Covering Index. Optimize the table scanning when the condition is false constant.</description>
    </item>
    
    <item>
      <title>PingCAP 第 20 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-20/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-20/</guid>
      <description>PingCAP 第 20 期 NewSQL Meetup 2016-08-20 雷丽媛&amp;amp;温文鎏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 20 期 Meetup，主题是百度网页搜索部工程师雷丽媛分享的《搜索引擎背后的万亿量级存储系统 Tera 》以及温文鎏分享的《Cloudtable：分布式强一致的 KV 存储系统》。
【
To
pic 1
】
搜索引擎背后的万亿量级存储系统 Tera
近景福利：
今日的美女讲师 :)
Lecture：
雷丽媛，百度网页搜索部工程师。专注于分布式存储领域，目前负责百度结构化数据存储和分布式文件系统的相关工作。
Content：
介绍支撑搜索引擎核心的海量存储——Tera 的设计与实现
【 ****
Topic 2
】
Cloudtable：分布式强一致的 KV 存储系统
Content：
如何搭建一个适用于互联网公司业务的大容量分布式强一致性 KV 存储系统?
通过结合分布式一致性协议 Raft，嵌入式存储引擎 RocksDB，HBASE 的架构和接口，YY 云存储团队在过去的两年开发了 Cloudtable 存储系统，它是一个分布式强一致性的 KV 存储系统。今天，前 YY 云存储工程师温文鎏分享了他们在构建 Cloudtbable 系统的实践和经验。</description>
    </item>
    
    <item>
      <title>基于 Raft 构建弹性伸缩的存储系统的一些实践</title>
      <link>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</guid>
      <description>最近几年来，越来越多的文章介绍了 Raft 或者 Paxos 这样的分布式一致性算法，且主要集中在算法细节和日志同步方面的应用。但是呢，这些算法的潜力并不仅限于此，基于这样的分布式一致性算法构建一个完整的可弹性伸缩的高可用的大规模存储系统，是一个很新的课题，我结合我们这一年多以来在 TiKV 这样一个大规模分布式数据库上的实践，谈谈其中的一些设计和挑战。
本次分享的主要内容是如何使用 Raft 来构建一个可以「弹性伸缩」存储。其实最近这两年也有很多的文章开始关注类似 Paxos 或者 Raft 这类的分布式一致性算法，但是主要内容还是在介绍算法本身和日志复制，但是对于如何基于这样的分布式一致性算法构建一个大规模的存储系统介绍得并不多，我们目前在以 Raft 为基础去构建一个大规模的分布式数据库 TiKV ，在这方面积累了一些第一手的经验，今天和大家聊聊类似系统的设计，本次分享的内容不会涉及很多 Raft 算法的细节，大家有个 Paxos 或者 Raft 的概念，知道它们是干什么的就好。
##先聊聊 Scale 其实一个分布式存储的核心无非两点，一个是 Sharding 策略，一个是元信息存储，如何在 Sharding 的过程中保持业务的透明及一致性是一个拥有「弹性伸缩」能力的存储系统的关键。如果一个存储系统，只有静态的数据 Sharding 策略是很难进行业务透明的弹性扩展的，比如各种 MySQL 的静态路由中间件（如 Cobar）或者 Twemproxy 这样的 Redis 中间件等，这些系统都很难无缝地进行 Scale。 ##Sharding 的几种策略 在集群中的每一个物理节点都存储若干个 Sharding 单元，数据移动和均衡的单位都是 Sharding 单元。策略主要分两种，一种是 Range 另外一种是 Hash。针对不同类型的系统可以选择不同的策略，比如 HDFS 的Datanode 的数据分布就是一个很典型的例子：
###首先是 Range Range 的想法比较简单粗暴，首先假设整个数据库系统的 key 都是可排序的，这点其实还是蛮普遍的，比如 HBase 中 key 是按照字节序排序，MySQL 可以按照自增 ID 排序，其实对于一些存储引擎来说，排序其实是天然的，比如 LSM-Tree 或者 BTree 都是天然有序的。Range 的策略就是一段连续的 key 作为一个 Sharding 单元：</description>
    </item>
    
    <item>
      <title>Weekly update (August 05 ~ August 12, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-12-tidb-weekly/</link>
      <pubDate>Fri, 12 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-12-tidb-weekly/</guid>
      <description>Weekly update (August 05 ~ August 12, 2016) Last week, we landed 20 PRs in the TiDB repositories and 11 PRs in the TiKV repositories.
Notable changes to TiDB  Rewrite Lexer and improve the speed of parsing SQL texts by 40%. Add a command line flag for log output file and rotate log files regularly. Optimize the 2 phase commit process and adopt faster methods to clear locks. Optimize the execution speed of the Insert On Duplicate Update statement.</description>
    </item>
    
    <item>
      <title>TiDB 优化器实现的基础 -- 统计信息的收集</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-08-11/</link>
      <pubDate>Thu, 11 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-08-11/</guid>
      <description>收集统计信息的意义 一个 SQL 数据库里，优化器实现的好坏对性能的影响是决定性的。一个未经优化的执行计划和经过充分优化后的执行计划，执行时间的差别往往是成千上万倍。而对一个 SQL 优化器来说，统计信息是必不可少的条件，只有依赖统计信息提供的数据，优化器才可以正确估算不同的执行计划的执行代价，以选择最优的执行计划。就像一个大厨无论多么优秀，没有上等食材也是无法做出美味的饭菜。
统计信息包含的内容 统计信息有两类，包括 Table 统计信息和 Column 统计信息。
Table 统计信息包含 Row Count 和 Row Size。
Column 统计信息包含 Null Count，Max Value，Min Value，Distinct Count 以及 Histogram。其中 Histogram 用来记录这个 Column 的数据详细分布，可以用来估算大于、小于或等于某个 Value 的 Row Count。
统计信息采集的步骤  在 TiDB 执行 ANALYZE TABLE 语句，手动触发收集动作。  我们知道，一个 Table 的数据往往是在不断变化的，我们无法保证统计信息时刻保持在最新状态，总会有一定的误差，如果我们不及时更新，随着时间的推进，这个误差可能会越来越大，影响到优化器的优化效果。
有时我们会需要让统计信息更新的频率低一些来降低系统的压力，因为每次的统计信息收集都是开销很大的操作。有时我们会需要立即更新统计数据，因为我们刚刚向一个表导入了大量的数据，马上就需要查询。
所以定期更新统计信息的功能，我们希望可以用独立的模块，用更灵活的策略来实现，TiDB 本身只需要支持基本的手动触发就可以了。
 全表扫描。  全表扫描的执行过程比较长，整个扫表的任务会被分解为一系列 Region 的小请求，每个 Region 的请求会返回该 Region 包含的 Table 的部分数据。
 用扫描得到的数据，记录 Row Count 和 Row Size，并对数据采样。  扫描得到的数据量有可能会非常大，以至于无法把全部数据保留在内存里进行处理，所以需要进行采样，当采样的概率均匀的时候，计算生成的统计信息的误差是可以接受的。这里我们设定的采样数是 1 万，无论 Table 有多大，最后保留的样本数不会超过 1 万。后面会详细介绍采样时使用到的算法。</description>
    </item>
    
    <item>
      <title>PingCAP 第 19 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-08-06/</link>
      <pubDate>Sat, 06 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-08-06/</guid>
      <description>PingCAP 第 19 期 NewSQL Meetup 2016-08-06 方君&amp;amp;韩飞 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 19 期 Meetup，主题是百度基础架构部工程师方君分享的《
What&amp;rsquo;s New in Spark 2.0
》以及韩飞分享 的《An Overview of Cost Based Optimization and Join Reorder》。
▌ ****
Topic 1
：What&amp;rsquo;s New in Spark 2.0
Lecture：
方君，百度基础架构部工程师，专注于分布式计算与流式计算领域，目前在百度负责 Spark 计算平台和计算表示层的相关工作。
Content:
 DataSet API Performance Optimization Structure Streaming  ▌ ****</description>
    </item>
    
    <item>
      <title>Weekly update (July 30 ~ August 05, 2016)</title>
      <link>https://pingcap.com/weekly/2016-08-05-tidb-weekly/</link>
      <pubDate>Fri, 05 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-08-05-tidb-weekly/</guid>
      <description>Weekly update (July 30 ~ August 05, 2016) Last week, we landed 28 PRs in the TiDB repositories and 32 PRs in the TiKV repositories.
Notable changes to TiDB  Add support for constant folding in the SQL optimizer. Optimize the query speed of the secondary index. In certain scenarios, only the data in the index needs to be read. Use dynamic programing to decide the join path for multiple tables.</description>
    </item>
    
    <item>
      <title>云时代数据库的核心特点</title>
      <link>https://pingcap.com/blog-cn/cloud-native-db/</link>
      <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/cloud-native-db/</guid>
      <description>引言 最近几年，随着云计算相关技术的发展，各种不同类型的云层出不穷，服务越来越多不同类型的企业业务，传统企业也渐渐开始探索上云的道路。在云上，作为业务最核心的数据库，相比之前的传统方案会有哪些变化呢？在正式聊云时代的数据库特点之前，我们需要了解一下目前云时代架构发生的变化。
畅想一下，未来的服务都跑在云端，任何的服务资源都可以像水电煤一样按需选购。从 IaaS 层的容器/虚拟机，到 PaaS 层的数据库，缓存和计算单元，再到 SaaS 层的不同类型的应用，我们只需要根据自身业务特点进行资源选配，再也不用担心应用服务支撑不住高速的业务增长，因为在云上一切都是弹性伸缩的。有了可靠的基础软件架构，我们就可以把更多精力放到新业务的探索，新模式的创新，就有可能产生更多不一样的新场景，从而催生更强大能力的云端服务，这是一件多么 cool 的事情。
当然，理想要一步一步实现，未来的基础软件栈到底会怎样呢？社区在这方面正在进行积极地探索，其中最有代表性的就是基于容器（以 Docker 为代表）的虚拟化技术和微服务（Microservice）。
在云时代，一切都应该是可伸缩的，使用 k8s（Kubernetes）在保证资源平衡的前提下，通过 Docker 部署我们依托于容器的微服务模块，我们不用关心服务到底跑在哪里，只需要关心我们需要多少服务资源。Docker 提供了极大的便利性，一次构建，到处运行，我们可以很好地解决开发、测试和上线的环境一致性问题。（如果不能很好地保证测试和实际上线环境的一致性，则很有可能需要花费远超过开发的时间去发现和修复问题。）k8s 更是在 Docker 构建的基础上增加了更多的云特性，包括 Docker 的升级，高可用和弹性伸缩等等。 关于 Docker/k8s 相关的讨论已经很多了，因为时间关系，关于具体的细节就不再展开。我们只需要了解，有了它，可以很轻松地解决服务的安装和部署。
下面再聊聊微服务，微服务将一个服务拆分成相对独立的更小的子服务单元，不同的子服务单元之间通过统一的接口（HTTP/RPC 等）进行数据交互。
相比于传统的解决方案，这种架构有很多的优点。
 更好的开发效率和可维护性。微服务将一个单独的服务进行更细力度的拆分，每一个子服务单元专注于更小的功能模块，可以更好地根据业务建立对应的数据模型，降低复杂度，使得开发变得更轻松，维护和部署变得更加友好. 更好的可扩展性。每个不同的子服务单元相互独立，彼此之间没有任何依赖，所以可以根据业务的具体需要，灵活地部署多个子服务单元进行水平扩展。 更强的容错性。当其中一个子服务出现故障的时候，可以通过辅助的负载均衡工具，自动路由到其他的子服务，不会影响整体服务的可用性.  当然，微服务也不是一个银弹，相对来说，这种方案会使整体系统的设计更加复杂，同时也加大了网络的延迟，对整个系统测试的复杂度也会更高。
Docker 提供的隔离型和可移植性，与微服务是一种天然的契合，微服务将整个软件进行拆分和解耦，而通过 Docker/k8s 可以很自然地做到独立的部署，高可用和容错性，似乎一切都可以完美地运转起来。但是真的是这样么？我们是不是忽略了什么？
是的，我们在讨论前面的问题的时候忽略了一个很重要的东西：状态。
从整个技术发展的角度来看，微服务是一个非常有意义的探索。每个人都期望着每个微服务的子服务都是无状态的，这样我可以自由地启停和伸缩，没有任何的心智负担，但是现实的业务情况是什么样的呢？比如一个电商网站，用户正在下单购买一件商品，此时平台是通过订单子服务的 A 应用来提供服务的，突然，因为机器故障，订单子服务的 A 应用不可用了，改由订单子服务的 B 应用提供服务，那么它是必须要知道刚才用户的订单信息的，否则正在访问自己订单页面的用户会发现自己的订单信息突然不见了。虽然我们尽量想把子服务设计成无状态的，但是很多时候状态都是不可避免的，我们不得不通过存储层保存状态，业界最主要的还是各种数据库，包括 RDBMS 和 NoSQL，比如使用 MySQL、MongoDB、HBase、Cassandra 等，特别是有些场景还要考虑数据一致性问题的时候，更加重了对存储层的依赖。
由此可见，云计算时代系统的架构发生了巨大的变化，这一方面为用户提供了更优秀的特性，另一方面也对云计算的组件提出了更高的要求。数据库作为云计算最基础的组件之一，也需要适应这种架构的变化。（这里我们主要关注 SQL 数据库，云时代的数据库以下简称云数据库。）
那么云数据库主要有一些什么样的特点呢？我认为主要有以下几点。 弹性伸缩 传统的数据库方案，常见的会选用 Oracle，MySQL，PostgreSQL。在云时代，数据量的规模有爆发性的增长，传统的数据库很容易遇到单机的存储瓶颈，不得不选用一些集群方案，常见的比如 Oracle RAC、 MySQL Sharding 等，而这些集群方案或多或少都有一些不令人满意的地方。
比如说，Oracle RAC 通过共享存储的硬件方案解决集群问题，这种方式基本上只能通过停机换用更大的共享内存硬件来解决扩容问题，RAC 节点过多会带来更多的并发问题，同样也会带来更高的成本。</description>
    </item>
    
    <item>
      <title>TiDB 中的子查询优化技术</title>
      <link>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</guid>
      <description>子查询简介 子查询是嵌套在另一个查询中的 SQL 表达式，比较常见的是嵌套在 FROM 子句中，如 SELECT ID FROM (SELECT * FROM SRC) AS T。对于出现在 FROM 中的子表达式，一般的 SQL 优化器都会处理的很好。但是当子查询出现在 WHERE 子句或 SELECT 列表中时，优化的难度就会大大增加，因为这时子查询可以出现在表达式中的任何位置，如 CASE...WHEN... 子句等。
对于不在 FROM 子句出现的子查询，分为“关联子查询”(Correlated Subquery) 和“非关联子查询”。关联子查询是指子查询中存在外部引用的列，例如：
ELECT * FROM SRC WHERE EXISTS(SELECT * FROM TMP WHERE TMP.id = SRC.id) 对于非关联子查询，我们可以在 plan 阶段进行预处理，将其改写成一个常量。因此，本文只考虑关联子查询的优化。
一般来说，子查询语句分为三种：
 标量子查询（Scalar Subquery），如(SELECT&amp;hellip;) + (SELECT&amp;hellip;)
 集合比较（Quantified Comparision），如T.a = ANY(SELECT&amp;hellip;)
 存在性测试（Existential Test），如NOT EXISTS(SELECT&amp;hellip;)，T.a IN (SELECT&amp;hellip;)
  对于简单的存在性测试类的子查询，一般的做法是将其改写成 SEMI-JOIN。但是很少有文献给出通用性的算法，指出什么样的查询可以“去关联化”。对于不能去关联化的子查询，数据库的做法通常是使用类似 Nested Loop 的方式去执行，称为 correlated execution。</description>
    </item>
    
    <item>
      <title>TiDB 中的子查询优化技术</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-08-01/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-08-01/</guid>
      <description>子查询优化一直是 SQL 查询优化中非常难的一部分，尤其是关联子查询的改写。TiDB 为了兼容 MySQL，允许用户在任何位置编写子查询。对于非关联子查询，TiDB 会对其进行提前求值，对于关联子查询，TiDB 会尽可能的对其进行去关联化，例如改写成 SemiJoin。本文会重点介绍 TiDB 对关联子查询的优化手段。
 子查询简介 子查询是嵌套在另一个查询中的 SQL 表达式，比较常见的是嵌套在 FROM 子句中，如 SELECT ID FROM (SELECT * FROM SRC) AS T。对于出现在 FROM 中的子表达式，一般的 SQL 优化器都会处理的很好。但是当子查询出现在 WHERE 子句或 SELECT 列表中时，优化的难度就会大大增加，因为这时子查询可以出现在表达式中的任何位置，如 CASE&amp;hellip;WHEN&amp;hellip; 子句等。
对于不在 FROM 子句出现的子查询，分为“关联子查询”(Correlated Subquery) 和“非关联子查询”。关联子查询是指子查询中存在外部引用的列，例如：
SELECT * FROM SRC WHERE EXISTS(SELECT * FROM TMP WHERE TMP.id = SRC.id) 对于非关联子查询，我们可以在 plan 阶段进行预处理，将其改写成一个常量。因此，本文只考虑关联子查询的优化。
一般来说，子查询语句分为三种：
 标量子查询（Scalar Subquery），如(SELECT&amp;hellip;) + (SELECT&amp;hellip;) 集合比较（Quantified Comparision），如T.a = ANY(SELECT&amp;hellip;) 存在性测试（Existential Test），如NOT EXISTS(SELECT&amp;hellip;)，T.</description>
    </item>
    
    <item>
      <title>PingCAP 第 18 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-30/</link>
      <pubDate>Sat, 30 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-30/</guid>
      <description>PingCAP 第 18 期 NewSQL Meetup 2016-07-30 常冰琳&amp;amp;张阳 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 18 期 Meetup，主题是小米云平台工程师常冰琳分享的《Kudu 的设计思想和具体实现》以及张阳分享的《Kubernetes in PingCAP》。
▌ ****
Topic 1
：Kudu 的设计思想和具体实现
lecture：
常冰琳 小米云平台工程师，长期专注于 Hadoop 生态的分布式计算框架，Kudu PMC&amp;amp;Commiter, Hadoop Nativetask 项目发起者(已合入 Hadoop)。目前在小米负责 SQL 类数据分析平台，利用 Impala 和 Kudu 搭建实时数据分析云服务。
Content：
本次分享将简单介绍 Kudu 的设计思想和具体实现，以及小米作为 Kudu 最早用户的一些实践经验。
 设计目标
 数据模型，分区和副本设计
 Tablet 存储设计</description>
    </item>
    
    <item>
      <title>Weekly update (July 23 ~ July 29, 2016)</title>
      <link>https://pingcap.com/weekly/2016-07-29-tidb-weekly/</link>
      <pubDate>Fri, 29 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-07-29-tidb-weekly/</guid>
      <description>Weekly update (July 23 ~ July 29, 2016) Last week, we landed 27 PRs in the TiDB repositories and 34 PRs in the TiKV repositories.
Notable changes to TiDB  Support cost based query optimization. Set the new query optimizer as default to improve the speed of complex queries. Meanwhile, a start-up parameter is provided to switch to the old query optimizer. Use Varint to encode the Column Value with integer type and Column ID, which saves storage space significantly.</description>
    </item>
    
    <item>
      <title>PingCAP 第 17 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-23/</link>
      <pubDate>Sat, 23 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-23/</guid>
      <description>PingCAP 第 17 期 NewSQL Meetup 2016-07-23 崔秋 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 17 期 Meetup，主题是崔秋
分享的《How does TiKV auto-balance work?》
。
▌ ****
Topic
：
How does TiKV auto-balance work?
TiDB
最近发布了
Beta
版本，相比传统的关系型数据库，
TiDB
具有在线弹性伸缩，高可用和强一致性，一致性的分布式事务和
MySQL
协议兼容性等特性，特别适用于大规模高并发的海量数据场景。
本次交流主要介绍了 TiKV 的 Balance Scheduler 框架和算法实现演进，对于大家主要关注的 TiKV 集群的在线弹性扩容实现细节和 TiKV Balance 中在线服务高可用的问题，进行了深度的探讨。
在 TiKV 里面，数据是按照 Range 进行存放的，称为一个 Region。PD(Placement Driver) 负责整个 TiKV 集群的管理和调度。</description>
    </item>
    
    <item>
      <title>Weekly update (July 17 ~ July 22, 2016)</title>
      <link>https://pingcap.com/weekly/2016-07-23-tidb-weekly/</link>
      <pubDate>Sat, 23 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/weekly/2016-07-23-tidb-weekly/</guid>
      <description>Weekly update (July 17 ~ July 22, 2016) Last week, we landed 22 PRs in the TiDB repositories and 15 PRs in the TiKV repositories.
Notable changes to TiDB  Refactor the query optimizer to imporve the query efficiency for Join and SubQuery Add distributed SQL support for aggregate functions Improve the stability of the TiDB service Refactor the Decimal codes to improve the compatibility with MySQL Optimize the TiDB compatibility and performance for Zabbix Enhance the performance and the Sysbench result is improved significantly  Notable changes to TiKV  Add asynchronous scheduler support for higher throughput and better performance, see Benchmark.</description>
    </item>
    
    <item>
      <title>PingCAP 第 16 期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-16/</link>
      <pubDate>Sat, 16 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-16/</guid>
      <description>PingCAP 第 16 期 NewSQL Meetup 2016-07-16 田琪&amp;amp;孟圣智 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第 16 期 Meetup，主题是
来自京东的田琪分享的《Cool Extensions of Raft for NewSQL》，以及
来自百度的孟圣智分享的《基于 Ceph 构建文件共享服务的实践》 。
▌ ****
Topic
1
：Cool Extensions of Raft for NewSQL
lecturer：
田琪，京东数据库系统部负责人，开源 docker 镜像存储系统 speedy 作者，
TiDB committer, etcd contributor
Topic summary:
主要分享了 Raft 协议在 etcd 中的实现，与 etcd 在 Raft 协议方面近期更新地比较重要的特性，以及引进这些特性的缘由。</description>
    </item>
    
    <item>
      <title>PingCAP 第15期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-09/</link>
      <pubDate>Sat, 09 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-09/</guid>
      <description>PingCAP 第15期 NewSQL Meetup 2016-07-09 申砾&amp;amp;周昱行 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第15期 Meetup ，主题是申砾分享
的《TiDB 存储模型变更》以及周昱行
分享的《TiDB 优化器统计信息的采集》
。
▌
Part 1
：《TiDB 存储模型变更》
TiDB 在 Key-Value 存储模型之上，将一行数据拆分成多个 Key-Value pair。这样做有利于列较多并且 update 较为频繁的业务场景，同时对 Online Schema 变更较为友好。但是这种存储模型对于需要读取/写入大量 row 的业务场景并不适用。为此我们修改了 TiDB 的存储模型，将一行内需要频繁修改和很少修改的数据存储在不同的 column family 中，以更好地适应不同热度的数据,以及生存期差别比较大的数据。同时，非常有效地适配了读写放大以及空间放大的问题。
▌Part 2：
《TiDB 优化器统计信息的采集》
统计信息是实现基于代价的优化（CBO）的必要条件，本期为大家介绍 TiDB 收集统计信息使用的采样算法和直方图生成算法。
PingCAP Meetup</description>
    </item>
    
    <item>
      <title>PingCAP 第14期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-07-02/</link>
      <pubDate>Sat, 02 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-07-02/</guid>
      <description>PingCAP 第14期 NewSQL Meetup 2016-07-02 马涛&amp;amp;刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第14期 Meetup ，主题是酷克数据联合创始人
马涛
分享的《HashData 数据仓库的动态缩容扩容实现》以及 PingCAP 联合创始人兼 CEO 刘奇针对近日发布的 TiDB Beta 版进行的现场 Demo 演示。
▌
Part 1
：《 HashData 数据仓库的动态缩容扩容实现》
讲师：马涛，酷克数据联合创始人，数据库领域从业近10年，最初 Pivotal HAWQ 项目成员，06年至11年就职人大金仓做内核开发。目前主要负责 OLAP 系统内核和外围云化工作。
通过对比 Greenplum，Dynamo 和 HashData 的当前实现，为大家简单介绍数据处理系统动态缩容扩容的实现。阐述数据系统缩容和扩容的需求集合和设计方案，深入介绍 HashData 选择的设计、目前实现和后续改进。
▌
Part 2
：
《 TiDB Beta 版现场 Demo 演示》</description>
    </item>
    
    <item>
      <title>PingCAP 第13期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-06-25/</link>
      <pubDate>Sat, 25 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-06-25/</guid>
      <description>PingCAP 第13期 NewSQL Meetup 2016-06-25 闫宇&amp;amp;崔秋 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第13期 Meetup ，主题是百度资深研发工程师、百度 BAC 存储负责人闫宇分享的《 百度 redis3 生产环境实践》以及 PingCAP 联合创始人崔秋分享的《TiKV Auto Balance 》。
▌
Topic 1
：
《百度 redis3 生产环境实践》
讲师：
闫宇，百度资深研发工程师，百度 BAC 存储负责人
**
（百度 BAC 的 redis3 服务目前机器规模达到1400台左右，总数据量接近100T，日 pv 超过1500亿，用户涵盖了百度贴吧、百度糯米、手机百度等百度内部几百个业务线。）
内容方向：
1）介绍百度BAC的 redis3 服务的整体架构；
2）交流在 redis3 实践中的一些经验。
以下为本次分享的干货PPT：
▌
Topic 2：
《TiKV Auto Balance》</description>
    </item>
    
    <item>
      <title>PingCAP 第12期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-06-18/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-06-18/</guid>
      <description>PingCAP 第12期 NewSQL Meetup 2016-06-18 张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第12期 Meetup ，主题是
张金鹏分享的《 rocksdb 日志分析和性能调优经验 》。
▌张金鹏
《 rocksdb 日志分析和性能调优经验 》
首先和大家一起分享如何分析 rocksdb 的 LOG，包括观察 compaction 相关的统计信息。
例如每个 level 导致的 compaction 个数，每个 compaction job 的平均持续时长，compaction 导致的 read 总量和 write 量，以及写放大等；也可以观察整个系统是否有 stall 情况，持续多长时间，时间占比是多少等；另外，还有跟踪某个具体的 compaction job 的 input files 组成，output files，以及 compacting 过程中 drop 掉的 key 个数等信息。</description>
    </item>
    
    <item>
      <title>TiDB 下推 API 实现细节 - Union Scan</title>
      <link>https://pingcap.com/blog-cn/tidb-api-union-scan/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-api-union-scan/</guid>
      <description>TiDB 集群的架构分为上层的 SQL 层和底层的 KV 层，SQL 层通过调用 KV 层的 API 读写数据，由于 SQL 层的节点和 KV 层节点通常不在一台机器上，所以，每次调用 KV 的 API 都是一次 RPC, 而往往一个普通的 Select 语句的执行，需要调用几十到几十万次 KV 的接口，这样的结果就是性能非常差，绝大部分时间都消耗在 RPC 上。
为了解决这个问题，TiDB 实现了下推 API，把一部分简单的 SQL 层的执行逻辑下推到 KV 层执行，让 KV 层可以理解 Table 和 Column，可以批量读取多行结果，可以用 Where 里的 Expression 对结果进行过滤, 可以计算聚合函数，大幅减少了 RPC 次数和数据的传输量。
TiDB 的下推 API 通过把 SQL 层的计算下推到 KV 层，大幅减少 RPC 次数和数据传输量，使性能得到数量级的提升。但是当我们一开始启用下推 API 的时候，发现了一个问题，就是当事务写入了数据，但是还未提交的时候，又执行了 Select 操作。
这个时候，刚刚写入的未提交的脏数据读不到，得到的结果是错误的，比如我们在一个空表 t 执行：
begin; insert t values (1); select * from t; 这时我们期待的结果是一条记录 “1”，但是启用下推 API 后得到的结果是空。</description>
    </item>
    
    <item>
      <title>TiDB 下推 API 实现细节 - Union Scan</title>
      <link>https://pingcap.com/meetup/memoir/meetup-2016-06-18/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/memoir/meetup-2016-06-18/</guid>
      <description>TiDB 集群的架构分为上层的 SQL 层和底层的 KV 层，SQL 层通过调用 KV 层的 API 读写数据，由于 SQL 层的节点和 KV 层节点通常不在一台机器上，所以，每次调用 KV 的 API 都是一次 RPC, 而往往一个普通的 Select 语句的执行，需要调用几十到几十万次 KV 的接口，这样的结果就是性能非常差，绝大部分时间都消耗在 RPC 上。
为了解决这个问题，TiDB 实现了下推 API，把一部分简单的 SQL 层的执行逻辑下推到 KV 层执行，让 KV 层可以理解 Table 和 Column，可以批量读取多行结果，可以用 Where 里的 Expression 对结果进行过滤, 可以计算聚合函数，大幅减少了 RPC 次数和数据的传输量。
 TiDB 的下推 API 通过把 SQL 层的计算下推到 KV 层，大幅减少 RPC 次数和数据传输量，使性能得到数量级的提升。但是当我们一开始启用下推 API 的时候，发现了一个问题，就是当事务写入了数据，但是还未提交的时候，又执行了 Select 操作。
这个时候，刚刚写入的未提交的脏数据读不到，得到的结果是错误的，比如我们在一个空表 t 执行：
begin; insert t values (1); select * from t; 这时我们期待的结果是一条记录 “1”，但是启用下推 API 后得到的结果是空。</description>
    </item>
    
    <item>
      <title>PingCAP 第11期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-06-04/</link>
      <pubDate>Sat, 04 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-06-04/</guid>
      <description>PingCAP 第11期 NewSQL Meetup 2016-06-04 黄梦龙&amp;amp;张金鹏 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第11期 Meetup ，
主题是黄梦龙分享的《 TiKV 的结构化存储模型优化》和张金鹏分享的《深入解析 LevelDB 》。
▌黄梦龙
《 TiKV 的结构化存储模型优化》
目前 TiKV 的存储模型是简单的纯 Key-Value，在存储 SQL 结构化数据的过程中会产生比较严重的读写放大问题。我们计划为 TiKV 添加类似于 Hbase 的 ColumnFamily 机制，以使得 TiKV 与 TiDB 成为更加完美的搭档。大家对其中的实现细节，以及各种方案的优缺点进行了探讨。
▌张金鹏
《深入解析 LevelDB 》
首先介绍了 LevelDB 的整体架构，以及 LSM Tree 这一数据库中非常经典的结构。之后对 LevelDB 的写和读的流程进行分析，同时介绍 LevelDB 的 snapshot 功能的实现原理，以及 iterator 内部实现，和 iterator 存在的潜在问题。最后介绍 LevelDB 的 compaction 过程，以及存在的问题。</description>
    </item>
    
    <item>
      <title>PingCAP 第10期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-05-28/</link>
      <pubDate>Sat, 28 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-05-28/</guid>
      <description>PingCAP 第10期 NewSQL Meetup 2016-05-28 刘奇&amp;amp;周昱行 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第10期 Meetup ，跟京东小伙伴就
Raft group 中出现网络隔离时的 stale read 的问题做了充分讨论交流。之后进行的
分享主题是《 TiKV 的网络模拟测试》和《 TiDB 的条件下推优化》。
▌随机讨论
Raft group 中出现网络隔离时，会有stale read 的问题。目前我们考虑采用 region leader 的方案，保证在出现网络隔离的情况下，也能保证读的正确性。大家对其中的实现细节，以及各种方案的优缺点进行了讨论。
▌刘奇
《 TiKV 的网络模拟测试》
TiKV 如何做分布式系统测试。目前已经构建了一套测试框架，提供设置网络延迟、网络隔离、节点掉线等功能，用于构建测试用例。
▌周昱行
《 TiDB 的条件下推优化》
使用基于 Row 的 Merge 算法，解决存在脏数据时，使用 TiDB 下推 API 优化的问题。
TiDB 的下推 API 相比基础的 API 对读性能有着几个数量级的提升，任何无法使用下推 API 的操作的请求，性能都慢到完全无法接受的程度。</description>
    </item>
    
    <item>
      <title>PingCAP 第9期 NewSQL Meetup</title>
      <link>https://pingcap.com/meetup/meetup-2016-05-21/</link>
      <pubDate>Sat, 21 May 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/meetup-2016-05-21/</guid>
      <description>PingCAP 第9期 NewSQL Meetup 2016-05-21 韩飞&amp;amp;刘奇 PingCAP PingCAP
PingCAP ![]() 微信号
pingcap2015
功能介绍
PingCAP 专注于新型分布式数据库的研发，是知名开源数据库 TiDB (GitHub 总计10000+ stars ) 背后的团队，总部设在北京，是国内第一家开源的新型分布式关系型数据库公司、国内领先的大数据技术和解决方案提供商。
NewSQL Meetup
今天是 PingCAP 第9期 NewSQL Meetup ，分享主题是韩飞的《 SQL 子查询优化》和刘奇的《 TiKV MVCC 和 GC 实现》。
▌韩飞 《 SQL 子查询优化》
分享 SQL subqueries 的变换和优化问题。
关联子查询的优化是 SQL 优化中很重要的一部分，一般的执行方式方式是 correlated execution，但是可以通过引入 Apply 算子形式化证明所有的子查询都可以改写成 Join 的不同形式。在分布式场景下，Join 可以比 correlated execution 有更多的优化空间。
▌刘奇
《 TiKV MVCC 和 GC 实现》
详细分析了 TiKV 的 MVCC 机制, 事务模型，并进一步介绍了 percolator 事务模型的特点，以及对 GC 的影响。另外讲解了 TiKV 对 percolator 事务模型的改进, 以及 TiKV 的 GC 算法，和如何支持长时间的数据库备份和分析操作。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/about-cn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/about-cn/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/about/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/blog-cn/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/README/</guid>
      <description> blog-cn 文档规范 meta 信息 头部的 meta 信息必须包含一下内容：
 title 文章标题 author 文章作者 list(array) 格式: [&amp;lsquo;author-1&amp;rsquo;, &amp;lsquo;author-2&amp;rsquo;] date 文章发布日期 格式:yyyy-mm-dd summary 文章简介 tags 标签分类 list(array) 格式: [&amp;lsquo;tag-1&amp;rsquo;, &amp;lsquo;tag-2&amp;rsquo;]  --- title: Blog Title author: [&amp;#39;Author&amp;#39;] date: yyyy-mm-dd summary: Blog Summary tags: [&amp;#39;Tag1&amp;#39;, &amp;#39;Tag2&amp;#39;] --- 文档内容  正文中不需要将 blog 的标题写在最前面 请将标题统一写在 meta 信息中 方便html中使用统一样式 正文中用到的图片请统一放在 blog 或 blog-cn repo 的 media 目录下 正文中引用的图片命名避免用1、2、3之类的 避免冲突  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/blog/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog/README/</guid>
      <description> blog meta data  title author  format: list(array) [&amp;lsquo;author-1&amp;rsquo;, &amp;lsquo;author-2&amp;rsquo;]  date:  format: yyyy-mm-dd  summary tags -  format: list(array) [&amp;lsquo;tag-1&amp;rsquo;, &amp;lsquo;tag-2&amp;rsquo;]   --- title: Blog Title author: [&amp;#39;Author&amp;#39;] date: yyyy-mm-dd summary: Blog Summary tags: [&amp;#39;Tag1&amp;#39;, &amp;#39;Tag2&amp;#39;] ---</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/cloud-tidb-argeement/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cloud-tidb-argeement/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/README/</guid>
      <description>TiDB 中文技术文档 目录  TiDB 简介与整体架构  TiDB 简介 TiDB 整体架构  TiDB 快速入门指南 TiDB 用户文档  TiDB 数据库管理 TiDB 服务 TiDB 进程启动参数 TiDB 数据目录 TiDB 系统数据库 TiDB 系统变量 TiDB 专用系统变量和语法 TiDB 服务器日志文件 TiDB 访问权限管理 TiDB 用户账户管理 使用加密连接 SQL 优化 理解 TiDB 执行计划 统计信息 语言结构 字面值 数据库、表、索引、列和别名 关键字和保留字 用户变量 表达式语法 注释语法 字符集和时区 字符集支持 字符集配置 时区 数据类型 数值类型 日期和时间类型 字符串类型 JSON 数据类型 枚举类型 集合类型 数据类型默认值 函数和操作符 函数和操作符概述 表达式求值的类型转换 操作符 控制流程函数 字符串函数 数值函数与操作符 日期和时间函数 位函数和操作符 Cast 函数和操作符 加密和压缩函数 信息函数 JSON 函数 GROUP BY 聚合函数 其他函数 精度数学 SQL 语句语法 数据定义语句 (DDL) 数据操作语句 (DML) 事务语句 数据库管理语句 Prepared SQL 语句语法 实用工具语句 TiDB SQL 语法图 JSON 支持 Connectors 和 API TiDB 事务隔离级别 错误码与故障诊断 与 MySQL 兼容性对比 高级功能 历史数据回溯  TiDB 运维文档  软硬件环境需求 部署集群  Ansible 部署方案（强烈推荐） 离线 Ansible 部署方案 Docker 部署方案 Docker Compose 部署方案 跨机房部署方案 配置集群 参数解释 开启 TLS 验证 生成自签名证书 监控集群 整体监控框架概述 重要监控指标详解 组件状态 API &amp;amp; 监控 扩容缩容  使用 Ansible 扩容缩容 集群扩容缩容方案  升级 性能调优 备份与迁移 备份与恢复 数据迁移  数据迁移概述 全量导入 增量导入  Binary 部署方案 故障诊断  TiDB 周边工具  Syncer 使用文档 Loader 使用文档 TiDB-Binlog 使用文档 PD Control 使用文档  TiSpark 文档  TiSpark 快速入门指南 TiSpark 用户指南  常见问题与解答(FAQ) 最佳实践 版本发布历史 TiDB 路线图 用户案例  Mobike 易果生鲜 一面数据 凤凰网 猿辅导 二维火 去哪儿 G7 盖娅互娱 游族网络 万达网络 佐助金融 360金融 某电信运营商  更多资源  常用工具 PingCAP 团队技术博客 知乎专栏 Weekly 英文文档   TiDB 简介 TiDB 是 PingCAP 公司受 Google Spanner / F1 论文启发而设计的开源分布式 NewSQL 数据库。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/ROADMAP/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/ROADMAP/</guid>
      <description> TiDB： 优化器 重构 Ranger 统计信息优化 代价模型优化  执行引擎 算子并行化 Compact Row Foramt，节省内存占用 File Sort  支持 View 支持窗口函数 支持 Common Table Expression 支持分区表 Hash 时间索引，解决写入热点 Region 问题 逆序索引 聚簇索引 DDL 改进 支持 utf8_general_ci collation  TiKV: Raft Region 合并 Local read thread 多线程 Raftstore None voter Pre-vote  RocksDB 使用 DeleteRange 特性  Transaction 提升冲突严重的场景下 Transaction 的性能  Coprocessor 支持 Streaming 接口  Tool 分布式数据导入 分布式数据导出 灾难恢复  流控和降级处理  PD: Namespace 完善 不同 Namespace 或者 Table 配置不同的副本策略  Table region 分散调度 调度支持优先级，更加可控 使用机器学习优化调度  TiSpark: limit / Order下推 DAG接口接入（废除Select接口） Index Join和并行merge join Data Federation（桥接其他数据源，最好能和社区同步，这个接进来可以比较好扩展Usecase，如果再做一个InputFormat适配就可以接Hive和Presto这些Hadoop上的数仓）  SRE&amp;amp;Tools: On-Premise 版本集成部署 (K8s based) On-Premise 版本 Dashboard UI 集群备份和恢复工具（结合物理备份） 数据迁移工具（Wormhole 二期） 安全与系统诊断  </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs-cn/sql/connection-and-APIs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/connection-and-APIs/</guid>
      <description>连接器和 API 数据库连接器为客户端提供了连接数据库服务端的方式，APIs 提供了使用 MySQL 协议和资源的底层接口。无论是连接器还是 API，都可以用来在不同的语言和环境内连接服务器并执行 sql 语句，包括 odbc、java(jdbc)、Perl、Python、PHP、Ruby 和 C。
TiDB 兼容 MySQL(5.6、5.7) 的所有连接器和 API，包括：
 MySQL Connector/C MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  使用 MySQL 连接器连接 TiDB Oracle 官方提供了以下 API , TiDB 可以兼容所有这些 API。
 MySQL Connector/C：C 语言的客户端库，是 libmysqlclient 的替代品 MySQL Connector/C++：C++ 语言的客户端库 MySQL Connector/J：Java 语言的客户端库，基于标准 JDBC 接口 MySQL Connector/Net：.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/README/</guid>
      <description>TiDB Documentation Documentation List  About TiDB  TiDB Introduction TiDB Architecture  TiDB Quick Start Guide TiDB User Guide  TiDB Server Administration The TiDB Server The TiDB Command Options The TiDB Data Directory The TiDB System Database The TiDB System Variables The Proprietary System Variables and Syntax in TiDB The TiDB Server Logs The TiDB Access Privilege System TiDB User Account Management Use Encrypted Connections SQL Optimization Understand the Query Execution Plan Introduction to Statistics Language Structure Literal Values Schema Object Names Keywords and Reserved Words User-Defined Variables Expression Syntax Comment Syntax Globalization Character Set Support Character Set Configuration Time Zone Data Types Numeric Types Date and Time Types String Types JSON Types The ENUM data type The SET Type Data Type Default Values Functions and Operators Function and Operator Reference Type Conversion in Expression Evaluation Operators Control Flow Functions String Functions Numeric Functions and Operators Date and Time Functions Bit Functions and Operators Cast Functions and Operators Encryption and Compression Functions Information Functions JSON Functions Aggregate (GROUP BY) Functions Miscellaneous Functions Precision Math SQL Statement Syntax Data Definition Statements Data Manipulation Statements Transactions Database Administration Statements Prepared SQL Statement Syntax Utility Statements TiDB SQL Syntax Diagram JSON Functions and Generated Column Connectors and APIs TiDB Transaction Isolation Levels Error Codes and Troubleshooting Compatibility with MySQL Advanced Usage Read Data From History Versions  TiDB Operations Guide  Hardware and Software Requirements Deploy Ansible Deployment (Recommended) Offline Deployment Using Ansible Docker Deployment Cross-Region Deployment Configure Configuration Flags Enable TLS Authentication Generate Self-signed Certificates Monitor Overview of the Monitoring Framework Key Metrics Monitor a TiDB Cluster Scale Scale a TiDB Cluster Use Ansible to Scale Upgrade Tune Performance Backup and Migrate Backup and Restore Migrate  Migration Overview Migrate All the Data Migrate the Data Incrementally  Deploy TiDB Using the Binary Troubleshoot  TiDB Utilities  Syncer User Guide Loader User Guide TiDB-Binlog User Guide PD Control User Guide  The TiDB Connector for Spark  Quick Start Guide User Guide  Frequently Asked Questions (FAQ) TiDB Best Practices Releases TiDB Roadmap Connect with us More Resources  Frequently Used Tools PingCAP Blog Weekly Update   TiDB Introduction TiDB (The pronunciation is: /&amp;lsquo;taɪdiːbi:/ tai-D-B, etymology: titanium) is a Hybrid Transactional/Analytical Processing (HTAP) database.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/deployment/</guid>
      <description>Build for deployment Overview Note: The easiest way to deploy TiDB is to use the official binary package directly, see Binary Deployment.
If you want to build the TiDB project, deploy the binaries to other machines and run them, you can follow this guide.
Check the supported platforms and prerequisites first.
Building and installing TiDB components You can use the build script to build and install TiDB components in the bin directory.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/development/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/development/</guid>
      <description>Build For Development Overview If you want to develop the TiDB project, you can follow this guide.
Before you begin, check the supported platforms and prerequisites first.
Build TiKV After you install the RocksDB shared library, you can build TiKV directly without ROCKSDB_SYS_STATIC.
 Get the TiKV source code.
git clone https://github.com/pingcap/tikv.git  Enter the source directory to build and install the binary in the bin directory.
make Run unit test.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/dev-guide/requirements/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/dev-guide/requirements/</guid>
      <description>Build requirements Supported platforms The following table lists TiDB support for common architectures and operating systems.
   Architecture Operating System Status     AMD64 Linux Ubuntu (14.04+) Stable   AMD64 Linux CentOS (7+) Stable   AMD64 Mac OSX Experimental    Prerequisites  Go 1.8+ Rust nightly version GCC 4.8+ with static library  The check requirement script can help you check prerequisites and install the missing ones automatically.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/op-guide/pd-api-v1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/pd-api-v1/</guid>
      <description>Placement Driver API  /*! jQuery v3.1.0 | (c) jQuery Foundation | jquery.org/license */ !function(a,b){&#34;use strict&#34;;&#34;object&#34;==typeof module&amp;&amp;&#34;object&#34;==typeof module.exports?module.exports=a.document?b(a,!0):function(a){if(!a.document)throw new Error(&#34;jQuery requires a window with a document&#34;);return b(a)}:b(a)}(&#34;undefined&#34;!=typeof window?window:this,function(a,b){&#34;use strict&#34;;var c=[],d=a.document,e=Object.getPrototypeOf,f=c.slice,g=c.concat,h=c.push,i=c.indexOf,j={},k=j.toString,l=j.hasOwnProperty,m=l.toString,n=m.call(Object),o={};function p(a,b){b=b||d;var c=b.createElement(&#34;script&#34;);c.text=a,b.head.appendChild(c).parentNode.removeChild(c)}var q=&#34;3.1.0&#34;,r=function(a,b){return new r.fn.init(a,b)},s=/^[\s\uFEFF\xA0]+|[\s\uFEFF\xA0]+$/g,t=/^-ms-/,u=/-([a-z])/g,v=function(a,b){return b.toUpperCase()};r.fn=r.prototype={jquery:q,constructor:r,length:0,toArray:function(){return f.call(this)},get:function(a){return null!=a?a=0&amp;&amp;c0&amp;&amp;b-1 in a)}var x=function(a){var b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u=&#34;sizzle&#34;+1*new Date,v=a.document,w=0,x=0,y=ha(),z=ha(),A=ha(),B=function(a,b){return a===b&amp;&amp;(l=!0),0},C={}.hasOwnProperty,D=[],E=D.pop,F=D.push,G=D.push,H=D.slice,I=function(a,b){for(var c=0,d=a.length;c+~]|&#34;+K+&#34;)&#34;+K+&#34;*&#34;),S=new RegExp(&#34;=&#34;+K+&#34;*([^\\]&#39;\&#34;]*?)&#34;+K+&#34;*\\]&#34;,&#34;g&#34;),T=new RegExp(N),U=new RegExp(&#34;^&#34;+L+&#34;$&#34;),V={ID:new RegExp(&#34;^#(&#34;+L+&#34;)&#34;),CLASS:new RegExp(&#34;^\\.(&#34;+L+&#34;)&#34;),TAG:new RegExp(&#34;^(&#34;+L+&#34;|[*])&#34;),ATTR:new RegExp(&#34;^&#34;+M),PSEUDO:new RegExp(&#34;^&#34;+N),CHILD:new RegExp(&#34;^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\(&#34;+K+&#34;*(even|odd|(([+-]|)(\\d*)n|)&#34;+K+&#34;*(?:([+-]|)&#34;+K+&#34;*(\\d+)|))&#34;+K+&#34;*\\)|)&#34;,&#34;i&#34;),bool:new RegExp(&#34;^(?:&#34;+J+&#34;)$&#34;,&#34;i&#34;),needsContext:new RegExp(&#34;^&#34;+K+&#34;*[+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\(&#34;+K+&#34;*((?:-\\d)?\\d*)&#34;+K+&#34;*\\)|)(?=[^-]|$)&#34;,&#34;i&#34;)},W=/^(?:input|select|textarea|button)$/i,X=/^h\d$/i,Y=/^[^{]+\{\s*\[native \w/,Z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,$=/[+~]/,_=new RegExp(&#34;\\\\([\\da-f]{1,6}&#34;+K+&#34;?|(&#34;+K+&#34;)|.)&#34;,&#34;ig&#34;),aa=function(a,b,c){var d=&#34;0x&#34;+b-65536;return d!==d||c?b:d10|55296,1023&amp;d|56320)},ba=/([\0-\x1f\x7f]|^-?\d)|^-$|[^\x80-\uFFFF\w-]/g,ca=function(a,b){return b?&#34;\0&#34;===a?&#34;\ufffd&#34;:a.slice(0,-1)+&#34;\\&#34;+a.charCodeAt(a.length-1).toString(16)+&#34; &#34;:&#34;\\&#34;+a},da=function(){m()},ea=ta(function(a){return a.disabled===!0},{dir:&#34;parentNode&#34;,next:&#34;legend&#34;});try{G.apply(D=H.call(v.childNodes),v.childNodes),D[v.childNodes.length].nodeType}catch(fa){G={apply:D.length?function(a,b){F.apply(a,H.call(b))}:function(a,b){var c=a.length,d=0;while(a[c++]=b[d++]);a.length=c-1}}}function ga(a,b,d,e){var f,h,j,k,l,o,r,s=b&amp;&amp;b.ownerDocument,w=b?b.nodeType:9;if(d=d||[],&#34;string&#34;!=typeof a||!a||1!==w&amp;&amp;9!==w&amp;&amp;11!==w)return d;if(!e&amp;&amp;((b?b.ownerDocument||b:v)!==n&amp;&amp;m(b),b=b||n,p)){if(11!==w&amp;&amp;(l=Z.exec(a)))if(f=l[1]){if(9===w){if(!(j=b.getElementById(f)))return d;if(j.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/docs/sql/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/operators/</guid>
      <description>Operators  Operator precedence Comparison functions and operators Logical operators Assignment operators     Name Description     AND, &amp;amp;&amp;amp; Logical AND   = Assign a value (as part of a SET statement, or as part of the SET clause in an UPDATE statement)   := Assign a value   BETWEEN &amp;hellip; AND &amp;hellip; Check whether a value is within a range of values   BINARY Cast a string to a binary string   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   CASE Case operator   DIV Integer division   / Division operator   = Equal operator   &amp;lt;=&amp;gt; NULL-safe equal to operator   &amp;gt; Greater than operator   &amp;gt;= Greater than or equal operator   IS Test a value against a boolean   IS NOT Test a value against a boolean   IS NOT NULL NOT NULL value test   IS NULL NULL value test   -&amp;gt; Return value from JSON column after evaluating path; equivalent to JSON_EXTRACT()   -&amp;gt;&amp;gt; Return value from JSON column after evaluating path and unquoting the result; equivalent to JSON_UNQUOTE(JSON_EXTRACT())   &amp;lt;&amp;lt; Left shift   &amp;lt; Less than operator   &amp;lt;= Less than or equal operator   LIKE Simple pattern matching   - Minus operator   %, MOD Modulo operator   NOT, !</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/en/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/en/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/meetup/list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/meetup/list/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/recruit-cn/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/TOC/</guid>
      <description> TiDB 招聘 目录  技术类职位  TiKV Engineer TiDB Engineer Bizdev &amp;amp; Tools Engineer Bizdev &amp;amp; Cloud Engineer Bizdev &amp;amp; SRE Engineer Bizdev &amp;amp; FE Engineer OPS Engineer DBA  市场类职位  PR Manager 市场运营  销售 | 售前 | 售后类职位  渠道合作总监 高级业务拓展（销售）经理 行业销售总监 售前技术总监  校园招聘职位  Front End Engineer Infrastructure Engineer Infrastructure Engineer Intern   </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/recruit/TOC/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit/TOC/</guid>
      <description> TiDB Recruit Directory  engineer  Software Engineer for TiDB Software Engineer for TiKV   </description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/site-index/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/site-index/</guid>
      <description></description>
    </item>
    
    <item>
      <title>About TiDB</title>
      <link>https://pingcap.com/docs/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/overview/</guid>
      <description>About TiDB TiDB introduction TiDB (The pronunciation is: /&amp;lsquo;taɪdiːbi:/ tai-D-B, etymology: titanium) is a Hybrid Transactional/Analytical Processing (HTAP) database. Inspired by the design of Google F1 and Google Spanner, TiDB features infinite horizontal scalability, strong consistency, and high availability. The goal of TiDB is to serve as a one-stop solution for online transactions and analyses.
 Horizontal scalability Compatible with MySQL protocol Automatic failover and high availability Consistent distributed transactions Online DDL Multiple storage engine support  Read the following three articles to understand TiDB techniques:</description>
    </item>
    
    <item>
      <title>Aggregate (GROUP BY) Functions</title>
      <link>https://pingcap.com/docs/sql/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/aggregate-group-by-functions/</guid>
      <description>Aggregate (GROUP BY) Functions Aggregate (GROUP BY) function descriptions This section describes the supported MySQL group (aggregate) functions in TiDB.
   Name Description     COUNT() Return a count of the number of rows returned   COUNT(DISTINCT) Return the count of a number of different values   SUM() Return the sum   AVG() Return the average value of the argument   MAX() Return the maximum value   MIN() Return the minimum value   GROUP_CONCAT() Return a concatenated string     Unless otherwise stated, group functions ignore NULL values.</description>
    </item>
    
    <item>
      <title>Ansible Deployment</title>
      <link>https://pingcap.com/docs/op-guide/ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/ansible-deployment/</guid>
      <description>Ansible Deployment Overview Ansible is an IT automation tool. It can configure systems, deploy software, and orchestrate more advanced IT tasks such as continuous deployments or zero downtime rolling updates.
TiDB-Ansible is a TiDB cluster deployment tool developed by PingCAP, based on Ansible playbook. TiDB-Ansible enables you to quickly deploy a new TiDB cluster which includes PD, TiDB, TiKV, and the cluster monitoring modules.
You can use the TiDB-Ansible configuration file to set up the cluster topology, completing all operation tasks with one click, including:</description>
    </item>
    
    <item>
      <title>Ansible Deployment Using the Root User Account</title>
      <link>https://pingcap.com/docs/op-guide/root-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/root-ansible-deployment/</guid>
      <description>Ansible Deployment Using the Root User Account  Note: The remote Ansible user (the ansible_user in the incentory.ini file) can use the root user account to deploy TiDB, but it is not recommended.
 The following example uses the tidb user account as the user running the service.
To deploy TiDB using a root user account, take the following steps:
 Edit inventory.ini as follows.
Remove the code comments for ansible_user = root, ansible_become = true and ansible_become_user.</description>
    </item>
    
    <item>
      <title>Backup and Restore</title>
      <link>https://pingcap.com/docs/op-guide/backup-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/backup-restore/</guid>
      <description>Backup and Restore About This document describes how to backup and restore the data of TiDB. Currently, this document only covers full backup and restoration.
Here we assume that the TiDB service information is as follows:
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    Use the following tools for data backup and restoration:
 mydumper: to export data from TiDB loader: to import data into TiDB  Download TiDB toolset (Linux) # Download the tool package.</description>
    </item>
    
    <item>
      <title>Bit Functions and Operators</title>
      <link>https://pingcap.com/docs/sql/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/bit-functions-and-operators/</guid>
      <description> Bit Functions and Operators In TiDB, the usage of bit functions and operators is similar to MySQL. See Bit Functions and Operators.
Bit functions and operators
   Name Description     BIT_COUNT() Return the number of bits that are set as 1   &amp;amp; Bitwise AND   ~ Bitwise inversion   | Bitwise OR   0 Bitwise XOR   &amp;lt;&amp;lt; Left shift   &amp;gt;&amp;gt; Right shift    </description>
    </item>
    
    <item>
      <title>Bit-value Literals</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-bit-value/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-bit-value/</guid>
      <description>Bit-value Literals 位值字面值用 b 或者 0b 做前缀，后接以 0 跟 1 组成的二进制数字。其中 0b 是区分大小写的，0B 是会报错的。
合法的 Bit-value：
 b&amp;rsquo;01&amp;rsquo; B&amp;rsquo;01&amp;rsquo; 0b01  非法的 Bit-value：
 b&amp;rsquo;2&amp;rsquo; (2 不是二进制数值, 必须为 0 或 1) 0B01 (0B 必须是小写 0b)  默认情况，位值字面值是一个二进制字符串。
Bit-value 是作为二进制返回的，所以输出到 MySQL Client 可能会显示不出来，如果要转换为可打印的字符，可以使用内建函数 BIN() 或者 HEX()：
CREATE TABLE t (b BIT(8)); INSERT INTO t SET b = b&amp;#39;00010011&amp;#39;; INSERT INTO t SET b = b&amp;#39;1110&amp;#39;; INSERT INTO t SET b = b&amp;#39;100101&amp;#39;; mysql&amp;gt; SELECT b+0, BIN(b), HEX(b) FROM t; +------+--------+--------+ | b+0 | BIN(b) | HEX(b) | +------+--------+--------+ | 19 | 10011 | 13 | | 14 | 1110 | E | | 37 | 100101 | 25 | +------+--------+--------+ 3 rows in set (0.</description>
    </item>
    
    <item>
      <title>Bizdev &amp; Cloud Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/bizdev-cloud-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/bizdev-cloud-engineer/</guid>
      <description>Bizdev &amp;amp; Cloud Engineer 岗位职责  TiDB 基于 Kubernetes 平台自动化部署运维工具的开发
 TiDB 与公有云 / 私有云平台整合
  职位要求  扎实的编程能力，熟悉 C/C++/Go/Rust/Python 一种编程语言
 对容器技术有较深入的了解
 熟悉 Swarm/Mesos/Kubernetes 等容器编排系统中至少一种
 熟练使用 Linux
 具备大型分布式系统监控、分析和故障排查等相关经验
 有国内外公有云平台使用和运维经验
 良好的沟通能力和技巧
  加分项  熟悉 Ansible / Saltstack 等自动化部署工具
 为 Docker / Kubernetes 贡献过代码
 熟悉 BGP，Overlay 网络
  待遇 20K - 40K + 期权, 13薪 + 奖金, 优秀者可面议
工作地点 北京，上海，广州，杭州，特别优秀可 remote</description>
    </item>
    
    <item>
      <title>Bizdev &amp; FE Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/bizdev-fe-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/bizdev-fe-engineer/</guid>
      <description>Bizdev &amp;amp; FE Engineer 岗位职责  负责为商业产品和工具等开发流畅酷炫富有科技范的前端界面
 前端组件设计，框架定制和保证快速迭代的速度和质量，探索前端开发新规范和模式
  职位要求  三年以上相关领域开发经验，扎实的编程能力
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神
 熟悉 JavaScript /TypeScript 和新语言规范和语法特性 如 ES2015 等
 精通 webpack 构建，nodejs 脚本开发和常用 prettier，eslint, babel 等配置
 熟悉 React/Angular/Vue 等现代 Web 前端框架使用和实现原理
 熟悉富应用 SPA 开发模式，如单向数据流 Flux / Redux，响应式编程 rxjs / cyclejs
  加分项  拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历
 良好的适应和学习能力对自己不设限，挑战如：数据可视化，监控告警 Devops，商业/工具产品设计等方向
 其他例如您熟悉 Electron、看过 Chromium 源代码、写过一些关于 JavaScript 技术的博客文章… 具体不限，我们愿闻其详
  待遇 20K - 40K + 期权, 13薪 + 奖金, 优秀者可面议</description>
    </item>
    
    <item>
      <title>Bizdev &amp; SRE Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/bizdev-sre-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/bizdev-sre-engineer/</guid>
      <description>Bizdev &amp;amp; SRE Engineer 岗位职责  管理维护公司内部各种资源，让一切自动化起来
 Linux 系统调优和诊断工具开发
  职位要求  以“折腾” Linux 为乐
 掌握一门基础编程语言，如 C/C++ / Go / Rust / &amp;hellip;
 熟练掌握一门脚本语言，如 shell / Python / Perl / &amp;hellip;
 基于系统内核的诊断和调优，工具
 熟悉 Linux kernel 和各个子系统(网络、存储，内存，调度、文件系统等)，熟悉常见的应用和系统 profile 工具。
 熟悉 TCP / IP 基本原理
 精通路由、交换、防火墙、四层交换等网络技术，有较强的网络安全意识
 熟悉配置调试主流厂商如华为、Juniper 网络设备，有相关项目实施运维经验
 责任心强、积极主动，抗压能力强，有良好的沟通能力和团队合作能力
  加分项  熟悉 Systemtap、Perf 等分析调试工具优先考虑。
 有 Cisco、H3C 网络认证者优先考虑。
  待遇 20K - 40K + 期权, 13薪 + 奖金, 优秀者可面议</description>
    </item>
    
    <item>
      <title>Bizdev &amp; Tools Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/bizdev-tools-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/bizdev-tools-engineer/</guid>
      <description>Bizdev &amp;amp; Tools Engineer 岗位职责  TiDB 商业工具开发，完善 TiDB 的周边生态，提升用户使用体验
 建设高度智能的自动化测试系统，进行各种破坏性测试，验证 TiDB 的可靠性
  职位要求  扎实的编程能力，熟悉 C/C++/Go/Rust 其中一种编程语言
 熟悉大型分布式系统，具备冷静分析复杂问题能力
 熟悉常用算法和数据结构
 深入了解过操作系统和网络
 良好的沟通能力和技巧，以及抗压能力
 了解 Automated Reasoning / Static Analysis 等测试方法及工具
  加分项  爱折腾，强烈的 Hack 精神
 TopCoder, Codeforces 黄色以上
  待遇 20K - 40K + 期权, 13薪 + 奖金, 优秀者可面议
工作地点 北京，上海，广州，杭州，特别优秀可 remote</description>
    </item>
    
    <item>
      <title>Boolean Literals</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-boolean/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-boolean/</guid>
      <description> Boolean Literals 常量 TRUE 和 FALSE 等于 1 和 0，它是大小写不敏感的。
mysql&amp;gt; SELECT TRUE, true, tRuE, FALSE, FaLsE, false; +------+------+------+-------+-------+-------+ | TRUE | true | tRuE | FALSE | FaLsE | false | +------+------+------+-------+-------+-------+ | 1 | 1 | 1 | 0 | 0 | 0 | +------+------+------+-------+-------+-------+ 1 row in set (0.00 sec)</description>
    </item>
    
    <item>
      <title>Cast Functions and Operators</title>
      <link>https://pingcap.com/docs/sql/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/cast-functions-and-operators/</guid>
      <description>Cast Functions and Operators    Name Description     BINARY Cast a string to a binary string   CAST() Cast a value as a certain type   CONVERT() Cast a value as a certain type    Cast functions and operators enable conversion of values from one data type to another.
For details, see here.</description>
    </item>
    
    <item>
      <title>Character Set Configuration</title>
      <link>https://pingcap.com/docs/sql/character-set-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/character-set-configuration/</guid>
      <description>Character Set Configuration Currently, TiDB does not support configuring the character set. The default character set is utf8.
For more information, see Character Set Configuration in MySQL.</description>
    </item>
    
    <item>
      <title>Character Set Support</title>
      <link>https://pingcap.com/docs/sql/character-set-support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/character-set-support/</guid>
      <description>Character Set Support A character set is a set of symbols and encodings. A collation is a set of rules for comparing characters in a character set.
Currently, TiDB supports the following character sets:
mysql&amp;gt; SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>Comment Syntax</title>
      <link>https://pingcap.com/docs/sql/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/comment-syntax/</guid>
      <description>Comment Syntax TiDB supports three comment styles:
 Use # to comment a line. Use -- to comment a line, and this style requires at least one whitespace after --. Use /* */ to comment a block or multiple lines.  Example:
mysql&amp;gt; SELECT 1+1; # This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; SELECT 1+1; -- This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>Compatibility with MySQL</title>
      <link>https://pingcap.com/docs/sql/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/mysql-compatibility/</guid>
      <description>Compatibility with MySQL TiDB supports the majority of the MySQL grammar, including cross-row transactions, JOIN, subquery, and so on. You can connect to TiDB directly using your own MySQL client. If your existing business is developed based on MySQL, you can replace MySQL with TiDB to power your application without changing a single line of code in most cases.
TiDB is compatible with most of the MySQL database management &amp;amp; administration tools such as PHPMyAdmin, Navicat, MySQL Workbench, and so on.</description>
    </item>
    
    <item>
      <title>Configuration Flags</title>
      <link>https://pingcap.com/docs/op-guide/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/configuration/</guid>
      <description>Configuration Flags TiDB, TiKV and PD are configurable using command-line flags and environment variables.
TiDB The default TiDB ports are 4000 for client requests and 10080 for status report.
--binlog-socket  The TiDB services use the unix socket file for internal connections, such as the PUMP service Default: `` You can use &amp;ldquo;/tmp/pump.sock&amp;rdquo; to accept the communication of PUMP unix socket file.  --cross-join  To enable (true) or disable (false) the cross join without any equal conditions Default: true The value can be true or false.</description>
    </item>
    
    <item>
      <title>Connect with us</title>
      <link>https://pingcap.com/docs/community/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/community/</guid>
      <description> Connect with us  Twitter: @PingCAP Reddit: https://www.reddit.com/r/TiDB/ Stack Overflow: https://stackoverflow.com/questions/tagged/tidb Mailing list: Google Group  </description>
    </item>
    
    <item>
      <title>Connectors and APIs</title>
      <link>https://pingcap.com/docs/sql/connection-and-APIs/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/connection-and-APIs/</guid>
      <description>Connectors and APIs Database Connectors provide connectivity to the TiDB server for client programs. APIs provide low-level access to the MySQL protocol and MySQL resources. Both Connectors and the APIs enable you to connect and execute MySQL statements from another language or environment, including ODBC, Java (JDBC), Perl, Python, PHP, Ruby and C.
TiDB is compatible with all Connectors and APIs of MySQL (5.6, 5.7), including:
 MySQL Connector/C MySQL Connector/C++ MySQL Connector/J MySQL Connector/Net MySQL Connector/ODBC MySQL Connector/Python MySQL C API MySQL PHP API MySQL Perl API MySQL Python API MySQL Ruby APIs MySQL Tcl API MySQL Eiffel Wrapper Mysql Go API  Connect to TiDB using MySQL Connectors Oracle develops the following APIs and TiDB is compatible with all of them:</description>
    </item>
    
    <item>
      <title>Control Flow Functions</title>
      <link>https://pingcap.com/docs/sql/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/control-flow-functions/</guid>
      <description> Control Flow Functions    Name Description     CASE Case operator   IF() If/else construct   IFNULL() Null if/else construct   NULLIF() Return NULL if expr1 = expr2    </description>
    </item>
    
    <item>
      <title>Cross-Region Deployment</title>
      <link>https://pingcap.com/docs/op-guide/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/location-awareness/</guid>
      <description>Cross-Region Deployment Overview PD schedules according to the topology of the TiKV cluster to maximize the TiKV&amp;rsquo;s capability for disaster recovery.
Before you begin, see Ansible Deployment (Recommended) and Docker Deployment.
TiKV reports the topological information TiKV reports the topological information to PD according to the startup parameter or configuration of TiKV.
Assuming that the topology has three structures: zone &amp;gt; rack &amp;gt; host, use lables to specify the following information:</description>
    </item>
    
    <item>
      <title>DBA</title>
      <link>https://pingcap.com/recruit-cn/engineer/dba/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/dba/</guid>
      <description>DBA 岗位职责  负责上线用户和 POC 用户 TiDB 集群的日常运行维护，包括配置管理、升级、扩容、备份，数据迁移等工作
 对用户进行培训，介绍 TiDB 的原理和使用指导，总结并传授最佳实践
 负责用户的 TiDB 集群的监控，性能分析、问题跟踪与管理；
 7x24小时响应故障处理。
  职位要求  三年以上 MySQL/postgreSQL/Oracle 运维相关工作经验
 精通 MySQL 数据库配置、备份、优化、监控，擅长使用自动化运维脚本
 熟悉大规模 Linux 环境下数据库系统运营和维护
 高度的责任心、良好的沟通技巧和团队合作精神
  待遇 15K - 25K , 13薪 + 奖金, 优秀者可面议
工作地点 北京，上海，广州，杭州</description>
    </item>
    
    <item>
      <title>DDL</title>
      <link>https://pingcap.com/docs-cn/sql/ddl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/ddl/</guid>
      <description>数据定义语言 DDL（Data Definition Language）用于定义和管理数据库以及数据库中各种对象的语句。
CREATE DATABASE 语法 CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name [create_specification] ... create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name CREATE DATABASE 用于创建数据库，并可以指定数据库的默认属性（如数据库默认字符集,校验规则。CREATE SCHEMA 跟 CREATE DATABASE 操作效果一样。
当创建已存在的数据库且不指定使用 IF NOT EXISTS 时会报错。
create_specification 选项用于指定数据库具体的 CHARACTER SET 和 COLLATE。目前这个选项只是语法支持。
DROP DATABASE 语法 DROP {DATABASE | SCHEMA} [IF EXISTS] db_name DROP DATABASE 用于删除指定数据库以及它其中的所用表格。
IF EXISTS 用于防止当数据库不存在时发生错误。
CREATE TABLE 语法 CREATE TABLE [IF NOT EXISTS] tbl_name (create_definition,.</description>
    </item>
    
    <item>
      <title>Data Definition Statements</title>
      <link>https://pingcap.com/docs/sql/ddl/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/ddl/</guid>
      <description>Data Definition Statements DDL (Data Definition Language) is used to define the database structure or schema, and to manage the database and statements of various objects in the database.
CREATE DATABASE syntax CREATE {DATABASE | SCHEMA} [IF NOT EXISTS] db_name [create_specification] ... create_specification: [DEFAULT] CHARACTER SET [=] charset_name | [DEFAULT] COLLATE [=] collation_name The CREATE DATABASE statement is used to create a database, and to specify the default properties of the database, such as the default character set and validation rules.</description>
    </item>
    
    <item>
      <title>Database Administration Statements</title>
      <link>https://pingcap.com/docs/sql/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/admin/</guid>
      <description>Database Administration Statements TiDB manages the database using a number of statements, including granting privileges, modifying system variables, and querying database status.
Privilege management See Privilege Management.
SET statement The SET statement has multiple functions and forms.
Assign values to variables SET variable_assignment [, variable_assignment] ... variable_assignment: user_var_name = expr | param_name = expr | local_var_name = expr | [GLOBAL | SESSION] system_var_name = expr | [@@global. | @@session. | @@] system_var_name = expr You can use the above syntax to assign values to variables in TiDB, which include system variables and user-defined variables.</description>
    </item>
    
    <item>
      <title>Date and Time Functions</title>
      <link>https://pingcap.com/docs/sql/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/date-and-time-functions/</guid>
      <description>Date and Time Functions The usage of date and time functions is similar to MySQL. For more information, see here.
Date/Time functions
   Name Description     ADDDATE() Add time values (intervals) to a date value   ADDTIME() Add time   CONVERT_TZ() Convert from one time zone to another   CURDATE() Return the current date   CURRENT_DATE(), CURRENT_DATE Synonyms for CURDATE()   CURRENT_TIME(), CURRENT_TIME Synonyms for CURTIME()   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP Synonyms for NOW()   CURTIME() Return the current time   DATE() Extract the date part of a date or datetime expression   DATE_ADD() Add time values (intervals) to a date value   DATE_FORMAT() Format date as specified   DATE_SUB() Subtract a time value (interval) from a date   DATEDIFF() Subtract two dates   DAY() Synonym for DAYOFMONTH()   DAYNAME() Return the name of the weekday   DAYOFMONTH() Return the day of the month (0-31)   DAYOFWEEK() Return the weekday index of the argument   DAYOFYEAR() Return the day of the year (1-366)   EXTRACT() Extract part of a date   FROM_DAYS() Convert a day number to a date   FROM_UNIXTIME() Format Unix timestamp as a date   GET_FORMAT() Return a date format string   HOUR() Extract the hour   LAST_DAY Return the last day of the month for the argument   LOCALTIME(), LOCALTIME Synonym for NOW()   LOCALTIMESTAMP, LOCALTIMESTAMP() Synonym for NOW()   MAKEDATE() Create a date from the year and day of year   MAKETIME() Create time from hour, minute, second   MICROSECOND() Return the microseconds from argument   MINUTE() Return the minute from the argument   MONTH() Return the month from the date passed   MONTHNAME() Return the name of the month   NOW() Return the current date and time   PERIOD_ADD() Add a period to a year-month   PERIOD_DIFF() Return the number of months between periods   QUARTER() Return the quarter from a date argument   SEC_TO_TIME() Converts seconds to &amp;lsquo;HH:MM:SS&amp;rsquo; format   SECOND() Return the second (0-59)   STR_TO_DATE() Convert a string to a date   SUBDATE() Synonym for DATE_SUB() when invoked with three arguments   SUBTIME() Subtract times   SYSDATE() Return the time at which the function executes   TIME() Extract the time portion of the expression passed   TIME_FORMAT() Format as time   TIME_TO_SEC() Return the argument converted to seconds   TIMEDIFF() Subtract time   TIMESTAMP() With a single argument, this function returns the date or datetime expression; with two arguments, the sum of the arguments   TIMESTAMPADD() Add an interval to a datetime expression   TIMESTAMPDIFF() Subtract an interval from a datetime expression   TO_DAYS() Return the date argument converted to days   TO_SECONDS() Return the date or datetime argument converted to seconds since Year 0   UNIX_TIMESTAMP() Return a Unix timestamp   UTC_DATE() Return the current UTC date   UTC_TIME() Return the current UTC time   UTC_TIMESTAMP() Return the current UTC date and time   WEEK() Return the week number   WEEKDAY() Return the weekday index   WEEKOFYEAR() Return the calendar week of the date (1-53)   YEAR() Return the year   YEARWEEK() Return the year and week    For details, see here.</description>
    </item>
    
    <item>
      <title>Date 和 Time 字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-date-and-time-literals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-date-and-time-literals/</guid>
      <description>Date and Time Literals Date 跟 Time 字面值有几种格式，例如用字符串表示，或者直接用数字表示。在 TiDB 里面，当 TiDB 期望一个 Date 的时候，它会把 &#39;2017-08-24&#39;， &#39;20170824&#39;，20170824 当做是 Date。
TiDB 的 Date 值有以下几种格式：
 &#39;YYYY-MM-DD&#39; 或者 &#39;YY-MM-DD&#39;，这里的 - 分隔符并不是严格的，可以是任意的标点符号。比如 &#39;2017-08-24&#39;，&#39;2017&amp;amp;08&amp;amp;24&#39;， &#39;2012@12^31&#39; 都是一样的。唯一需要特别对待的是 &amp;lsquo;.&amp;rsquo; 号，它被当做是小数点，用于分隔整数和小数部分。 Date 和 Time 部分可以被 &amp;rsquo;T&amp;rsquo; 分隔，它的作用跟空格符是一样的，例如 2017-8-24 10:42:00 跟 2017-8-24T10:42:00 是一样的。 &#39;YYYYMMDDHHMMSS&#39; 或者 &#39;YYMMDDHHMMSS&#39;，例如 &#39;20170824104520&#39; 和 &#39;170824104520&#39; 被当做是 &#39;2017-08-24 10:45:20&#39;，但是如果你提供了一个超过范围的值，例如&#39;170824304520&#39;，那这就不是一个有效的 Date 字面值。 YYYYMMDDHHMMSS 或者 YYMMDDHHMMSS 注意这里没有单引号或者双引号，是一个数字。例如 20170824104520表示为 &#39;2017-08-24 10:45:20&#39;。  DATETIME 或者 TIMESTAMP 值可以接一个小数部分，用来表示微秒（精度最多到小数点后 6 位），用小数点 .</description>
    </item>
    
    <item>
      <title>Deploy TiDB Using the Binary</title>
      <link>https://pingcap.com/docs/op-guide/binary-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/binary-deployment/</guid>
      <description>Deploy TiDB Using the Binary Overview A complete TiDB cluster contains PD, TiKV, and TiDB. To start the database service, follow the order of PD -&amp;gt; TiKV -&amp;gt; TiDB. To stop the database service, follow the order of stopping TiDB -&amp;gt; TiKV -&amp;gt; PD.
Before you start, see TiDB architecture and Software and Hardware Requirements.
This document describes the binary deployment of three scenarios:
 To quickly understand and try TiDB, see Single node cluster deployment.</description>
    </item>
    
    <item>
      <title>Enable TLS Authentication</title>
      <link>https://pingcap.com/docs/op-guide/security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/security/</guid>
      <description>Enable TLS Authentication Overview This document describes how to enable TLS authentication in the TiDB cluster. The TLS authentication includes the following two conditions:
 The mutual authentication between TiDB components, including the authentication among TiDB, TiKV and PD, between TiKV Control and TiKV, between PD Control and PD, between TiKV peers, and between PD peers. Once enabled, the mutual authentication applies to all components, and it does not support applying to only part of the components.</description>
    </item>
    
    <item>
      <title>Encryption and Compression Functions</title>
      <link>https://pingcap.com/docs/sql/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/encryption-and-compression-functions/</guid>
      <description> Encryption and Compression Functions    Name Description     MD5() Calculate MD5 checksum   PASSWORD() (deprecated 5.7.6) Calculate and return a password string   RANDOM_BYTES() Return a random byte vector   SHA1(), SHA() Calculate an SHA-1 160-bit checksum   SHA2() Calculate an SHA-2 checksum   AES_DECRYPT() Decrypt using AES   AES_ENCRYPT() Encrypt using AES   COMPRESS() Return result as a binary string   UNCOMPRESS() Uncompress a string compressed   UNCOMPRESSED_LENGTH() Return the length of a string before compression   CREATE_ASYMMETRIC_PRIV_KEY() Create private key   CREATE_ASYMMETRIC_PUB_KEY() Create public key   CREATE_DH_PARAMETERS() Generate shared DH secret   CREATE_DIGEST() Generate digest from string   ASYMMETRIC_DECRYPT() Decrypt ciphertext using private or public key   ASYMMETRIC_DERIVE() Derive symmetric key from asymmetric keys   ASYMMETRIC_ENCRYPT() Encrypt cleartext using private or public key   ASYMMETRIC_SIGN() Generate signature from digest   ASYMMETRIC_VERIFY() Verify that signature matches digest    </description>
    </item>
    
    <item>
      <title>Error Codes and Troubleshooting</title>
      <link>https://pingcap.com/docs/sql/error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/error/</guid>
      <description>Error Codes and Troubleshooting This document describes the problems encountered during the use of TiDB and provides the solutions.
Error codes TiDB is compatible with the error codes in MySQL, and in most cases returns the same error code as MySQL. In addition, TiDB has the following unique error codes:
   Error code Description Solution     9001 The PD request timed out. Check the state/monitor/log of the PD server and the network between the TiDB server and the PD server.</description>
    </item>
    
    <item>
      <title>Expression Syntax</title>
      <link>https://pingcap.com/docs/sql/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/expression-syntax/</guid>
      <description>Expression Syntax The following rules define the expression syntax in TiDB. You can find the definition in parser/parser.y. The syntax parsing in TiDB is based on Yacc.
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>Front End Engineer</title>
      <link>https://pingcap.com/recruit-cn/campus/frontend-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/frontend-engineer/</guid>
      <description>Front End Engineer 职位描述 这是一个对我们这种做「后端」的公司非常重要的岗位，直接关系到我们能够提供一个什么「样子」的解决方案给我们的客户。 我们需要把技术上复杂的算法和逻辑隐藏起来，让开发者没有心智负担的使用，而不是终日面对冰冷的命令行接口狂敲。一个现代的商用基础软件，流畅优雅的 UI/UE 必不可少，我们对设计和交互的偏执等同于分布式算法和测试的偏执，不可分割。我们在后边的一切工作和炫酷的技术，都需要同样炫酷的前端来落地。
我们在 enjoy 这个「造物」的过程，希望邀你一起。
哦，对了，我们的技术栈：
 Bootstrap Vue.js AngularJS ReactJS HighChart Gulp Less  我们对于前端工程师没有其他别的要求，就是对于「美」有所追求，充满好奇心：）
待遇 15K - 20K + 期权, 13薪 + 奖金
联系方式： hire@pingcap.com
工作地点 北京</description>
    </item>
    
    <item>
      <title>Function and Operator Reference</title>
      <link>https://pingcap.com/docs/sql/functions-and-operators-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/functions-and-operators-reference/</guid>
      <description>Function and Operator Reference The usage of the functions and operators in TiDB is similar to MySQL. See Functions and Operators in MySQL.
In SQL statements, expressions can be used on the ORDER BY and HAVING clauses of the SELECT statement, the WHERE clause of SELECT/DELETE/UPDATE statements, and SET statements.
You can write expressions using literals, column names, NULL, built-in functions, operators and so on.</description>
    </item>
    
    <item>
      <title>GROUP BY 聚合函数</title>
      <link>https://pingcap.com/docs-cn/sql/aggregate-group-by-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/aggregate-group-by-functions/</guid>
      <description>GROUP BY 聚合函数 GROUP BY 聚合函数功能描述 本节介绍 TiDB 中支持的 MySQL GROUP BY 聚合函数。
   函数名 功能描述     COUNT() 返回检索到的行的数目   COUNT(DISTINCT) 返回不同值的数目   SUM() 返回和   AVG() 返回平均值   MAX() 返回最大值   MIN() 返回最小值   GROUP_CONCAT() 返回连接的字符串     Note:
 除非另有说明，否则组函数默认忽略 NULL 值。 如果在不包含 GROUP BY 子句的语句中使用组函数，则相当于对所有行进行分组。详情参阅 TiDB 中的 GROUP BY。   GROUP BY 修饰符 TiDB 目前不支持任何 GROUP BY 修饰符，将来会提供支持，详情参阅 #4250。</description>
    </item>
    
    <item>
      <title>Generate Self-signed Certificates</title>
      <link>https://pingcap.com/docs/op-guide/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/generate-self-signed-certificates/</guid>
      <description>Generate Self-signed Certificates Overview This document describes how to generate self-signed certificates using cfssl.
Assume that the topology of the instance cluster is as follows:
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    Download cfssl Assume that the host is x86_64 Linux:</description>
    </item>
    
    <item>
      <title>Information Functions</title>
      <link>https://pingcap.com/docs/sql/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/information-functions/</guid>
      <description> Information Functions In TiDB, the usage of information functions is similar to MySQL. For more information, see Information Functions.
Information function descriptions    Name Description     CONNECTION_ID() Return the connection ID (thread ID) for the connection   CURRENT_USER(), CURRENT_USER Return the authenticated user name and host name   DATABASE() Return the default (current) database name   FOUND_ROWS() For a SELECT with a LIMIT clause, the number of the rows that are returned if there is no LIMIT clause   LAST_INSERT_ID() Return the value of the AUTOINCREMENT column for the last INSERT   SCHEMA() Synonym for DATABASE()   SESSION_USER() Synonym for USER()   SYSTEM_USER() Synonym for USER()   USER() Return the user name and host name provided by the client   VERSION() Return a string that indicates the MySQL server version   TIDB_VERSION Return a string that indicates the TiDB server version    </description>
    </item>
    
    <item>
      <title>Infrastructure Engineer</title>
      <link>https://pingcap.com/recruit-cn/campus/infrastructure-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/infrastructure-engineer/</guid>
      <description>Infrastructure Engineer 职位描述 如果你：
 内心不安，喜欢挑战和创新 熟悉分布式系统，大数据或者数据库领域 想和简单有爱的 PingCAP 的工程师们一起做世界级的开源项目  那么你就是我们要找的人。
在分布式数据库领域有很多迷人的问题需要去解决，如果你对任何一个问题感到无比的好奇，想要深挖究竟，都可以来和我们聊聊:
 想深入理解业界最前沿的分布式数据库 Spanner 的设计和思考，如何从 0 到 1 落地实现 如何设计和实现世界前沿的分布式 SQL 优化器，让一个复杂的 SQL 查询变的无比轻快智能 如何在成千上万台集群规模的情况下，实现无阻塞的表结构变更操作，而不影响任何在线的业务 如何实现一个高效的分布式事务管理器，让 ACID 事务在大规模并发的分布式存场景下依然可以高效可靠 如何基于一致性的 Raft 协议实现快速稳定的数据复制和自动故障恢复，确保数据安全 如何在一个 PR 提交之后，快速验证千万级别的 tests 是否全部通过，性能有没有显著提升  &amp;hellip; &amp;hellip;
待遇 15K - 20K + 期权, 13薪 + 奖金
联系方式： hire@pingcap.com
工作地点 北京，上海，广州，杭州</description>
    </item>
    
    <item>
      <title>Infrastructure Engineer Intern</title>
      <link>https://pingcap.com/recruit-cn/campus/infrastructure-engineer-intern/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/campus/infrastructure-engineer-intern/</guid>
      <description>Infrastructure Engineer Intern 职位描述 你能从工作中学习到什么？
 如何构建一个分布式关系数据库 如何将其包装成为一套完整的商业产品 亲身参与以上过程，并实践你所掌握的开发技术 成为未来具有全球影响力的开源分布式数据库产品的早期贡献者  要求：
 熟悉常用的开发语言，熟悉 Golang/Rust 优先 熟悉分布式系统/数据库系统优先 有开源项目实践经历优先 实习优秀者可获得正式工作机会，并有期权  待遇 250 * 8小时，水果零食，购书补助等等
联系方式： hire@pingcap.com
工作地点 北京，上海，广州，杭州</description>
    </item>
    
    <item>
      <title>Introduction to Statistics</title>
      <link>https://pingcap.com/docs/sql/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/statistics/</guid>
      <description>Introduction to Statistics Based on the statistics, the TiDB optimizer chooses the most efficient query execution plan. The statistics collect table-level and column-level information. The statistics of a table include the total number of rows and the number of updated rows. The statistics of a column include the number of different values, the number of NULL, and the histogram of the column.
Collect statistics Manual collection You can run the ANALYZE statement to collect statistics.</description>
    </item>
    
    <item>
      <title>JSON Functions</title>
      <link>https://pingcap.com/docs/sql/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/json-functions/</guid>
      <description> JSON Functions    Function Name and Syntactic Sugar Description     JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) Return data from a JSON document, selected from the parts of the document matched by the path arguments   JSON_UNQUOTE(json_val) Unquote JSON value and return the result as a utf8mb4 string   JSON_TYPE(json_val) Return a utf8mb4 string indicating the type of a JSON value   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) Insert or update data in a JSON document and return the result   JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) Insert data into a JSON document and return the result   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) Replace existing values in a JSON document and return the result   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) Remove data from a JSON document and return the result   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) Merge two or more JSON documents and return the merged result   JSON_OBJECT(key, val[, key, val] &amp;hellip;) Evaluate a (possibly empty) list of key-value pairs and return a JSON object containing those pairs   JSON_ARRAY([val[, val] &amp;hellip;]) Evaluate a (possibly empty) list of values and return a JSON array containing those values   -&amp;gt; Return value from JSON column after evaluating path; the syntactic sugar of JSON_EXTRACT(doc, path_literal)   -&amp;gt;&amp;gt; Return value from JSON column after evaluating path and unquoting the result; the syntactic sugar of JSON_UNQUOTE(JSONJSON_EXTRACT(doc, path_literal))    </description>
    </item>
    
    <item>
      <title>JSON Functions and Generated Column</title>
      <link>https://pingcap.com/docs/sql/json-functions-generated-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/json-functions-generated-column/</guid>
      <description>JSON Functions and Generated Column About To be compatible with MySQL 5.7 or later and better support the document store, TiDB supports JSON in the latest version. In TiDB, a document is a set of Key-Value pairs, encoded as a JSON object. You can use the JSON datatype in a TiDB table and create indexes for the JSON document fields using generated columns. In this way, you can flexibly deal with the business scenarios with uncertain schema and are no longer limited by the read performance and the lack of support for transactions in traditional document databases.</description>
    </item>
    
    <item>
      <title>JSON 函数及 Generated Column</title>
      <link>https://pingcap.com/docs-cn/sql/json-functions-generated-column/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/json-functions-generated-column/</guid>
      <description>JSON 函数及 Generated Column 概述 为了在功能上兼容 MySQL 5.7 及以上，同时更好地支持文档类型存储，我们在最新版本的 TiDB 中加入了 JSON 的支持。TiDB 所支持的文档是指以 JSON 为编码类型的键值对的组合。用户可以在 TiDB 的表中使用 JSON 类型的字段，同时以生成列（generated column）的方式为 JSON 文档内部的字段建立索引。基于此，用户可以很灵活地处理那些 schema 不确定的业务，同时不必受限于传统文档数据库糟糕的读性能及匮乏的事务支持。
JSON功能介绍 TiDB 的 JSON 主要参考了 MySQL 5.7 的用户接口。例如，可以创建一个表，包含一个 JSON 字段来存储那些复杂的信息：
CREATE TABLE person ( id INT NOT NULL AUTO_INCREMENT PRIMARY KEY, name VARCHAR(255) NOT NULL, address_info JSON ); 当我们向表中插入数据时，便可以这样处理那些模式不确定的数据了：
INSERT INTO person (name, address_info) VALUES (&amp;#34;John&amp;#34;, &amp;#39;{&amp;#34;city&amp;#34;: &amp;#34;Beijing&amp;#34;}&amp;#39;); 就这么简单！直接在 JSON 字段对应的位置上，放一个合法的 JSON 字符串，就可以向表中插入 JSON 了。TiDB 会解析这个文本，然后以一种更加紧凑、易于访问的二进制形式来保存。</description>
    </item>
    
    <item>
      <title>JSON 相关的函数和语法糖</title>
      <link>https://pingcap.com/docs-cn/sql/json-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/json-functions/</guid>
      <description> JSON 相关的函数和语法糖    函数或语法糖 功能描述     JSON_EXTRACT(json_doc, path[, path] &amp;hellip;) 从 JSON 文档中解出某一路径对应的子文档   JSON_UNQUOTE(json_val) 去掉 JSON 文档外面的引号   JSON_TYPE(json_val) 检查某 JSON 文档内部内容的类型   JSON_SET(json_doc, path, val[, path, val] &amp;hellip;) 在 JSON 文档中为某一路径设置子文档   JSON_INSERT(json_doc, path, val[, path, val] &amp;hellip;) 在 JSON 文档中在某一路径下插入子文档   JSON_REPLACE(json_doc, path, val[, path, val] &amp;hellip;) 替换 JSON 文档中的某一路径下的子文档   JSON_REMOVE(json_doc, path[, path] &amp;hellip;) 移除 JSON 文档中某一路径下的子文档   JSON_MERGE(json_doc, json_doc[, json_doc] &amp;hellip;) 将多个 JSON 文档合并成一个文档，其类型为数组   JSON_OBJECT(key, val[, key, val] &amp;hellip;) 根据一系列 K/V 对创建一个 JSON 文档   JSON_ARRAY([val[, val] &amp;hellip;]) 根据一系列元素创建一个 JSON 文档   -&amp;gt; JSON_EXTRACT(doc, path_literal) 的语法糖   -&amp;gt;&amp;gt; JSON_UNQUOTE(JSONJSON_EXTRACT(doc, path_literal)) 的语法糖    </description>
    </item>
    
    <item>
      <title>Key Metrics</title>
      <link>https://pingcap.com/docs/op-guide/dashboard-overview-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/dashboard-overview-info/</guid>
      <description>Key Metrics If you use Ansible to deploy TiDB cluster, you can deploy the monitoring system at the same time. See Overview of the Monitoring Framework for more information.
The Grafana dashboard is divided into four sub dashboards: node_export, PD, TiKV, and TiDB. There are a lot of metics there to help you diagnose. For routine operations, some of the key metrics are displayed on the Overview dashboard so that you can get the overview of the status of the components and the entire cluster.</description>
    </item>
    
    <item>
      <title>Keywords and Reserved Words</title>
      <link>https://pingcap.com/docs-cn/sql/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/keywords-and-reserved-words/</guid>
      <description>Keywords and Reserved Words 关键字在 SQL 中有特殊的意义， 例如 SELECT， UPDATE， DELETE，在作为表名跟函数名的时候，需要特殊对待，例如作为表名，保留字需要被反引号包住：
mysql&amp;gt; CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27) mysql&amp;gt; CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.09 sec) BEGIN 和 END 是关键字， 但不是保留字，所以不需要反引号：
mysql&amp;gt; CREATE TABLE `select` (BEGIN int, END int); Query OK, 0 rows affected (0.09 sec) 有一种特殊情况， 如果使用了限定符 .，那么也不需要用反引号：
mysql&amp;gt; CREATE TABLE test.</description>
    </item>
    
    <item>
      <title>Keywords and Reserved Words</title>
      <link>https://pingcap.com/docs/sql/keywords-and-reserved-words/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/keywords-and-reserved-words/</guid>
      <description>Keywords and Reserved Words Keywords are words that have significance in SQL. Certain keywords, such as SELECT, UPDATE, or DELETE, are reserved and require special treatment for use as identifiers such as table and column names. For example, as table names, the reserved words must be quoted with backquotes:
mysql&amp;gt; CREATE TABLE select (a INT); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a INT)&amp;#34; (total length 27) mysql&amp;gt; CREATE TABLE `select` (a INT); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Literal Values</title>
      <link>https://pingcap.com/docs/sql/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/literal-values/</guid>
      <description>Literal Values String literals A string is a sequence of bytes or characters, enclosed within either single quote &#39; or double quote &amp;quot; characters. For example:
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; Quoted strings placed next to each other are concatenated to a single string. The following lines are equivalent:
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; If the ANSI_QUOTES SQL MODE is enabled, string literals can be quoted only within single quotation marks because a string quoted within double quotation marks is interpreted as an identifier.</description>
    </item>
    
    <item>
      <title>Loader Instructions</title>
      <link>https://pingcap.com/docs/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/loader/</guid>
      <description>Loader Instructions What is Loader? Loader is a data import tool to load data to TiDB.
Download the Binary.
Why did we develop Loader? Since tools like mysqldump will take us days to migrate massive amounts of data, we used the mydumper/myloader suite of Percona to multi-thread export and import data. During the process, we found that mydumper works well. However, as myloader lacks functions of error retry and savepoint, it is inconvenient for us to use.</description>
    </item>
    
    <item>
      <title>Loader 使用文档</title>
      <link>https://pingcap.com/docs-cn/tools/loader/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/loader/</guid>
      <description>Loader 使用文档 Loader 是什么 是由 PingCAP 开发的数据导入工具，可以用于向 TiDB 中导入数据。
Binary 下载
为什么我们要做这个东西 当数据量比较大的时候，如果用 mysqldump 这样的工具迁移数据会比较慢。我们尝试了 Percona 的 mydumper/myloader 套件，能够多线程导出和导入数据。在使用过程中，mydumper 问题不大，但是 myloader 由于缺乏出错重试、断点续传这样的功能，使用起来很不方便。所以我们开发了 loader，能够读取 mydumper 的输出数据文件，通过 mysql protocol 向 TiDB/MySQL 中导入数据。
Loader 有哪些优点  多线程导入
 支持表级别的并发导入，分散写入热点
 支持对单个大表并发导入，分散写入热点
 支持 mydumper 数据格式
 出错重试
 断点续导
 通过 system variable 优化 TiDB 导入数据速度
  使用方法 注意事项 请勿使用 loader 导入 MySQL 实例中 mysql 系统数据库到下游 TiDB。
如果 mydumper 使用 -m 参数，会导出不带表结构的数据，这时 loader 无法导入数据。</description>
    </item>
    
    <item>
      <title>Migrate Data from MySQL to TiDB</title>
      <link>https://pingcap.com/docs/op-guide/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/migration/</guid>
      <description>Migrate Data from MySQL to TiDB Use the mydumper / loader tool to export and import all the data You can use mydumper to export data from MySQL and loader to import the data into TiDB.
 Note: Although TiDB also supports the official mysqldump tool from MySQL for data migration, it is not recommended to use it. Its performance is much lower than mydumper / loader and it takes much time to migrate large amounts of data.</description>
    </item>
    
    <item>
      <title>Migration Overview</title>
      <link>https://pingcap.com/docs/op-guide/migration-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/migration-overview/</guid>
      <description>Migration Overview Overview This document describes how to migrate data from MySQL to TiDB in detail.
See the following for the assumed MySQL and TiDB server information:
   Name Address Port User Password     MySQL 127.0.0.1 3306 root *   TiDB 127.0.0.1 4000 root *    Scenarios  To import all the history data. This needs the following tools:
 Checker: to check if the shema is compatible with TiDB.</description>
    </item>
    
    <item>
      <title>Miscellaneous Functions</title>
      <link>https://pingcap.com/docs/sql/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/miscellaneous-functions/</guid>
      <description> Miscellaneous Functions    Name Description     ANY_VALUE() Suppress ONLY_FULL_GROUP_BY value rejection   SLEEP() Sleep for a number of seconds   UUID() Return a Universal Unique Identifier (UUID)   VALUES() Defines the values to be used during an INSERT   INET_ATON() Return the numeric value of an IP address   INET_NTOA() Return the IP address from a numeric value   INET6_ATON() Return the numeric value of an IPv6 address   INET6_NTOA() Return the IPv6 address from a numeric value   IS_IPV4() Whether argument is an IPv4 address   IS_IPV4_COMPAT() Whether argument is an IPv4-compatible address   IS_IPV4_MAPPED() Whether argument is an IPv4-mapped address   IS_IPV6() Whether argument is an IPv6 address   GET_LOCK() Get a named lock   RELEASE_LOCK() Releases the named lock    </description>
    </item>
    
    <item>
      <title>Monitor a TiDB Cluster</title>
      <link>https://pingcap.com/docs/op-guide/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/monitor/</guid>
      <description>Monitor a TiDB Cluster Currently there are two types of interfaces to monitor the state of the TiDB cluster:
 Using the HTTP interface to get the internal information of a component, which is called the component state interface. Using Prometheus to record the detailed information of the various operations in the components, which is called the Metrics interface.  The component state interface You can use this type of interface to monitor the basic information of the component.</description>
    </item>
    
    <item>
      <title>NULL Values</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-null-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-null-values/</guid>
      <description>NULL Values NULL 代表数据为空，它是大小写不敏感的，与 \N(大小写敏感) 同义。
需要注意的是 NULL 跟 0 并不一样，跟空字符串 &#39;&#39; 也不一样。</description>
    </item>
    
    <item>
      <title>Numeric Functions and Operators</title>
      <link>https://pingcap.com/docs/sql/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/numeric-functions-and-operators/</guid>
      <description> Numeric Functions and Operators Arithmetic operators    Name Description     + Addition operator   - Minus operator   * Multiplication operator   / Division operator   DIV Integer division   %, MOD Modulo operator   - Change the sign of the argument    Mathematical functions    Name Description     POW() Return the argument raised to the specified power   POWER() Return the argument raised to the specified power   EXP() Raise to the power of   SQRT() Return the square root of the argument   LN() Return the natural logarithm of the argument   LOG() Return the natural logarithm of the first argument   LOG2() Return the base-2 logarithm of the argument   LOG10() Return the base-10 logarithm of the argument   PI() Return the value of pi   TAN() Return the tangent of the argument   COT() Return the cotangent   SIN() Return the sine of the argument   COS() Return the cosine   ATAN() Return the arc tangent   ATAN2(), ATAN() Return the arc tangent of the two arguments   ASIN() Return the arc sine   ACOS() Return the arc cosine   RADIANS() Return argument converted to radians   DEGREES() Convert radians to degrees   MOD() Return the remainder   ABS() Return the absolute value   CEIL() Return the smallest integer value not less than the argument   CEILING() Return the smallest integer value not less than the argument   FLOOR() Return the largest integer value not greater than the argument   ROUND() Round the argument   RAND() Return a random floating-point value   SIGN() Return the sign of the argument   CONV() Convert numbers between different number bases   TRUNCATE() Truncate to specified number of decimal places   CRC32() Compute a cyclic redundancy check value    </description>
    </item>
    
    <item>
      <title>OPS Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/ops-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/ops-engineer/</guid>
      <description>OPS Engineer 岗位职责  维护 TiDB 集群在用户生产系统中平稳运行，包括产品部署、配置管理、系统监控和线上诊断，及时应对和处理相关模块的线上问题
 负责公司内部软硬件资源管理和内部系统配置管理
 研究分布式系统前沿技术，改进系统的服务和运维架构，提升系统可靠性和可运维性
 探索、研究新的运维自动化技术和方向
  职位要求  两年以上互联网公司运维经验，至少熟练掌握 Python/shell/php 等1种脚本语言
 有 web server、分布式系统、负载均衡，系统监控等运维经验，熟悉 nginx，lvs，keepalived，zabbix，mysql，redis 等常用开源系统的搭建，配置，优化
 有自动化运维经验，熟悉 puppet/ansible/saltstack
 对容器有一定的了解，有 docker 使用经验
 高度的责任心、良好的沟通技巧和团队合作精神
  待遇 15K - 25K , 13薪 + 奖金, 优秀者可面议
工作地点 北京，上海，广州，杭州</description>
    </item>
    
    <item>
      <title>Offline Deployment Using Ansible</title>
      <link>https://pingcap.com/docs/op-guide/offline-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/offline-ansible-deployment/</guid>
      <description>Offline Deployment Using Ansible Prepare Before you start, make sure that you have:
 A download machine
 The machine must have access to the Internet in order to download TiDB-Ansible, TiDB and related packages. For Linux operating system, it is recommended to install CentOS 7.3 or later.  Several target machines and one Control Machine
 For system requirements and configuration, see Prepare the environment. It is acceptable without access to the Internet.</description>
    </item>
    
    <item>
      <title>Overview of the TiDB Monitoring Framework</title>
      <link>https://pingcap.com/docs/op-guide/monitor-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/monitor-overview/</guid>
      <description>Overview of the Monitoring Framework The TiDB monitoring framework adopts two open source projects: Prometheus and Grafana. TiDB uses Prometheus to store the monitoring and performance metrics and Grafana to visualize these metrics.
About Prometheus in TiDB As a time series database, Prometheus has a multi-dimensional data model and flexible query language. As one of the most popular open source projects, many companies and organizations have adopted Prometheus, and the project has a very active community.</description>
    </item>
    
    <item>
      <title>PD Control User Guide</title>
      <link>https://pingcap.com/docs/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/pd-control/</guid>
      <description>PD Control User Guide As a command line tool of PD, PD Control obtains the state information of the cluster and tunes the cluster.
Source code compiling  Go Version 1.7 or later In the PD root directory, use the make command to compile and generate bin/pd-ctl   Note: Generally, you don&amp;rsquo;t need to compile source code as the PD Control tool already exists in the released Binary or Docker.</description>
    </item>
    
    <item>
      <title>PD Control 使用说明</title>
      <link>https://pingcap.com/docs-cn/tools/pd-control/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/pd-control/</guid>
      <description>PD Control 使用说明 PD Control 是 PD 的命令行工具，用于获取集群状态信息和调整集群。
源码编译  Go Version 1.7 以上 在 PD 项目根目录使用 make 命令进行编译，生成 bin/pd-ctl  简单例子 单命令模式：
./pd-ctl store -d -u http://127.0.0.1:2379 交互模式：
./pd-ctl -u http://127.0.0.1:2379 使用环境变量：
export PD_ADDR=http://127.0.0.1:2379 ./pd-ctl 使用TLS加密：
./pd-ctl -u https://127.0.0.1:2379 --cacert=&amp;#34;path/to/ca&amp;#34; --cert=&amp;#34;path/to/cert&amp;#34; --key=&amp;#34;path/to/key&amp;#34; 命令行参数(flags) --pd,-u  指定 PD 的地址 默认地址: http://127.0.0.1:2379 环境变量: PD_ADDR  --detach,-d  使用单命令行模式(不进入 readline ) 默认值: false  &amp;ndash;cacert  指定 PEM 格式的受信任 CA 的证书文件路径 默认值: &amp;ldquo;&amp;rdquo;  &amp;ndash;cert  指定 PEM 格式的 SSL 证书文件路径 默认值: &amp;ldquo;&amp;rdquo;  &amp;ndash;key  指定 PEM 格式的 SSL 证书密钥文件路径，即 --cert 所指定的证书的私钥 默认值: &amp;ldquo;&amp;rdquo;  &amp;ndash;version,-V  打印版本信息并退出 默认值: false  命令(command) cluster 用于显示集群基本信息。</description>
    </item>
    
    <item>
      <title>PR经理</title>
      <link>https://pingcap.com/recruit-cn/market/pr-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/market/pr-manager/</guid>
      <description>PR经理 岗位职责  负责公司媒体资源开拓、谈判、合作和后期运营
 负责公关稿件的撰写、公关传播方案、市场推广宣传方案的策划，提高品牌美誉度
 策划主持公关专题活动，协调处理各方面的关系
 分析评估公关及活动效果、检测市场反应，及时优化调整活动策略
  职位要求  本科及以上，新闻专业出身，有良好的写作能力，2年以上科技媒体或商业媒体的采编工作经验
 熟悉各类型的媒体，具有一定的媒体资源
 熟悉公关宣传活动策划和执行流程
 对各类人士的接触及交往能力较好，能够维护良好人际关系
 对科技行业，互联网创业，企业级服务，数据库、开源等领域的发展趋势有浓厚兴趣
 英文好为加分项
  待遇 15K - 30K ，13薪 + 奖金，优秀者可面议
工作地点 北京</description>
    </item>
    
    <item>
      <title>Pre-GA release notes</title>
      <link>https://pingcap.com/docs/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/prega/</guid>
      <description> Pre-GA Release Notes On August 30, 2017, TiDB Pre-GA is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Use index scan to handle the where clause with the compare expression which has different types on each side Support the Greedy algorithm based Join Reorder  Many enhancements have been introduced to be more compatible with MySQL Support Natural Join Support the JSON type (Experimental), including the query, update and index of the JSON fields Prune the useless data to reduce the consumption of the executor memory Support configuring prioritization in the SQL statements and automatically set the prioritization for some of the statements according to the query type Completed the expression refactor and the speed is increased by about 30%  Placement Driver (PD):  Support manually changing the leader of the PD cluster  TiKV:  Use dedicated Rocksdb instance to store Raft log Use DeleteRange to speed up the deleting of replicas Coprocessor now supports more pushdown operators Improve the performance and stability  TiDB Connector for Spark Beta Release:  Implement the predicates pushdown Implement the aggregation pushdown Implement range pruning Capable of running full set of TPC+H except for one query that needs view support  </description>
    </item>
    
    <item>
      <title>Precision Math</title>
      <link>https://pingcap.com/docs/sql/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/precision-math/</guid>
      <description>Precision Math The precision math support in TiDB is consistent with MySQL. For more information, see Precision Math in MySQL.
Numeric types The scope of precision math for exact-value operations includes the exact-value data types (integer and DECIMAL types) and exact-value numeric literals. Approximate-value data types and numeric literals are handled as floating-point numbers.
Exact-value numeric literals have an integer part or fractional part, or both. They may be signed.</description>
    </item>
    
    <item>
      <title>Prepared SQL Statement Syntax</title>
      <link>https://pingcap.com/docs/sql/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/prepare/</guid>
      <description>Prepared SQL Statement Syntax TiDB supports server-side Prepared statements, which can reduce the load of statement parsing and query optimization and improve execution efficiency. You can use Prepared statements in two ways: application programs and SQL statements.
Use application programs Most MySQL Drivers support Prepared statements, such as MySQL Connector/C. You can call the Prepared statement API directly through the Binary protocol.
Use SQL statements You can also implement Prepared statements using PREPARE, EXECUTE and DEALLOCATE PREPARE.</description>
    </item>
    
    <item>
      <title>Prepared SQL 语句语法</title>
      <link>https://pingcap.com/docs-cn/sql/prepare/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/prepare/</guid>
      <description>Prepared SQL 语句语法 TiDB 支持服务器端的 Prepared 语句，这种方式可以降低语句解析以及查询优化的开销，提高执行效率。有两种方式可以使用 Prepared 语句：
通过应用程序 大多数 MySQL Driver 都支持 Prepared 语句，比如 MySQL Connector/C。这种方式可以通过 Binary 协议直接调用 Prepared 语句 API。
通过 SQL 语句 通过 PREPARE，EXECUTE 以及 DEALLOCATE PREPARE 这三个语句也可以实现 Prepared 语句，这种方式不如第一种方式效率高，但是不需要写程序即可使用。
PREPARE 语句 PREPARE stmt_name FROM preparable_stmt PREPARE 语句对 preparable_stmt 做预处理（语法解析、语义检查、查询优化）并将其处理结果命名为 stmt_name，后面的操作可以通过 stmt_name 来引用。处理好的语句可以通过 EXECUTE 语句执行或者是通过 DEALLOCATE PREPARE 语句释放。
EXECUTE 语句 EXECUTE stmt_name [USING @var_name [, @var_name] ...] EXECUTE 语句执行名字为 stmt_name 的预处理语句。如果预处理语句中有参数，则可以通过 USING 子句中的 User Variable 列表给参数赋值。</description>
    </item>
    
    <item>
      <title>Privilege Management</title>
      <link>https://pingcap.com/docs/sql/privilege/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/privilege/</guid>
      <description>Privilege Management Privilege management overview TiDB&amp;rsquo;s privilege management system is implemented according to the privilege management system in MySQL. It supports most of the syntaxes and privilege types in MySQL. If you find any inconsistency with MySQL, feel free to open an issue.
Examples User account operation TiDB user account names consist of a user name and a host name. The account name syntax is &#39;user_name&#39;@&#39;host_name&#39;.
 The user_name is case sensitive.</description>
    </item>
    
    <item>
      <title>Reading Data from History Versions</title>
      <link>https://pingcap.com/docs/op-guide/history-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/history-read/</guid>
      <description>Reading Data From History Versions This document describes how TiDB reads data from the history versions, how TiDB manages the data versions, as well as an example to show how to use the feature.
Feature description TiDB implements a feature to read history data using the standard SQL interface directly without special clients or drivers. By using this feature, - Even when data is updated or removed, its history versions can be read using the SQL interface.</description>
    </item>
    
    <item>
      <title>Release Notes</title>
      <link>https://pingcap.com/docs/releases/rn/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rn/</guid>
      <description> TiDB Release Notes  1.0.8 1.0.7 1.1 Alpha 1.0.6 1.0.5 1.0.4 1.0.3 1.0.2 1.0.1 1.0 Pre-GA RC4 RC3 RC2 RC1  </description>
    </item>
    
    <item>
      <title>Scale a TiDB cluster</title>
      <link>https://pingcap.com/docs/op-guide/horizontal-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/horizontal-scale/</guid>
      <description>Scale a TiDB cluster Overview The capacity of a TiDB cluster can be increased or reduced without affecting online services.
The following part shows you how to add or delete PD, TiKV or TiDB nodes.
About pd-ctl usage, please refer to PD Control User Guide.
PD Assume we have three PD servers with the following details:
   Name ClientUrls PeerUrls     pd1 http://host1:2379 http://host1:2380   pd2 http://host2:2379 http://host2:2380   pd3 http://host3:2379 http://host3:2380    Get the information about the existing PD nodes through pd-ctl:</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs-cn/sql/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/schema-object-names/</guid>
      <description>Schema Object Names 在 TiDB 中，包括 database，table，index，column，alias 等等都被认为是 identifier (标识符，之后阐述用英文).
在 TiDB 中，identifier可以被反引号 (`) 包裹，为了阐述方便，我们叫这种情况为 被引用。identifier 也可以不被 ` 包裹。 但是如果一个 identifier 存在一个特殊符号或者是一个保留关键字，那么你必须要 引用 它。
mysql&amp;gt; SELECT * FROM `table` WHERE `table`.id = 20; 如果ANSI_QUOTES sql mode 被设置了，那么我们认为被双引号 &amp;quot; 包裹的字符串为 identifier。
mysql&amp;gt; CREATE TABLE &amp;#34;test&amp;#34; (a varchar(10)); ERROR 1105 (HY000): line 0 column 19 near &amp;#34; (a varchar(10))&amp;#34; (total length 35) mysql&amp;gt; SET SESSION sql_mode=&amp;#39;ANSI_QUOTES&amp;#39;; Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>Schema Object Names</title>
      <link>https://pingcap.com/docs/sql/schema-object-names/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/schema-object-names/</guid>
      <description>Schema Object Names Some objects names in TiDB, including database, table, index, column, alias, etc., are known as identifiers.
In TiDB, you can quote or unquote an identifier. If an identifier contains special characters or is a reserved word, you must quote it whenever you refer to it. To quote, use the backtick (`) to wrap the identifier. For example:
mysql&amp;gt; SELECT * FROM `table` WHERE `table`.id = 20; If the ANSI_QUOTES SQL mode is enabled, you can also quote identifiers within double quotation marks(&amp;ldquo;):</description>
    </item>
    
    <item>
      <title>Software Engineer for TiDB</title>
      <link>https://pingcap.com/recruit/engineer/software-engineer-for-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit/engineer/software-engineer-for-tidb/</guid>
      <description>Software Engineer for TiDB Minimum qualifications  BA/BS degree in Computer Science or related technical field or equivalent practical experience. 2 years of professional software development experience. Experience with one or more programming languages including C, C++, Java and Go.  Preferred qualifications  Experience with Unix/Linux environments. Experience with designing and deploying large scale distributed systems. Experience in concurrency, multithreading and synchronization. Experience with database internals, database language theories, database design, SQL and database programming.</description>
    </item>
    
    <item>
      <title>Software Engineer for TiKV</title>
      <link>https://pingcap.com/recruit/engineer/software-engineer-for-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit/engineer/software-engineer-for-tikv/</guid>
      <description>Software Engineer for TiKV Qualifications  Solid development experience on distributed systems, understanding distributed transactions and consensus algorithms like Paxos or Raft. Development experience on high performance services, knowledge of performance testing and system optimisation based on relevant profile tools such as FlameGraph. Testing experience on distributed systems, knowledge of how to create corner cases of distributed environments and verification of system stability. Familiar with Rust or C or C++.</description>
    </item>
    
    <item>
      <title>Software and Hardware Requirements</title>
      <link>https://pingcap.com/docs/op-guide/recommendation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/recommendation/</guid>
      <description>Software and Hardware Requirements About As an open source distributed NewSQL database with high performance, TiDB can be deployed in the Intel architecture server and major virtualization environments and runs well. TiDB supports most of the major hardware networks and Linux operating systems.
Linux OS version requirements    Linux OS Platform Version     Red Hat Enterprise Linux 7.3 and above   CentOS 7.3 and above   Oracle Enterprise Linux 7.</description>
    </item>
    
    <item>
      <title>String Functions</title>
      <link>https://pingcap.com/docs/sql/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/string-functions/</guid>
      <description> String Functions    Name Description     ASCII() Return numeric value of left-most character   CHAR() Return the character for each integer passed   BIN() Return a string containing binary representation of a number   HEX() Return a hexadecimal representation of a decimal or string value   OCT() Return a string containing octal representation of a number   UNHEX() Return a string containing hex representation of a number   TO_BASE64() Return the argument converted to a base-64 string   FROM_BASE64() Decode to a base-64 string and return result   LOWER() Return the argument in lowercase   LCASE() Synonym for LOWER()   UPPER() Convert to uppercase   UCASE() Synonym for UPPER()   LPAD() Return the string argument, left-padded with the specified string   RPAD() Append string the specified number of times   TRIM() Remove leading and trailing spaces   LTRIM() Remove leading spaces   RTRIM() Remove trailing spaces   BIT_LENGTH() Return length of argument in bits   CHAR_LENGTH() Return number of characters in argument   CHARACTER_LENGTH() Synonym for CHAR_LENGTH()   LENGTH() Return the length of a string in bytes   OCTET_LENGTH() Synonym for LENGTH()   INSERT() Insert a substring at the specified position up to the specified number of characters   REPLACE() Replace occurrences of a specified string   SUBSTR() Return the substring as specified   SUBSTRING() Return the substring as specified   SUBSTRING_INDEX() Return a substring from a string before the specified number of occurrences of the delimiter   MID() Return a substring starting from the specified position   LEFT() Return the leftmost number of characters as specified   RIGHT() Return the specified rightmost number of characters   INSTR() Return the index of the first occurrence of substring   LOCATE() Return the position of the first occurrence of substring   POSITION() Synonym for LOCATE()   REPEAT() Repeat a string the specified number of times   CONCAT() Return concatenated string   CONCAT_WS() Return concatenate with separator   REVERSE() Reverse the characters in a string   SPACE() Return a string of the specified number of spaces   FIELD() Return the index (position) of the first argument in the subsequent arguments   ELT() Return string at index number   EXPORT_SET() Return a string such that for every bit set in the value bits, you get an on string and for every unset bit, you get an off string   MAKE_SET() Return a set of comma-separated strings that have the corresponding bit in bits set   FIND_IN_SET() Return the index position of the first argument within the second argument   FORMAT() Return a number formatted to specified number of decimal places   ORD() Return character code for leftmost character of the argument   QUOTE() Escape the argument for use in an SQL statement   SOUNDEX() Return a soundex string   SOUNDS LIKE Compare sounds    String comparison functions    Name Description     LIKE Simple pattern matching   NOT LIKE Negation of simple pattern matching   STRCMP() Compare two strings   MATCH Perform full-text search    Regular expressions    Name Description     REGEXP Pattern matching using regular expressions   RLIKE Synonym for REGEXP   NOT REGEXP Negation of REGEXP    </description>
    </item>
    
    <item>
      <title>Syncer User Guide</title>
      <link>https://pingcap.com/docs/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/syncer/</guid>
      <description>Syncer User Guide Syncer architecture Download the TiDB toolset (Linux) # Download the tool package. wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # Check the file integrity. If the result is OK, the file is correct. sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # Extract the package. tar -xzf tidb-enterprise-tools-latest-linux-amd64.tar.gz cd tidb-enterprise-tools-latest-linux-amd64 Where to deploy Syncer Syncer can be deployed to any of the machines that can connect to MySQL or TiDB cluster. But it is recommended to be deployed to the TiDB cluster.</description>
    </item>
    
    <item>
      <title>Syncer 使用文档</title>
      <link>https://pingcap.com/docs-cn/tools/syncer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/syncer/</guid>
      <description>Syncer 使用文档 syncer 架构 下载 TiDB 工具集 (Linux) # 下载 tool 压缩包 wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # 检查文件完整性，返回 ok 则正确 sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # 解开压缩包 tar -xzf tidb-enterprise-tools-latest-linux-amd64.tar.gz cd tidb-enterprise-tools-latest-linux-amd64 Syncer 部署位置 Syncer 可以部署在任一台可以连通对应的 MySQL 和 TiDB 集群的机器上，推荐部署在 TiDB 集群。
syncer 增量导入数据示例 使用前请详细阅读syncer 同步前预检查
设置同步开始的 position 设置 syncer 的 meta 文件, 这里假设 meta 文件是 syncer.meta:
# cat syncer.meta binlog-name = &amp;#34;mysql-bin.000003&amp;#34; binlog-pos = 930143241 binlog-gtid = &amp;#34;2bfabd22-fff7-11e6-97f7-f02fa73bcb01:1-23,61ccbb5d-c82d-11e6-ac2e-487b6bd31bf7:1-4&amp;#34;  注意： syncer.</description>
    </item>
    
    <item>
      <title>The Proprietary System Variables and Syntaxes in TiDB</title>
      <link>https://pingcap.com/docs/sql/tidb-specific/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/tidb-specific/</guid>
      <description>The Proprietary System Variables and Syntaxes in TiDB On the basis of MySQL variables and syntaxes, TiDB has defined some specific system variables and syntaxes to optimize performance.
System variable Variables can be set with the SET statement, for example:
set @@tidb_distsql_scan_concurrency = 10
If you need to set the global variable, run:
set @@global.tidb_distsql_scan_concurrency = 10
tidb_distsql_scan_concurrency Scope: SESSION | GLOBAL Default value: 10 This variable is used to set the concurrency of the scan operation.</description>
    </item>
    
    <item>
      <title>The System Variables</title>
      <link>https://pingcap.com/docs/sql/variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/variable/</guid>
      <description>The System Variables The system variables in MySQL are the system parameters that modify the operation of the database runtime. These variables have two types of scope, Global Scope and Session Scope. TiDB supports all the system variables in MySQL 5.7. Most of the variables are only supported for compatibility and do not affect the runtime behaviors.
Set the system variables You can use the SET statement to change the value of the system variables.</description>
    </item>
    
    <item>
      <title>The TiDB Command Options</title>
      <link>https://pingcap.com/docs/sql/server-command-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/server-command-option/</guid>
      <description>The TiDB Command Options TiDB startup options When you star TiDB processes, you can specify some program options.
TiDB supports a lot of startup options. Run the following command to get a brief introduction:
./tidb-server --help Run the following command to get the version:
./tidb-server -V The complete descriptions of startup options are as follows.
-L  Log level Default: &amp;ldquo;info&amp;rdquo; Optional values: debug, info, warn, error or fatal  -P  TiDB service monitor port Default: &amp;ldquo;4000&amp;rdquo; TiDB uses this port to accept requests from the MySQL client  --binlog-socket  TiDB uses the unix socket file to accept the internal connection, such as the PUMP service.</description>
    </item>
    
    <item>
      <title>The TiDB Server</title>
      <link>https://pingcap.com/docs/sql/tidb-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/tidb-server/</guid>
      <description>The TiDB Server TiDB service TiDB refers to the TiDB database management system. This document describes the basic management functions of the TiDB cluster.
TiDB cluster startup configuration You can set the service parameters using the command line or the configuration file, or both. The priority of the command line parameters is higher than the configuration file. If the same parameter is set in both ways, TiDB uses the value set using command line parameters.</description>
    </item>
    
    <item>
      <title>The TiDB System Database</title>
      <link>https://pingcap.com/docs/sql/system-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/system-database/</guid>
      <description>The TiDB System Database The TiDB System Database is similar to MySQL, which contains tables that store information required by the server when it runs.
Grant system tables These system tables contain grant information about user accounts and their privileges:
 user: user accounts, global privileges, and other non-privilege columns db: database-level privileges tables_priv: table-level privileges columns_priv: column-level privileges  Server-side help system tables Currently, the help_topic is NULL.</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs-cn/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/ga/</guid>
      <description>TiDB 1.0 release notes 10 月 16 日，TiDB 发布 GA 版（TiDB 1.0）。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB:  SQL 查询优化器
 调整代价模型 Analyze 下推 函数签名下推  优化内部数据格式，减小中间结果大小
 提升 MySQL 兼容性
 支持 NO_SQL_CACHE 语法，控制存储引擎对缓存的使用
 重构 Hash Aggregator 算子，降低内存使用
 支持 Stream Aggragator 算子
  PD:  支持基于读流量的热点调度 支持设置 Store 权重，以及基于权重的调度  TiKV:  Coprocessor 支持更多下推函数 支持取样操作下推 支持手动触发数据 Compact，用于快速回收空间 提升性能和稳定性 增加 Debug API，方便调试  TiSpark Beta Release:  支持可配置框架 支持 ThriftSever/JDBC 和 Spark SQL 脚本入口  源码地址 源码地址</description>
    </item>
    
    <item>
      <title>TiDB 1.0 release notes</title>
      <link>https://pingcap.com/docs/releases/ga/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/ga/</guid>
      <description>TiDB 1.0 Release Notes On October 16, 2017, TiDB 1.0 is now released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  The SQL query optimizer:  Adjust the cost model Analyze pushdown Function signature pushdown  Optimize the internal data format to reduce the interim data size Enhance the MySQL compatibility Support the NO_SQL_CACHE syntax and limit the cache usage in the storage engine Refactor the Hash Aggregator operator to reduce the memory usage Support the Stream Aggregator operator  PD:  Support read flow based balancing Support setting the Store weight and weight based balancing  TiKV:  Coprocessor now supports more pushdown functions Support pushing down the sampling operation Support manually triggering data compact to collect space quickly Improve the performance and stability Add a Debug API for debugging TiSpark Beta Release: Support configuration framework Support ThriftSever/JDBC and Spark SQL  Acknowledgement Special thanks to the following enterprises and teams!</description>
    </item>
    
    <item>
      <title>TiDB 1.0.1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/101/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/101/</guid>
      <description>TiDB 1.0.1 Release Notes On November 1, 2017, TiDB 1.0.1 is released with the following updates:
TiDB:  Support canceling DDL Job. Optimize the IN expression. Correct the result type of the Show statement. Support log slow query into a separate log file. Fix bugs.  TiKV:  Support flow control with write bytes. Reduce Raft allocation. Increase coprocessor stack size to 10MB. Remove the useless log from the coprocessor.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/102/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/102/</guid>
      <description> TiDB 1.0.2 Release Notes On November 13, 2017, TiDB 1.0.2 is released with the following updates:
TiDB:  Optimize the cost estimation of index point query Support the Alter Table Add Column (ColumnDef ColumnPosition) syntax Optimize the queries whose where conditions are contradictory Optimize the Add Index operation to rectify the progress and reduce repetitive operations Optimize the Index Look Join operator to accelerate the query speed for small data size Fix the issue with prefix index judgment  Placement Driver (PD):  Improve the stability of scheduling under exceptional situations  TiKV:  Support splitting table to ensure one region does not contain data from multiple tables Limit the length of a key to be no more than 4 KB More accurate read traffic statistics Implement deep protection on the coprocessor stack Fix the LIKE behavior and the do_div_mod bug  </description>
    </item>
    
    <item>
      <title>TiDB 1.0.3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/103/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/103/</guid>
      <description>TiDB 1.0.3 Release Notes On November 28, 2017, TiDB 1.0.3 is released with the following updates:
TiDB  Optimize the performance in transaction conflicts scenario Add the TokenLimit option in the config file Output the default database in slow query logs Remove the DDL statement from query duration metrics Optimize the query cost estimation Fix the index prefix issue when creating tables Support pushing down the expressions for the Float type to TiKV Fix the issue that it is slow to add index for tables with discrete integer primary index Reduce the unnecessary statistics updates Fix a potential issue during the transaction retry  PD  Support adding more types of schedulers using API  TiKV  Fix the deadlock issue with the PD client Fix the issue that the wrong leader value is prompted for NotLeader Fix the issue that the chunk size is too large in the coprocessor  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/104/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/104/</guid>
      <description>TiDB 1.0.4 Release Notes On December 11, 2017, TiDB 1.0.4 is released with the following updates:
TiDB  Speed up the loading of the statistics when starting the tidb-server Improve the performance of the show variables statement Fix a potential issue when using the Add Index statement to handle the combined indexes Fix a potential issue when using the Rename Table statement to move a table to another database Accelerate the effectiveness for the Alter/Drop User statement  TiKV  Fix a possible performance issue when a snapshot is applied  Fix the performance issue for reverse scan after removing a lot of data Fix the wrong encoded result for the Decimal type under special circumstances  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.5 Release Notes</title>
      <link>https://pingcap.com/docs/releases/105/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/105/</guid>
      <description>TiDB 1.0.5 Release Notes On December 26, 2017, TiDB 1.0.5 is released with the following updates:
TiDB  Add the max value for the current Auto_Increment ID in the Show Create Table statement. Fix a potential goroutine leak. Support outputting slow queries into a separate file. Load the TimeZone variable from TiKV when creating a new session. Support the schema state check so that the Show Create Tableand Analyze statements process the public table/index only.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.6 Release Notes</title>
      <link>https://pingcap.com/docs/releases/106/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/106/</guid>
      <description>TiDB 1.0.6 Release Notes On January 08, 2018, TiDB 1.0.6 is released with the following updates:
TiDB:  Support the Alter Table Auto_Increment syntax Fix the bug in Cost Based computation and the Null Json issue in statistics Support the extension syntax to shard the implicit row ID to avoid write hot spot for a single table Fix a potential DDL issue Consider the timezone setting in the curtime, sysdate and curdate functions Support the SEPARATOR syntax in the GROUP_CONCAT function Fix the wrong return type issue of the GROUP_CONCAT function.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.7 Release Notes</title>
      <link>https://pingcap.com/docs/releases/107/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/107/</guid>
      <description>TiDB 1.0.7 Release Notes On January 22, 2018, TiDB 1.0.7 is released with the following updates:
TiDB:  Optimize the FIELD_LIST command Fix data race of the information schema Avoid adding read-only statements to history Add the session variable to control the log query Fix the resource leak issue in statistics Fix the goroutine leak issue Add schema info API for the http status server Fix an issue about IndexJoin Update the behavior when RunWorker is false in DDL Improve the stability of test results in statistics Support PACK_KEYS syntax for the CREATE TABLE statement Add row_id column for the null pushdown schema to optimize performance  PD:  Fix possible scheduling loss issue in abnormal conditions Fix the compatibility issue with proto3 Add the log  TiKV:  Support Table Scan Support the remote mode in tikv-ctl Fix the format compatibility issue of tikv-ctl proto Fix the loss of scheduling command from PD Add timeout in Push metric  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.0.8 Release Notes</title>
      <link>https://pingcap.com/docs/releases/108/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/108/</guid>
      <description>TiDB 1.0.8 Release Notes On Feburary 11, 2018, TiDB 1.0.8 is released with the following updates:
TiDB:  Fix issues in the Outer Join result in some scenarios Optimize the performance of the InsertIntoIgnore statement Fix the issue in the ShardRowID option Add limitation (Configurable, the default value is 5000) to the DML statements number within a transaction Fix an issue in the Table/Column aliases returned by the Prepare statement Fix an issue in updating statistics delta Fix a panic error in the Drop Column statement Fix an DML issue when running the Add Column After statement Improve the stability of the GC process by ignoring the regions with GC errors Run GC concurrently to accelerate the GC process Provide syntax support for the CREATE INDEX statement  PD:  Reduce the lock overheat of the region heartbeats Fix the issue that a hot region scheduler selects the wrong Leader  TiKV:  Use DeleteFilesInRanges to clear stale data and improve the TiKV starting speed Using Decimal in Coprocessor sum Sync the metadata of the received Snapshot compulsorily to ensure its safety  To upgrade from 1.</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/11alpha/</guid>
      <description> TiDB 1.1 Alpha Release Notes 2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB：  SQL parser  兼容更多语法  SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确地估算点查的代价 支持更复杂的条件，更充分使用索引  SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT INGORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计  Server  支持 PROXY protocol   PD：  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 Region size Fix 了一些调度的 bug  TiKV：  支持 Raft learner 优化 Raft Snapshot，减少 IO 开销 支持 TLS 优化 RocksDB 配置，提升性能 优化 Coprocessor count (*) 和点查 unique index 的性能 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 TiKV-CTL 的功能 Region 支持按 table 进行分裂 支持 Delete Range 功能 支持设置 snapshot 导致的 IO 上限 完善流控机制  </description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release Notes</title>
      <link>https://pingcap.com/docs/releases/11alpha/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/11alpha/</guid>
      <description> TiDB 1.1 Alpha Release Notes On January 19, 2018, TiDB 1.1 Alpha is released. This release has great improvement in MySQL compatibility, SQL optimization, stability, and performance.
TiDB:  SQL parser  Support more syntax  SQL query optimizer  Use more compact structure to reduce statistics info memory usage Speed up loading statistics info when starting tidb-server Provide more accurate query cost evaluation Use Count-Min Sketch to evaluate the cost of queries using unique index more accurately Support more complex conditions to make full use of index  SQL executor  Refactor all executor operators using Chunk architecture, improve the execution performance of analytical statements and reduce memory usage Optimize performance of the INSERT INGORE statement Push down more types and functions to TiKV Support more SQL_MODE Optimize the Load Data performance to increase the speed by 10 times Optimize the Use Database performance Support statistics on the memory usage of physical operators  Server  Support the PROXY protocol   PD:  Add more APIs Support TLS Add more cases for scheduling Simulator Schedule to adapt to different Region sizes Fix some bugs about scheduling  TiKV:  Support Raft learner Optimize Raft Snapshot and reduce the IO overhead Support TLS Optimize the RocksDB configuration to improve performance Optimize count (*) and query performance of unique index in Coprocessor Add more failpoints and stability test cases Solve the reconnection issue between PD and TiKV Enhance the features of the data recovery tool TiKV-CTL Support splitting according to table in Region Support the Delete Range feature Support setting the IO limit caused by snapshot Improve the flow control mechanism  </description>
    </item>
    
    <item>
      <title>TiDB Ansible 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/ansible-deployment/</guid>
      <description>TiDB Ansible 部署方案 概述 Ansible 是一款自动化运维工具，TiDB-Ansible 是 PingCAP 基于 Ansible playbook 功能编写的集群部署工具。使用 TiDB-Ansible 可以快速部署一个完整的 TiDB 集群（包括 PD、TiDB、TiKV 和集群监控模块)。
本部署工具可以通过配置文件设置集群拓扑，一键完成以下各项运维工作：
 初始化操作系统参数 部署组件 滚动升级，滚动升级时支持模块存活检测 数据清理 环境清理 配置监控模块  准备机器  部署目标机器若干
 建议 4 台及以上，TiKV 至少 3 实例，且与 TiDB、PD 模块不位于同一主机，详见部署建议。 推荐安装 CentOS 7.3 及以上版本 Linux 操作系统，x86_64 架构(amd64)，数据盘请使用 ext4 文件系统，挂载 ext4 文件系统时请添加 nodelalloc 挂载参数，可参考数据盘 ext4 文件系统挂载参数。 机器之间内网互通，防火墙如 iptables 等请在部署时关闭。 机器的时间、时区设置一致，开启 NTP 服务且在正常同步时间，可参考如何检测 NTP 服务是否正常。 创建 tidb 普通用户作为程序运行用户，tidb 用户可以免密码 sudo 到 root 用户，可参考如何配置 ssh 互信及 sudo 免密码。   注：使用 Ansible 方式部署时，TiKV 及 PD 节点数据目录所在磁盘请使用 SSD 磁盘，否则无法通过检测。 如果仅验证功能，建议使用 Docker Compose 部署方案单机进行测试。</description>
    </item>
    
    <item>
      <title>TiDB Binary 部署方案详解</title>
      <link>https://pingcap.com/docs-cn/op-guide/binary-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/binary-deployment/</guid>
      <description>TiDB Binary 部署指导 概述 一个完整的 TiDB 集群包括 PD，TiKV 以及 TiDB。启动顺序依次是 PD，TiKV 以及 TiDB。在关闭数据库服务时，请按照启动的相反顺序进行逐一关闭服务。
阅读本章前，请先确保阅读 TiDB 整体架构及部署建议。
本文档描述了三种场景的二进制部署方式：
 快速了解和试用 TiDB，推荐使用单节点方式快速部署。
 功能性测试 TiDB，推荐使用功能性测试部署。
 生产环境使用 TiDB，推荐使用多节点集群模式部署。
  TiDB 组件及默认端口 1. TiDB 数据库组件（必装）    组件 默认端口 协议 说明     ssh 22 TCP sshd 服务   TiDB 4000 TCP 应用及 DBA 工具访问通信端口   TiDB 10080 TCP TiDB 状态信息上报通信端口   TiKV 20160 TCP TiKV 通信端口   PD 2379 TCP 提供 TiDB 和 PD 通信端口   PD 2380 TCP PD 集群节点间通信端口    2.</description>
    </item>
    
    <item>
      <title>TiDB Cluster Troubleshooting Guide</title>
      <link>https://pingcap.com/docs/trouble-shooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/trouble-shooting/</guid>
      <description>TiDB Cluster Troubleshooting Guide You can use this guide to help you diagnose and solve basic problems while using TiDB. If your problem is not resolved, please collect the following information and create an issue:
 The exact error message and the operations while the error occurs The state of all the components The error / fatal / panic information in the log of the component that reports the error The configuration and deployment topology The TiDB component related issue in dmesg  For other information, see Frequently Asked Questions (FAQ).</description>
    </item>
    
    <item>
      <title>TiDB Connector for Spark User Guide</title>
      <link>https://pingcap.com/docs/tispark/tispark-user-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tispark/tispark-user-guide/</guid>
      <description>TiDB Connector for Spark User Guide The TiDB Connector for Spark is a thin layer built for running Apache Spark on top of TiDB/TiKV to answer the complex OLAP queries. It takes advantages of both the Spark platform and the distributed TiKV cluster and seamlessly glues to TiDB, the distributed OLTP database, to provide a Hybrid Transactional/Analytical Processing (HTAP) solution to serve as a one-stop solution for both online transactions and analysis.</description>
    </item>
    
    <item>
      <title>TiDB Data Manipulation Language</title>
      <link>https://pingcap.com/docs/sql/dml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/dml/</guid>
      <description>TiDB Data Manipulation Language Data manipulation language (DML) is a family of syntax elements used for selecting, inserting, deleting and updating data in a database.
SELECT SELECT is used to retrieve rows selected from one or more tables.
Syntax SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], .</description>
    </item>
    
    <item>
      <title>TiDB Data Type</title>
      <link>https://pingcap.com/docs/sql/datatype/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/datatype/</guid>
      <description>TiDB Data Type Overview TiDB supports all the data types in MySQL except the Spatial type, including numeric type, string type, date &amp;amp; time type, and JSON type.
The definition of the data type is: T(M[, D]). In this format:
 T indicates the specific data type. M indicates the maximum display width for integer types. For floating-point and fixed-point types, M is the total number of digits that can be stored (the precision).</description>
    </item>
    
    <item>
      <title>TiDB Docker Compose</title>
      <link>https://pingcap.com/docs/op-guide/docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/docker-compose/</guid>
      <description>TiDB Docker Compose Use docker-compose Note: If you are using docker-compose, you don&amp;rsquo;t need to create a Docker network and start TiDB,TiKV and PD containers separately. The following docker-compose.yml file is enough.
version: &amp;#39;2&amp;#39; services: pd1: image: pingcap/pd expose: - &amp;#34;2379&amp;#34; - &amp;#34;2380&amp;#34; volumes: - /etc/localtime:/etc/localtime:ro command: - --name=pd1 - --client-urls=http://0.0.0.0:2379 - --peer-urls=http://0.0.0.0:2380 - --advertise-client-urls=http://pd1:2379 - --advertise-peer-urls=http://pd1:2380 - --initial-cluster=pd1=http://pd1:2380,pd2=http://pd2:2380,pd3=http://pd3:2380 privileged: true pd2: image: pingcap/pd expose: - &amp;#34;2379&amp;#34; - &amp;#34;2380&amp;#34; volumes: - /etc/localtime:/etc/localtime:ro command: - --name=pd2 - --client-urls=http://0.</description>
    </item>
    
    <item>
      <title>TiDB Docker Deployment</title>
      <link>https://pingcap.com/docs/op-guide/docker-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/docker-deployment/</guid>
      <description>Docker Deployment This page shows you how to manually deploy a multi-node TiDB cluster on multiple machines using Docker.
To learn more, see TiDB architecture and Software and Hardware Requirements.
Preparation Before you start, make sure that you have:
 Installed the latest version of Docker Pulled the latest images of TiDB, TiKV and PD from Docker Hub. If not, pull the images using the following commands:
docker pull pingcap/tidb:latest docker pull pingcap/tikv:latest docker pull pingcap/pd:latest  Multi nodes deployment Assume we have 6 machines with the following details:</description>
    </item>
    
    <item>
      <title>TiDB Docker 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/docker-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/docker-deployment/</guid>
      <description>TiDB Docker 部署方案 本篇将展示如何在多台主机上使用 Docker 部署一个 TiDB 集群。
阅读本章前，请先确保阅读 TiDB 整体架构 及 部署建议。
环境准备 安装 Docker Docker 可以方便地在 Linux / Mac OS / Windows 平台安装，安装方法请参考 Docker 官方文档。
拉取 TiDB 的 Docker 镜像 部署 TiDB 集群主要包括 3 个服务组件:
 TiDB TiKV PD  对应的最新 Docker 镜像可以通过 Docker 官方镜像仓库 获取：
docker pull pingcap/tidb:latest docker pull pingcap/tikv:latest docker pull pingcap/pd:latest 部署一个多节点集群 假设我们打算在 6 台主机上部署一个 TiDB 集群:
   主机名 IP 部署服务 数据盘挂载     host1 192.</description>
    </item>
    
    <item>
      <title>TiDB Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/tidb-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/tidb-engineer/</guid>
      <description>TiDB Engineer 岗位职责  负责分布式数据库查询优化器相关的设计，开发，文档撰写和新人指导
 负责分布式数据库 SQL 层的设计，开发和性能优化
 参与分布式数据库底层系统存储系统的设计
  职位要求  三年以上相关领域开发经验，扎实的编程能力，熟悉 C/C++/Go/Java/Python 中的一种
 对分布式系统的架构和原理有比较深入的了解
 熟悉 MapReduce/Spark/Hive 等分布式计算框架中的一种或多种
 熟悉 MySQL/PostgreSQL/Greenplum 等数据库系统实现原理
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神
  加分项  拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历
 熟悉 Spark 内核，并阅读过其中的源码
 熟悉 MySQL/PostgreSQL/Greenplum 的查询引擎，并阅读过其中的源码
  待遇 20K - 40K + 期权, 13薪 + 奖金, 优秀者可面议
工作地点 北京，上海，广州，杭州，特别优秀可 remote</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs-cn/FAQ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/FAQ/</guid>
      <description>一、 TiDB 介绍、架构、原理 1.1 TiDB 介绍及整体架构 1.1.1 TiDB 整体架构 https://pingcap.com/docs-cn/overview/
1.1.2 TiDB 是什么？ TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、标准 SQL、MySQL 语法和 MySQL 协议，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。
1.1.3 TiDB 是基于 MySQL 开发的吗？ 不是，虽然 TiDB 支持 MySQL 语法和协议，但是 TiDB 是由 PingCAP 团队完全自主开发的产品。
1.1.4 TiDB、TiKV、Placement Driver (PD) 主要作用？  TiDB 是 Server 计算层，主要负责 SQL 的解析、制定查询计划、生成执行器。 TiKV 是分布式 Key-Value 存储引擎，用来存储真正的数据，简而言之，TiKV 是 TiDB 的存储引擎。 PD 是 TiDB 集群的管理组件，负责存储 TiKV 的元数据，同时也负责分配时间戳以及对 TiKV 做负载均衡调度。  1.1.5 TiDB 易用性如何？ TiDB 使用起来很简单，可以将 TiDB 集群当成 MySQL 来用，你可以将 TiDB 用在任何以 MySQL 作为后台存储服务的应用中，并且基本上不需要修改应用代码，同时你可以用大部分流行的 MySQL 管理工具来管理 TiDB。</description>
    </item>
    
    <item>
      <title>TiDB FAQ</title>
      <link>https://pingcap.com/docs/FAQ/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/FAQ/</guid>
      <description>TiDB FAQ This document lists the Most Frequently Asked Questions about TiDB.
Product General What is TiDB? TiDB is a distributed SQL database that features in horizontal scalability, high availability and consistent distributed transactions. It also enables you to use MySQL’s SQL syntax and protocol to manage and retrieve data.
Is TiDB based on MySQL? No. TiDB supports MySQL syntax and protocol, but it is a new open source database that is developed and maintained by PingCAP, Inc.</description>
    </item>
    
    <item>
      <title>TiDB Pre-GA Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/prega/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/prega/</guid>
      <description> TiDB Pre-GA Release Notes 8 月 30 日，TiDB 发布 Pre-GA 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB:  SQL 查询优化器  调整代价模型 优化索引选择，支持不同类型字段比较的索引选择 支持基于贪心算法的 Join Reorder  大量 MySQL 兼容性相关功能 支持 Natural Join 完成 JSON 类型支持 (Experimental)，包括对 JSON 中的字段查询、更新、建索引 裁剪无用数据，减小执行器内存消耗 支持在 SQL 语句中设置优先级，并根据查询类型自动设置部分语句的优先级 完成表达式重构，执行速度提升 30% 左右  PD:  支持手动切换 PD 集群 Leader  TiKV:  Raft Log 使用独立的 RocksDB 实例 使用 DeleteRange 加快删除副本速度 Coprocessor 支持更多运算符下推 提升性能，提升稳定性  TiSpark Beta Release:  支持谓词下推 支持聚合下推 支持范围裁剪 通过 TPC-H 测试 (除去一个需要 View 的 Query)  </description>
    </item>
    
    <item>
      <title>TiDB Quick Start Guide</title>
      <link>https://pingcap.com/docs/QUICKSTART/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/QUICKSTART/</guid>
      <description>TiDB Quick Start Guide About TiDB TiDB (The pronunciation is: /’taɪdiːbi:/ tai-D-B, etymology: titanium) is a Hybrid Transactional/Analytical Processing (HTAP) database. Inspired by the design of Google F1 and Google Spanner, TiDB features infinite horizontal scalability, strong consistency, and high availability. The goal of TiDB is to serve as a one-stop solution for online transactions and analyses.
About this guide This guide outlines how to perform a quick deployment of a TiDB cluster using TiDB-Ansible and walks you through the basic TiDB operations and administrations.</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc1/</guid>
      <description> TiDB RC1 Release Notes 2016 年 12 月 23 日，分布式关系型数据库 TiDB 正式发布 RC1。
TiKV + 提升写入速度 + 降低磁盘空间占用 + 支持百 TB 级别数据 + 提升稳定性，集群规模支持 200 个节点 + 提供 Raw KV API，以及 Golang client PD + PD 调度策略框架优化，策略更加灵活合理 + 添加 label 支持，支持跨 DC 调度 + 提供 PD Controler，方便操作 PD 集群 TiDB + SQL 查询优化器 - 支持 eager aggregate - 更详细的 explain 信息 - union 算子并行化 - 子查询性能优化 - 条件下推优化 - 优化 CBO 框架 + 重构 time 相关类型的实现，提升和 MySQL 的兼容性 + 支持更多的 MySQL 内建函数 + Add Index 语句提速 + 支持用 change column 语句修改列名；支持使用 Alter table 的 modify column 和 change column 完成部分列类型转换 工具 + Loader：兼容 Percona 的 mydumper 数据格式，提供多线程导入、出错重试、断点续传等功能，并且针对 TiDB 有优化 + 开发完成一键部署工具</description>
    </item>
    
    <item>
      <title>TiDB RC1 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc1/</guid>
      <description>TiDB RC1 Release Notes On December 23, 2016, TiDB RC1 is released. See the following updates in this release:
TiKV:  The write speed has been improved. The disk space usage is reduced. Hundreds of TBs of data can be supported. The stability is improved and TiKV can support a cluster with 200 nodes. Supports the Raw KV API and the Golang client.  Placement Driver (PD): + The scheduling strategy framework is optimized and now the strategy is more flexible and reasonable.</description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc2/</guid>
      <description> TiDB RC2 Release Notes 2017 年 3 月 1 日，TiDB 正式发布 RC2 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。对于 OLTP 场景，读取性能提升 60%，写入性能提升 30%。另外提供了权限管理功能，用户可以按照 MySQL 的权限管理方式控制数据访问权限。
TiDB  SQL 查询优化器  统计信息收集和使用 关联子查询优化 优化 CBO 框架 通过 Unique Key 信息消除聚合 重构 Expression Distinct 转换为 GroupBy 支持 topn 操作下推  支持基本权限管理 新增大量 MySQL 内建函数 完善 Alter Table 语句，支持修改表名、默认值、注释 支持 Create Table Like 语句 支持 Show Warnings 语句 支持 Rename Table 语句 限制单个事务大小，避免大事务阻塞整个集群 Load Data 过程中对数据进行自动拆分 优化 AddIndex、Delete 语句性能 支持 &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode 完善监控 修复 Bug 修复内存泄漏问题  PD  支持 Label 对副本进行 Location 调度 基于 region 数量的快速调度 pd-ctl 支持更多功能  添加、删除 PD 通过 Key 获取 Region 信息 添加、删除 scheduler 和 operator 获取集群 label 信息   TiKV  支持 Async Apply 提升整体写入性能 使用 prefix seek 提升 Write CF 的读取性能 使用 memory hint prefix 提升 Raft CF 插入性能 优化单行读事务性能 支持更多下推功能 加入更多统计 修复 Bug  </description>
    </item>
    
    <item>
      <title>TiDB RC2 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc2/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc2/</guid>
      <description> TiDB RC2 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on the compatibility with MySQL, SQL query optimizer, system stability and performance in this version. What’s more, a new permission management mechanism is added and users can control data access in the same way as the MySQL privilege management system.
TiDB:  Query optimizer  Collect column/index statistics and use them in the query optimizer Optimize the correlated subquery Optimize the Cost Based Optimizer (CBO) framework Eliminate aggregation using unique key information Refactor expression evaluation framework Convert Distinct to GroupBy Support the topn operation push-down  Support basic privilege management Add lots of MySQL built-in functions Improve the Alter Table statement and support the modification of table name, default value and comment Support the Create Table Like statement Support the Show Warnings statement Support the Rename Table statement Restrict the size of a single transaction to avoid the cluster blocking of large transactions Automatically split data in the process of Load Data Optimize the performance of the AddIndex and Delete statement Support &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode Improve the monitoring system Fix Bugs Solve the problem of memory leak  PD:  Support location aware replica scheduling Conduct fast scheduling based on the number of region pd-ctl support more features  Add or delete PD Obtain Region information with Key Add or delete scheduler and operator Obtain cluster label information   TiKV:  Support Async Apply to improve the entire write performance Use prefix seek to improve the read performance of Write CF Use memory hint prefix to improve the insert performance of Raft CF Optimize the single read transaction performance Support more push-down expressions Improve the monitoring system Fix Bugs  </description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc3/</guid>
      <description> TiDB RC3 Release Notes 2017 年 6 月 16 日，TiDB 正式发布 RC3 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。性能方面重点优化了负载均衡调度策略和流程。功能方面进一步完善权限管理功能，用户可以按照 MySQL 的权限管理方式控制数据访问权限。另外 DDL 的速度也得到显著的提升。 同时为了简化运维工作，开源了 TiDB-Ansible 项目，可以一键部署/升级/启停 TiDB 集群。
TiDB  SQL 查询优化器  统计信息收集和使用 关联子查询优化 优化 CBO 框架 通过 Unique Key 信息消除聚合 重构 Expression Distinct 转换为 GroupBy 支持 topn 操作下推  支持基本权限管理 新增大量 MySQL 内建函数 完善 Alter Table 语句，支持修改表名、默认值、注释 支持 Create Table Like 语句 支持 Show Warnings 语句 支持 Rename Table 语句 限制单个事务大小，避免大事务阻塞整个集群 Load Data 过程中对数据进行自动拆分 优化 AddIndex、Delete 语句性能 支持 &amp;ldquo;ANSI_QUOTES&amp;rdquo; sql_mode 完善监控 修复 Bug 修复内存泄漏问题  PD  支持 Label 对副本进行 Location 调度 基于 region 数量的快速调度 pd-ctl 支持更多功能  添加、删除 PD 通过 Key 获取 Region 信息 添加、删除 scheduler 和 operator 获取集群 label 信息    TiKV  支持 Async Apply 提升整体写入性能 使用 prefix seek 提升 Write CF 的读取性能 使用 memory hint prefix 提升 Raft CF 插入性能 优化单行读事务性能 支持更多下推功能 加入更多统计 修复 Bug  </description>
    </item>
    
    <item>
      <title>TiDB RC3 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc3/</guid>
      <description>TiDB RC3 Release Notes On June 20, 2017, TiDB RC4 is released!This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  The privilege management is refined to enable users to manage the data access privileges using the same way as in MySQL. DDL is accelerated. The load balancing policy and process are optimized for performance. TiDB-Ansible is open sourced. By using TiDB-Ansilbe, you can deploy, upgrade, start and shutdown a TiDB cluster with one click.</description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs-cn/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/rc4/</guid>
      <description> TiDB RC4 Release Notes 8 月 4 日，TiDB 正式发布 RC4 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。性能方面重点优化了写入速度，计算任务调度支持优先级，避免分析型大事务影响在线事务。SQL 优化器全新改版，查询代价估算更加准确，且能够自动选择 Join 物理算子。功能方面进一步 MySQL 兼容性。 同时为了更好的支持 OLAP 业务，开源了 TiSpark 项目，可以通过 Spark 读取和分析 TiKV 中的数据。
TiDB:  SQL 查询优化器重构  更好的支持 TopN 查询 支持 Join 算子根据代价自动选择 更完善的 Projection Elimination  Schema 版本检查区分 Table，避免 DDL 干扰其他正在执行的事务 支持 BatchIndexJoin 完善 Explain 语句 提升 Index Scan 性能 大量 MySQL 兼容性相关功能 支持 Json 类型及其操作 支持查询优先级、隔离级别的设置  PD:  支持通过 PD 设置 TiKV location labels 调度优化  支持 PD 主动向 TiKV 下发调度命令 加快 region heartbeat 响应速度 优化 balance 算法  优化数据加载，加快 failover 速度  TiKV:  支持查询优先级设置 支持 RC 隔离级别 完善 Jepsen，提升稳定性 支持 Document Store Coprocessor 支持更多下推函数 提升性能，提升稳定性  TiSpark Beta Release:  支持谓词下推 支持聚合下推 支持范围裁剪 通过 TPC-H 测试 (除去一个需要 View 的 Query)  </description>
    </item>
    
    <item>
      <title>TiDB RC4 Release Notes</title>
      <link>https://pingcap.com/docs/releases/rc4/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/releases/rc4/</guid>
      <description>TiDB RC4 Release Notes On August 4, 2017, TiDB RC4 is released! This release is focused on MySQL compatibility, SQL optimization, stability, and performance.
Highlight:  For performance, the write performance is improved significantly, and the computing task scheduling supports prioritizing to avoid the impact of OLAP on OLTP. The optimizer is revised for a more accurate query cost estimating and for an automatic choice of the Join physical operator based on the cost.</description>
    </item>
    
    <item>
      <title>TiDB Roadmap</title>
      <link>https://pingcap.com/docs/ROADMAP/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/ROADMAP/</guid>
      <description>TiDB Roadmap This document defines the roadmap for TiDB development.
TiDB： Optimizer Refactor Ranger Optimize the statistics info Optimize the cost model  Executor Parallel Operators Compact Row Format to reduce memory usage File Sort  Support View Support Window Function Common Table Expression Table Partition Hash time index to resolve the issue with hot regions Reverse Index Cluster Index Improve DDL Support utf8_general_ci collation  TiKV: Raft Region merge Local read thread Multi-thread raftstore None voter Pre-vote  RocksDB DeleteRange  Transaction Optimize transaction conflicts  Coprocessor Streaming  Tool Import distributed data Export distributed data Disaster Recovery  Flow control and degradation  PD:  [ ] Improve namespace</description>
    </item>
    
    <item>
      <title>TiDB Transaction Isolation Levels</title>
      <link>https://pingcap.com/docs/sql/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/transaction-isolation/</guid>
      <description>TiDB Transaction Isolation Levels Transaction isolation is one of the foundations of database transaction processing. Isolation is the I in the acronym ACID (Atomicity, Consistency, Isolation, Durability), which represents the isolation property of database transactions.
The SQL-92 standard defines four levels of transaction isolation: Read Uncommitted, Read Committed, Repeatable Read and Serializable. See the following table for details:
   Isolation Level Dirty Read Nonrepeatable Read Phantom Read Serialization Anomaly     Read Uncommitted Possible Possible Possible Possible   Read Committed Not possible Possible Possible Possible   Repeatable Read Not possible Not possible Not possible in TiDB Possible   Serializable Not possible Not possible Not possible Not possible    TiDB offers two transaction isolation levels: Read Committed and Repeatable Read.</description>
    </item>
    
    <item>
      <title>TiDB User Account Management</title>
      <link>https://pingcap.com/docs/sql/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/user-account-management/</guid>
      <description>TiDB User Account Management User names and passwords TiDB stores the user accounts in the table of the mysql.user system database. Each account is identified by a user name and the client host. Each account may have a password.
You can connect to the TiDB server using the MySQL client, and use the specified account and password to login:
shell&amp;gt; mysql --port 4000 --user xxx --password Or use the abbreviation of command line parameters:</description>
    </item>
    
    <item>
      <title>TiDB User Guide</title>
      <link>https://pingcap.com/docs/sql/user-manual/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/user-manual/</guid>
      <description>TiDB User Guide TiDB supports the SQL-92 standard and is compatible with MySQL. To help you easily get started with TiDB, TiDB user guide mainly inherits the MySQL document structure with some TiDB specific changes.
TiDB server administration  The TiDB Server The TiDB Command Options The TiDB Data Directory The TiDB System Database The TiDB System Variables The Proprietary System Variables and Syntax in TiDB The TiDB Server Logs The TiDB Access Privilege System TiDB User Account Management Use Encrypted Connections  SQL optimization  Understand the Query Execution Plan Introduction to Statistics  Language structure  Literal Values Schema Object Names Keywords and Reserved Words User-Defined Variables Expression Syntax Comment Syntax  Globalization  Character Set Support Character Set Configuration Time Zone  Data types  Numeric Types Date and Time Types String Types JSON Types The ENUM data type The SET Type Data Type Default Values  Functions and operators  Function and Operator Reference Type Conversion in Expression Evaluation Operators Control Flow Functions String Functions Numeric Functions and Operators Date and Time Functions Bit Functions and Operators Cast Functions and Operators Encryption and Compression Functions Information Functions JSON Functions Functions Used with Global Transaction IDs [TBD] Aggregate (GROUP BY) Functions Miscellaneous Functions Precision Math  SQL statement syntax  Data Definition Statements Data Manipulation Statements Transactions</description>
    </item>
    
    <item>
      <title>TiDB 专用系统变量和语法</title>
      <link>https://pingcap.com/docs-cn/sql/tidb-specific/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/tidb-specific/</guid>
      <description>TiDB 专用系统变量和语法 TiDB 在 MySQL 的基础上，定义了一些专用的系统变量和语法用来优化性能。
System Variable 变量可以通过 SET 语句设置，例如
set @@tidb_distsql_scan_concurrency = 10
如果需要设值全局变量，执行
set @@global.tidb_distsql_scan_concurrency = 10
tidb_distsql_scan_concurrency 作用域: SESSION | GLOBAL
默认值: 10
这个变量用来设置 scan 操作的并发度，AP 类应用适合较大的值，TP 类应用适合较小的值。 对于 AP 类应用，最大值建议不要超过所有 TiKV 节点的 CPU 核数。
tidb_index_lookup_size 作用域: SESSION | GLOBAL
默认值: 20000
这个变量用来设置 index lookup 操作的 batch 大小，AP 类应用适合较大的值，TP 类应用适合较小的值。
tidb_index_lookup_concurrency 作用域: SESSION | GLOBAL
默认值: 4
这个变量用来设置 index lookup 操作的并发度，AP 类应用适合较大的值，TP 类应用适合较小的值。
tidb_index_serial_scan_concurrency 作用域：SESSION | GLOBAL</description>
    </item>
    
    <item>
      <title>TiDB 事务隔离级别</title>
      <link>https://pingcap.com/docs-cn/sql/transaction-isolation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/transaction-isolation/</guid>
      <description>TiDB 事务隔离级别 事务隔离级别是数据库事务处理的基础，ACID 中 I，即 Isolation，指的就是事务的隔离性。
sql 92标准定义了4种隔离级别，读未提交、读已提交、可重复读、串行化，见下表。
   Isolation Level Dirty Read Nonrepeatable Read Phantom Read Serialization Anomaly     Read uncommitted Possible Possible Possible Possible   Read committed Not possible Possible Possible Possible   Repeatable read Not possible Not possible Not possible in TiDB Possible   Serializable Not possible Not possible Not possible Not possible    TiDB 实现了其中的两种：读已提交和可重复读。</description>
    </item>
    
    <item>
      <title>TiDB 历史数据回溯</title>
      <link>https://pingcap.com/docs-cn/op-guide/history-read/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/history-read/</guid>
      <description>TiDB 历史数据回溯 本文档用于描述 TiDB 如何读取历史版本数据，包括具体的操作流程以及历史数据的保存策略。
功能说明 TiDB 实现了通过标准 SQL 接口读取历史数据功能，无需特殊的 client 或者 driver。当数据被更新、删除后，依然可以通过 SQL 接口将更新/删除前的数据读取出来。
另外即使在更新数据之后，表结构发生了变化，TiDB 依旧能用旧的表结构将数据读取出来。
操作流程 为支持读取历史版本数据， 引入了一个新的 system variable: tidb_snapshot ，这个变量是 Session 范围有效，可以通过标准的 Set 语句修改其值。其值为文本，记录了时间，格式为： “2016-10-08 16:45:26.999”，一般来说可以只写到秒，比如”2016-10-08 16:45:26”。 当这个变量被设置时，TiDB 会用这个时间戳建立 Snapshot（没有开销，只是创建数据结构），随后所有的 Select 操作都会在这个 Snapshot 上读取数据。
 注意 TiDB 的事务是通过 PD 进行全局授时，所以存储的数据版本也是以 PD 所授时间戳作为版本号。在生成 Snapshot ·时，是以 tidb_snapshot 变量的值作为版本号，如果 TiDB Server 所在机器和 PD Server 所在机器的本地时间相差较大，需要以 PD 的时间为准。
 当读取历史版本操作结束后，可以结束当前 Session 或者是通过 Set 语句将 tidb_snapshot 变量的值设为 ”“，即可读取最新版本的数据。
历史数据保留策略 TiDB 使用 MVCC 管理版本，当更新/删除数据时，不会做真正的数据删除，只会添加一个新版本数据，所以可以保留历史数据。历史数据不会全部保留，超过一定时间的历史数据会被彻底删除，以减小空间占用以及避免历史版本过多引入的性能开销。</description>
    </item>
    
    <item>
      <title>TiDB 数据库管理</title>
      <link>https://pingcap.com/docs-cn/sql/tidb-server/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/tidb-server/</guid>
      <description>TiDB 数据库管理 TiDB 服务 TiDB 是指 TiDB 数据库系统，本篇文档涉及到 TiDB 集群的基本管理功能。
TiDB 集群启动配置 可以通过命令行参数或者配置文件设置服务参数，或者是两者一起使用。注意命令行参数的优先级高于配置文件，如果同一个参数两种方式都设置，会以命令行参数中的值为准。具体信息参考这篇文档。
TiDB 数据库系统变量 TiDB 兼容 MySQL 的系统变量，同时定义了一些特有的系统变量用于调整数据库行为，具体信息参考 TiDB 专用系统变量和语法 文档。
TiDB 系统表 和 MySQL 类似，TiDB 中也有系统表，用于存放数据库运行时所需信息。具体信息参考 TiDB 系统数据库文档。
TiDB 数据目录 TiDB 数据存放在存储引擎中，数据目录取决于使用的存储引擎，存储引擎的选择参见 TiDB 启动参数文档。
对于使用本地存储引擎的情况，数据存储在本机硬盘上，目录位置通过 path 参数控制。
对于使用 TiKV 引擎的情况，数据存储在 TiKV 节点上，目录位置通过 data-dir 参数控制。
TiDB 服务器日志文件 TiDB 集群的三个组件（tidb-server、tikv-server、pd-server）默认会将日志输出到标准错误中，并且三个组件都支持设置 --log-file 启动参数 （或者是配置文件中的配置项）将日志输出到文件中。
通过配置文件可以调整日志的行为，具体信息请参见各个组件的配置文件说明。例如： tidb-server 日志配置项。</description>
    </item>
    
    <item>
      <title>TiDB 数据类型</title>
      <link>https://pingcap.com/docs-cn/sql/datatype/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/datatype/</guid>
      <description>TiDB 数据类型 概述 TiDB 支持 MySQL 除空间类型之外的所有数据类型，包括数值型类型、字符串类型、时间&amp;amp;日期类型、Json 类型。
数据类型定义一般为 T(M[, D])，其中:
 T 表示具体的类型 M 对于整数类型表示最大显示长度；对于浮点数或者定点数表示精度；对于字符类型表示最大长度。M 的最大值取决于具体的类型。 D 表示浮点数/定点数的小数位长度 对于时间&amp;amp;日期类型中的 TIME、DATETIME 以及 TIMESTAMP，定义中可以包含 Fsp 表示秒的精度，其取值范围是0到6，默认的精度为0  数值类型 概述 TiDB 支持 MySQL 所有的数值类型，按照精度可以分为:
 整数类型（精确值) 浮点类型（近似值) 定点类型（精确值)  整数类型 TiDB 支持 MySQL 所有的整数类型，包括 INTEGER/INT、TINYINT、SMALLINT、MEDIUMINT 以及 BIGINT，完整信息参考这篇文档。
类型定义 语法：
BIT[(M)] &amp;gt; 比特值类型。M 表示比特位的长度，取值范围从1到64，其默认值是1。 TINYINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; TINYINT 类型。有符号数的范围是[-128, 127]。无符号数的范围是[0, 255]。 BOOL, BOOLEAN &amp;gt; 布尔类型，和 TINYINT(1) 等价。零值被认为是 False，非零值认为是 True。在 TiDB 内部，True 存储为1， False 存储为0。 SMALLINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; SMALLINT 类型。有符号数的范围是[-32768, 32767]。无符号数的范围是[0, 65535]。 MEDIUMINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; MEDIUMINT 类型。有符号数的范围是[-8388608, 8388607]。无符号数的范围是[0, 16777215]。 INT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; INT 类型。 有符号数的范围是[-2147483648, 2147483647]。无符号数的范围是[0, 4294967295]。 INTEGER[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; 和 INT 相同。 BIGINT[(M)] [UNSIGNED] [ZEROFILL] &amp;gt; BIGINT 类型。 有符号数的范围是[-9223372036854775808, 9223372036854775807]。无符号数的范围是[0, 18446744073709551615]。 字段意义:</description>
    </item>
    
    <item>
      <title>TiDB 版本发布历史</title>
      <link>https://pingcap.com/docs-cn/releases/README/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/releases/README/</guid>
      <description> TiDB 版本发布历史 TiDB 历史版本发布声明如下：
 1.1 Alpha 1.0 Pre-GA RC4 RC3 RC2 RC1  </description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/bit-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/bit-functions-and-operators/</guid>
      <description> 位函数和操作符 TiDB 中位函数和操作符的使用方法与 MySQL 基本一致，详情参见: Bit Functions and Operators。
位函数和操作符表
   函数和操作符名 功能描述     BIT_COUNT() 返回参数二进制表示中为 1 的个数   &amp;amp; 位与   ~ 按位取反   | 位或   0 位亦或   &amp;lt;&amp;lt; 左移   &amp;gt;&amp;gt; 右移    </description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/cast-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/cast-functions-and-operators/</guid>
      <description> Cast 函数和操作符 Cast 函数和操作符用于将某种数据类型的值转换为另一种数据类型。TiDB 中该函数和操作符的使用方法与 MySQL基本一致，详情参见: Cast Functions and Operators.
Cast 函数和操作符表
   函数和操作符名 功能描述     BINARY 将一个字符串转换成一个二进制字符串   CAST() 将一个值转换成一个确定类型   CONVERT() 将一个值转换成一个确定类型    </description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/date-and-time-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/date-and-time-functions/</guid>
      <description> 日期和时间函数 TiDB 中日期和时间函数的使用方法与 MySQL 基本一致，详情参见: Date and Time Functions.
日期时间函数表
   函数名 功能描述     ADDDATE() 将时间间隔添加到日期上   ADDTIME() 时间数值相加   CONVERT_TZ() 转换时区   CURDATE() 返回当前日期   CURRENT_DATE(), CURRENT_DATE 与 CURDATE() 同义   CURRENT_TIME(), CURRENT_TIME 与 CURTIME() 同义   CURRENT_TIMESTAMP(), CURRENT_TIMESTAMP 与 NOW() 同义   CURTIME() 返回当前时间   DATE() 从日期或日期/时间表达式中提取日期部分   DATE_ADD() 将时间间隔添加到日期上   DATE_FORMAT() 返回满足指定格式的日期/时间   DATE_SUB() 从日期减去指定的时间间隔   DATEDIFF() 返回两个日期间隔的天数   DAY() 与 DAYOFMONTH() 同义   DAYNAME() 返回星期名称   DAYOFMONTH() 返回参数对应的天数部分(1-31)   DAYOFWEEK() 返回参数对应的星期下标   DAYOFYEAR() 返回参数代表一年的哪一天 (1-366)   EXTRACT() 提取日期/时间中的单独部分   FROM_DAYS() 将天数转化为日期   FROM_UNIXTIME() 将 Unix 时间戳格式化为日期   GET_FORMAT() 返回满足日期格式的字符串   HOUR() 提取日期/时间表达式中的小时部分   LAST_DAY 返回参数中月份的最后一天   LOCALTIME(), LOCALTIME 与 NOW() 同义   LOCALTIMESTAMP, LOCALTIMESTAMP() 与 NOW() 同义   MAKEDATE() 根据给定的年份和一年中的天数生成一个日期   MAKETIME() 根据给定的时、分、秒生成一个时间   MICROSECOND() 返回参数的微秒部分   MINUTE() 返回参数的分钟部分   MONTH() 返回参数的月份部分   MONTHNAME() 返回参数的月份名称   NOW() 返回当前日期和时间   PERIOD_ADD() 在年-月表达式上添加一段时间(数个月)   PERIOD_DIFF() 返回间隔的月数   QUARTER() 返回参数对应的季度(1-4)   SEC_TO_TIME() 将秒数转化为 &amp;lsquo;HH:MM:SS&amp;rsquo; 的格式   SECOND() 返回秒数(0-59)   STR_TO_DATE() 将字符串转化为日期   SUBDATE() 当传入三个参数时作为 DATE_SUB() 的同义   SUBTIME() 从一个时间中减去一段时间   SYSDATE() 返回该方法执行时的时间   TIME() 返回参数的时间表达式部分   TIME_FORMAT() 格式化时间   TIME_TO_SEC() 返回参数对应的秒数   TIMEDIFF() 返回时间间隔   TIMESTAMP() 传入一个参数时候,该方法返回日期或日期/时间表达式, 传入两个参数时候, 返回参数的和   TIMESTAMPADD() 在日期/时间表达式上增加一段时间间隔   TIMESTAMPDIFF() 从日期/时间表达式中减去一段时间间隔   TO_DAYS() 将参数转化对应的天数(从第 0 年开始)   TO_SECONDS() 将日期或日期/时间参数转化为秒数(从第 0 年开始)   UNIX_TIMESTAMP() 返回一个 Unix 时间戳   UTC_DATE() 返回当前的 UTC 日期   UTC_TIME() 返回当前的 UTC 时间   UTC_TIMESTAMP() 返回当前的 UTC 日期和时间   WEEK() 返回参数所在的一年中的星期数   WEEKDAY() 返回星期下标   WEEKOFYEAR() 返回参数在日历中对应的一年中的星期数   YEAR() 返回参数对应的年数   YEARWEEK() 返回年数和星期数    </description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/functions-and-operators-reference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/functions-and-operators-reference/</guid>
      <description>函数和操作符概述 TiDB 中函数和操作符使用方法与 MySQL 基本一致, 详情参见: Functions and Operators
在 SQL 语句中, 表达式可用于诸如 SELECT 语句的 ORDER BY 或 HAVING 子句, SELECT/ DELETE/ UPDATE 语句的 WHERE 子句, 或 SET 语句之类的地方.
可使用字面值, 列名, NULL, 内置函数, 操作符等来书写表达式.</description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/information-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/information-functions/</guid>
      <description> 信息函数 TiDB 中信息函数的使用方法与 MySQL 基本一致，详情参见: Information Functions.
信息函数表
   函数名 功能描述     CONNECTION_ID() 返回当前连接的连接 ID (线程 ID)   CURRENT_USER(), CURRENT_USER 返回当前用户的用户名和主机名   DATABASE() 返回默认(当前)的数据库名   FOUND_ROWS() 该函数返回对于一个包含 LIMIT 的 SELECT 查询语句，在不包含 LIMIT 的情况下回返回的记录数   LAST_INSERT_ID() 返回最后一条 INSERT 语句中自增列的值   SCHEMA() 与 DATABASE() 同义   SESSION_USER() 与 USER() 同义   SYSTEM_USER() 与 USER() 同义   USER() 返回客户端提供的用户名和主机名   VERSION() 返回当前 MySQL 服务器的版本信息   TIDB_VERSION 返回当前 TiDB 服务器的版本信息    </description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/operators/</guid>
      <description>操作符    操作符名 功能描述     AND, &amp;amp;&amp;amp; 逻辑与   = 赋值 (可用于 SET 语句中, 或用于 UPDATE 语句的 SET 中 )   := 赋值   BETWEEN ... AND ... 判断值满足范围   BINARY 将一个字符串转换为一个二进制字符串   &amp;amp; 位与   ~ 位非   \| 位或   ^ 按位异或   CASE case 操作符   DIV 整数除   / 除法   = 相等比较   &amp;lt;=&amp;gt; 空值安全型相等比较   &amp;gt; 大于   &amp;gt;= 大于或等于   IS 判断一个值是否等于一个布尔值   IS NOT 判断一个值是否不等于一个布尔值   IS NOT NULL 非空判断   IS NULL 空值判断   &amp;lt;&amp;lt; 左移   &amp;lt; 小于   &amp;lt;= 小于或等于   LIKE 简单模式匹配   - 减   %, MOD 求余   NOT, !</description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/precision-math/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/precision-math/</guid>
      <description>精度数学 TiDB 中精度数学计算与 MySQL 中基本一致, 详情请参见: Precision Math.
 数值类型 DECIMAL 数据类型的特性  数值类型 精确数值运算的范围包括精确值数据类型(整型和 DECIMAL 类型), 以及精确值数字字面量. 近似值数据类型和近似值数字字面量被作为浮点数来处理.
精确值数字字面量包含整数部分或小数部分, 或二者都包含. 精确值数字字面量可以包含符号位. 例如: 1, .2, 3.4, -5, -6.78, +9.10.
近似值数字字面量以一个包含尾数和指数的科学计数法表示(基数为 10). 其中尾数和指数可以分别或同时带有符号位. 例如: 1.2E3, 1.2E-3, -1.2E3, -1.2E-3.
两个看起来相似的数字可能会被以不同的方式进行处理. 例如, 2.34 是精确值(定点数), 而 2.3E0 是近似值(浮点数).
DECIMAL 数据类型是定点数类型, 其运算是精确计算. FLOAT 和 DOUBLE 数据类型是浮点类型, 其运算是近似计算.
DECIMAL 数据类型的特性 本节讨论 DECIMAL 数据类型的特性, 主要涉及以下几点:
 最大位数 存储格式 存储要求  DECIMAL 列的声明语法为 DECIMAL(M, D). 其中参数值意义及其范围如下:
 M 表示最大的数字位数 (精度).</description>
    </item>
    
    <item>
      <title>TiDB 用户文档</title>
      <link>https://pingcap.com/docs-cn/sql/user-manual/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/user-manual/</guid>
      <description> TiDB 用户文档 TiDB 支持 SQL92 标准并兼容 MySQL 语法，为了帮您更好地使用 TiDB, 该文档沿用了 MySQL 大部分的文档结构， 同时针对 TiDB 特有的功能作了详细的描述。
TiDB 数据库管理  TiDB 服务 TiDB 进程启动参数 TiDB 数据目录 TiDB 系统数据库 TiDB 系统变量 TiDB 专用系统变量和语法 TiDB 服务器日志文件 TiDB 访问权限管理 TiDB 用户账户管理 使用加密连接  SQL 优化  理解 TiDB 执行计划 统计信息  语言结构  字面值  字符串字面值 数字字面值 NULL 值 十六进制字面值 date 和 time 字面值 布尔值 bit-val 字面值  数据库、表、索引、列和别名 关键字和保留字 用户变量 表达式语法 注释语法  字符集和时区  字符集支持 字符集配置 时区  数据类型  数值类型 日期和时间类型 字符串类型 JSON 数据类型 数据类型默认值  函数和操作符  函数和操作符概述 表达式求值的类型转换 操作符 控制流程函数 字符串函数 数值函数与操作符 日期和时间函数 位函数和操作符 Cast 函数和操作符 加密和压缩函数 信息函数 JSON 函数 信息函数 全局事务 ID 函数 [TBD] GROUP BY 聚合函数 其他函数 精度数学  SQL 语句语法  数据定义语句(DDL) 数据操作语句(DML) 事务语句 数据库管理语句 Prepared SQL 语句语法 实用工具语句 TiDB SQL 语法图  JSON 支持  JSON 支持  Connectors 和 API  Connectors 和 API  错误码与故障诊断  错误码与故障诊断  与 MySQL 兼容性对比  与 MySQL 兼容性对比  </description>
    </item>
    
    <item>
      <title>TiDB 用户账户管理</title>
      <link>https://pingcap.com/docs-cn/sql/user-account-management/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/user-account-management/</guid>
      <description>TiDB 用户账户管理 用户名和密码 TiDB 将用户账户存储在 mysql.user 系统表里面。每个账户由用户名和 host 作为标识。每个账户可以设置一个密码。
通过 MySQL 客户端连接到 TiDB 服务器，通过指定的账户和密码登陆：
shell&amp;gt; mysql --port 4000 --user xxx --password 使用缩写的命令行参数则是：
shell&amp;gt; mysql -P 4000 -u xxx -p 添加用户 添加用户有两种方式：
 通过标准的用户管理的 SQL 语句创建用户以及授予权限，比如 CREATE USER 和 GRANT 。 直接通过 INSERT ， UPDATE 和 DELETE 操作授权表。  推荐的方式是使用第一种。第二种方式修改容易导致一些不完整的修改，因此不推荐。还有另一种可选方式是使用第三方工具的图形化界面工具。
下面的例子用 CREATE USER 和 GRANT 语句创建了四个账户：
mysql&amp;gt; CREATE USER &amp;#39;finley&amp;#39;@&amp;#39;localhost&amp;#39; IDENTIFIED BY &amp;#39;some_pass&amp;#39;; mysql&amp;gt; GRANT ALL PRIVILEGES ON *.* TO &amp;#39;finley&amp;#39;@&amp;#39;localhost&amp;#39; WITH GRANT OPTION; mysql&amp;gt; CREATE USER &amp;#39;finley&amp;#39;@&amp;#39;%&amp;#39; IDENTIFIED BY &amp;#39;some_pass&amp;#39;; mysql&amp;gt; GRANT ALL PRIVILEGES ON *.</description>
    </item>
    
    <item>
      <title>TiDB 监控框架概述</title>
      <link>https://pingcap.com/docs-cn/op-guide/monitor-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/monitor-overview/</guid>
      <description>TiDB 监控框架概述 TiDB 使用开源时序数据库 Prometheus 作为监控和性能指标信息存储方案，使用 Grafana 作为可视化组件进行展示。
Prometheus 是一个拥有多维度数据模型，灵活的查询语句的时序数据库。Prometheus 作为热门的开源项目，拥有活跃的社区及众多的成功案例。
Prometheus 提供了多个组件供用户使用。目前，我们使用 Prometheus Server，来收集和存储时间序列数据。Client 代码库，在程序中定制需要的 Metric 。Push GateWay 来接收 Client Push 上来的数据，统一供 Prometheus 主服务器抓取。以及 AlertManager 来实现报警机制。其结构如下图：
Grafana 是一个开源的 metric 分析及可视化系统。我们使用 Grafana 来展示 TiDB 的各项性能指标 。如下图所示:</description>
    </item>
    
    <item>
      <title>TiDB 简介与整体架构</title>
      <link>https://pingcap.com/docs-cn/overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/overview/</guid>
      <description>TiDB 简介与整体架构 TiDB 简介 TiDB 是 PingCAP 公司受 Google Spanner / F1 论文启发而设计的开源分布式 NewSQL 数据库。
TiDB 具备如下 NewSQL 核心特性：
 SQL支持（TiDB 是 MySQL 兼容的） 水平弹性扩展（吞吐可线性扩展） 分布式事务 跨数据中心数据强一致性保证 故障自恢复的高可用 海量数据高并发实时写入与实时查询（HTAP 混合负载）  TiDB 的设计目标是 100% 的 OLTP 场景和 80% 的 OLAP 场景，更复杂的 OLAP 分析可以通过 TiSpark 项目来完成。
TiDB 对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。
三篇文章了解 TiDB 技术内幕：
 说存储 说计算 谈调度  TiDB 整体架构 要深入了解 TiDB 的水平扩展和高可用特点，首先需要了解 TiDB 的整体架构。
TiDB 集群主要分为三个组件：
TiDB Server TiDB Server 负责接收 SQL 请求，处理 SQL 相关的逻辑，并通过 PD 找到存储计算所需数据的 TiKV 地址，与 TiKV 交互获取数据，最终返回结果。 TiDB Server 是无状态的，其本身并不存储数据，只负责计算，可以无限水平扩展，可以通过负载均衡组件（如LVS、HAProxy 或 F5）对外提供统一的接入地址。</description>
    </item>
    
    <item>
      <title>TiDB 系统数据库</title>
      <link>https://pingcap.com/docs-cn/sql/system-database/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/system-database/</guid>
      <description>TiDB 系统数据库 TiDB 的系统数据库跟 MySQL 类似，里面包含一些服务器运行时需要的信息。
权限系统表 这些系统表里面包含了用户账户以及相应的授权信息：
 user 用户账户，全局权限，以及其它一些非权限的列 db 数据库级别的权限 tables_priv 表级的权限 columns_priv 列级的权限  服务端帮助信息系统表  help_topic 目前为空  统计信息相关系统表  stats_buckets 统计信息的桶 stats_histograms 统计信息的直方图 stats_meta 表的元信息，比如总行数和修改数  GC Worker 相关系统表  gc_delete_range  其它系统表  GLOBAL_VARIABLES 全局系统变量表 tidb 用于 TiDB 在 bootstrap 的时候记录相关版本信息  INFORMATION_SCHEMA 里面的表 INFORMATION_SCHEMA 库里面的表主要是为了兼容 MySQL 而存在，有些第三方软件会查询里面的信息。在目前 TiDB 的实现中，里面大部分只是一些空表。
CHARACTER_SETS Table 提供字符集相关的信息，其实数据是假的。TiDB 默认支持并且只支持 utf8mb4 。
mysql&amp;gt; select * from CHARACTER_SETS; +--------------------|----------------------|-----------------------|--------+ | CHARACTER_SET_NAME | DEFAULT_COLLATE_NAME | DESCRIPTION | MAXLEN | +--------------------|----------------------|-----------------------|--------+ | ascii | ascii_general_ci | US ASCII | 1 | | binary | binary | Binary pseudo charset | 1 | | latin1 | latin1_swedish_ci | cp1252 West European | 1 | | utf8 | utf8_general_ci | UTF-8 Unicode | 3 | | utf8mb4 | utf8mb4_general_ci | UTF-8 Unicode | 4 | +--------------------|----------------------|-----------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>TiDB 运维文档</title>
      <link>https://pingcap.com/docs-cn/op-guide/op-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/op-guide/</guid>
      <description> TiDB 运维文档 软硬件环境需求  软硬件环境需求  部署集群  Ansible 部署方案 (强烈推荐) 离线 Ansible 部署方案 (强烈推荐) Docker 部署方案 跨机房部署方案  配置集群  配置参数  监控集群  整体监控框架概述 重要监控指标详解 组件状态 API &amp;amp; 监控  扩容缩容  使用 Ansible 扩容缩容 集群扩容缩容方案  升级  使用 Ansible 升级  性能调优  TiKV 性能参数调优  备份与迁移  备份与恢复 数据迁移  全量导入 增量导入   Binary 部署方案  Binary 部署方案  </description>
    </item>
    
    <item>
      <title>TiDB 进程启动参数和配置</title>
      <link>https://pingcap.com/docs-cn/sql/server-command-option/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/server-command-option/</guid>
      <description>TiDB 进程启动参数 启动 TiDB 进程时，可以指定一些程序启动参数。
TiDB 接受许多的启动参数，执行这个命令可以得到一个简要的说明：
./tidb-server --help 获取版本信息可以使用下面命令：
./tidb-server -V 以下是启动参数的完整描述。
-L  Log 级别 默认: &amp;ldquo;info&amp;rdquo; 可选值包括 debug, info, warn, error 或者 fatal  -P  TiDB 服务监听端口 默认: &amp;ldquo;4000&amp;rdquo; TiDB 服务将会使用这个端口接受 MySQL 客户端发过来的请求  --binlog-socket  TiDB 服务使用 unix socket file 方式接受内部连接，如 PUMP 服务 默认: &amp;ldquo;&amp;rdquo; 譬如使用 &amp;ldquo;/tmp/pump.sock&amp;rdquo; 来接受 PUMP unix socket file 通信  --config  TiDB 配置文件 默认: &amp;ldquo;&amp;rdquo; 配置文件的路径  --lease  Schema 的租约时间，单位：秒 默认: &amp;ldquo;10&amp;rdquo; Schema 的 lease 主要用在 online schema changes 上面。这个值会影响到实际的 DDL 语句的执行时间。大多数情况下，用户不需要修改这个值，除非您清晰的了解 TiDB DDL 的内部实现机制  --host  TiDB 服务监听 host 默认: &amp;ldquo;0.</description>
    </item>
    
    <item>
      <title>TiDB 集群扩容缩容方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/horizontal-scale/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/horizontal-scale/</guid>
      <description>TiDB 集群扩容缩容方案 概述 TiDB 集群可以在不影响线上服务的情况下动态进行扩容和缩容。
下面分别介绍如果增加或者删除 PD，TiKV 以及 TiDB 的节点。
下面用到的 pd-ctl 文档可以参考 pd-control。
PD 假设现在我们有三个 PD 服务，详细信息如下：
   Name ClientUrls PeerUrls     pd1 http://host1:2379 http://host1:2380   pd2 http://host2:2379 http://host2:2380   pd3 http://host3:2379 http://host3:2380    我们可以通过 pd-ctl 来查看当前所有 PD 节点的信息：
./pd-ctl -u http://host1:2379 &amp;gt;&amp;gt; member 动态添加节点 我们可以使用 join 参数，将一个新的 PD 服务加入到现有的 PD 集群里面。 如果我们需要添加 pd4，只需要在 --join 参数里面填入当前 PD 集群任意一个 PD 服务的 client url，比如：</description>
    </item>
    
    <item>
      <title>TiDB 集群故障诊断</title>
      <link>https://pingcap.com/docs-cn/trouble-shooting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/trouble-shooting/</guid>
      <description>TiDB 集群故障诊断 当试用 TiDB 遇到问题时，请先参考本篇文档。如果问题未解决，请按文档要求收集必要的信息通过 Github 提供给 TiDB 开发者。
如何给 TiDB 开发者报告错误 当使用 TiDB 遇到问题并且通过后面所列信息无法解决时，请收集以下信息并创建新 Issue:
 具体的出错信息以及正在执行的操作 当前所有组件的状态 出问题组件 log 中的 error/fatal/panic 信息 机器配置以及部署拓扑 dmesg 中 TiDB 组件相关的问题  数据库连接不上 首先请确认集群的各项服务是否已经启动，包括 tidb-server、pd-server、tikv-server。请用 ps 命令查看所有进程是否在。如果某个组件的进程已经不在了，请参考对应的章节排查错误。
如果所有的进程都在，请查看 tidb-server 的日志，看是否有报错？常见的错误包括：
 InfomationSchema is out of date
无法连接 tikv-server，请检查 pd-server 以及 tikv-server 的状态和日志。
 panic
程序有错误，请将具体的 panic log 提供给 TiDB 开发者。
  如果是清空数据并重新部署服务，请确认以下信息：
 pd-server、tikv-server 数据都已清空
tikv-server 存储具体的数据，pd-server 存储 tikv-server 中数据的的元信息。如果只清空 pd-server 或只清空 tikv-server 的数据，会导致两边数据不匹配。</description>
    </item>
    
    <item>
      <title>TiDB 集群监控</title>
      <link>https://pingcap.com/docs-cn/op-guide/monitor/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/monitor/</guid>
      <description>TiDB 集群监控 TiDB 集群状态监控目前有两种接口，第一种是通过 HTTP 接口对外汇报组件的信息，我们称之为组件的状态接口；第二种是使用 prometheus 记录组件中各种操作的详细信息，我们称之为 metrics 接口。
组件状态接口 这类接口可以获取组件的一些基本信息，并且可以作为 keepalive 监测接口。另外 PD 的接口可以看到整个 TiKV 集群的详细信息。
TiDB Server TiDB 对外暴露的 HTTP 接口是 http://host:port/status ，默认的端口号是 10080 （可以通过 &amp;ndash;status 参数设置），可以通过访问这个接口获取当前 TiDB Server 的状态，以及判断是否存活。返回结果是 Json 格式：
curl http://127.0.0.1:10080/status { connections: 0, version: &amp;#34;5.5.31-TiDB-1.0&amp;#34;, git_hash: &amp;#34;b99521846ff6f71f06e2d49a3f98fa1c1d93d91b&amp;#34; }  connection: 当前 TiDB Server 上的客户端连接数 version: TiDB 版本号 git_hash: TiDB 当前代码的 Git Hash  PD Server PD API 地址： http://${host}:${port}/pd/api/v1/${api_name}。
其中 port 默认为 2379，各类 api_name 详细信息参见 PD API Doc。</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/tools/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/tidb-binlog-kafka/</guid>
      <description>TiDB-Binlog User Guide This document describes how to deploy the Kafka version of TiDB-Binlog. If you need to deploy the local version of TiDB-Binlog, see the TiDB-Binlog user guide for the local version.
About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases</description>
    </item>
    
    <item>
      <title>TiDB-Binlog user guide</title>
      <link>https://pingcap.com/docs/tools/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tools/tidb-binlog/</guid>
      <description>TiDB-Binlog User Guide About TiDB-Binlog TiDB-Binlog is a tool for enterprise users to collect binlog files for TiDB and provide real-time backup and synchronization.
TiDB-Binlog supports the following scenarios:
 Data synchronization: to synchronize TiDB cluster data to other databases
 Real-time backup and recovery: to back up TiDB cluster data, and recover in case of cluster outages   TiDB-Binlog architecture The TiDB-Binlog architecture is as follows:
The TiDB-Binlog cluster mainly consists of two components:</description>
    </item>
    
    <item>
      <title>TiDB-Binlog 部署方案</title>
      <link>https://pingcap.com/docs-cn/tools/tidb-binlog-kafka/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/tidb-binlog-kafka/</guid>
      <description>TiDB-Binlog 部署方案 本文档介绍如何部署 Kafka 版本的 TiDB-Binlog。如需部署 local 版本的 TiDB-Binlog，可参考 local 版本的 TiDB-Binlog 部署文档。
TiDB-Binlog 简介 TiDB-Binlog 用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。
TiDB-Binlog 支持以下功能场景:
 数据同步: 同步 TiDB 集群数据到其他数据库 实时备份和恢复: 备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复  TiDB-Binlog 架构 首先介绍 TiDB-Binlog 的整体架构。
TiDB-Binlog 集群主要分为三个组件：
Pump Pump 是一个守护进程，在每个 TiDB 的主机上后台运行。他的主要功能是实时记录 TiDB 产生的 Binlog 并顺序写入kafka中
Drainer Drainer 从 kafka 中收集 Binlog，并按照在 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句，最后同步到目的数据库或者写到顺序文件
Kafka &amp;amp; Zookeeper Kafka 集群用来存储由 Pump 写入的 binlog 数据，并提供给 Drainer 进行读取。（local版本将 binlog 存储在文件中，最新版本都使用 Kafka 存储）</description>
    </item>
    
    <item>
      <title>TiDB-Binlog 部署方案</title>
      <link>https://pingcap.com/docs-cn/tools/tidb-binlog/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tools/tidb-binlog/</guid>
      <description>TiDB-Binlog 部署方案 TiDB-Binlog 简介 TiDB-Binlog 用于收集 TiDB 的 Binlog，并提供实时备份和同步功能的商业工具。
TiDB-Binlog 支持以下功能场景:
 数据同步: 同步 TiDB 集群数据到其他数据库 实时备份和恢复: 备份 TiDB 集群数据，同时可以用于 TiDB 集群故障时恢复  TiDB-Binlog 架构 首先介绍 TiDB-Binlog 的整体架构。
TiDB-Binlog 集群主要分为两个组件：
Pump Pump 是一个守护进程，在每个 TiDB 的主机上后台运行。他的主要功能是实时记录 TiDB 产生的 Binlog 并顺序写入磁盘文件
Drainer Drainer 从各个 Pump 节点收集 Binlog，并按照在 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句，最后同步到目的数据库或者写到顺序文件
TiDB-Binlog 安装 下载官方 Binary  CentOS 7+
# 下载压缩包 wget http://download.pingcap.org/tidb-binlog-local-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-binlog-local-linux-amd64.sha256 # 检查文件完整性，返回 ok 则正确 sha256sum -c tidb-binlog-local-linux-amd64.sha256 # 解开压缩包 tar -xzf tidb-binlog-local-linux-amd64.</description>
    </item>
    
    <item>
      <title>TiKV Engineer</title>
      <link>https://pingcap.com/recruit-cn/engineer/tikv-engineer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/engineer/tikv-engineer/</guid>
      <description>TiKV Engineer 岗位职责  负责分布式数据库 TiKV 相关的设计，开发
 负责构建分布式压力测试框架，稳定性测试框架
  职位要求  三年以上相关领域开发经验，扎实的编程能力，精通 C/C++/Go/Rust 中的一种
 对分布式系统的架构和原理有比较深入的了解
 优秀的发现和解决问题能力，良好的沟通能力，具备团队合作精神
  加分项  拥抱开源，对前沿技术有浓厚的热情和探索欲望，有开源项目经历
 熟悉 Paxos/Raft 等分布式一致性算法
 熟悉分布式事务模型
 熟悉操作系统底层知识，有 TCP/IP， IO 等系统调优经验
  待遇 20K - 40K + 期权, 13薪 + 奖金, 优秀者可面议
工作地点 北京，上海，广州，杭州，特别优秀可 remote</description>
    </item>
    
    <item>
      <title>TiKV 性能参数调优</title>
      <link>https://pingcap.com/docs-cn/op-guide/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/tune-tikv/</guid>
      <description>TiKV 性能参数调优 本文档用于描述如何根据机器配置情况来调整 TiKV 的参数，使 TiKV 的性能达到最优。
TiKV 最底层使用的是 RocksDB 做为持久化存储，所以 TiKV 的很多性能相关的参数都是与 RocksDB 相关的。TiKV 使用了两个 RocksDB 实例，默认 RocksDB 实例存储 KV 数据，Raft RocksDB 实例（简称 RaftDB）存储 Raft 数据。
TiKV 使用了 RocksDB 的 Column Falimies 特性。
默认 RocksDB 实例将 KV 数据存储在内部的 default、write 和 lock 3 个 CF 内。
 default CF 存储的是真正的数据，与其对应的参数位于 [rocksdb.defaultcf] 项中； write CF 存储的是数据的版本信息（MVCC）以及索引相关的数据，相关的参数位于 [rocksdb.writecf] 项中； lock CF 存储的是锁信息，系统使用默认参数。  Raft RocksDB 实例存储 Raft log。
 default CF 主要存储的是 raft log，与其对应的参数位于 [raftdb.</description>
    </item>
    
    <item>
      <title>TiSpark Quick Start Guide</title>
      <link>https://pingcap.com/docs/tispark/tispark-quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/tispark/tispark-quick-start-guide/</guid>
      <description>Quick Start Guide for the TiDB Connector for Spark To make it easy to try the TiDB Connector for Spark, TiDB cluster integrates Spark, TiSpark jar package and TiSpark sample data by default, in both the Pre-GA and master versions installed using TiDB-Ansible.
Deployment information  Spark is deployed by default in the spark folder in the TiDB instance deployment directory. The TiSpark jar package is deployed by default in the jars folder in the Spark deployment directory.</description>
    </item>
    
    <item>
      <title>TiSpark 快速入门指南</title>
      <link>https://pingcap.com/docs-cn/tispark/tispark-quick-start-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tispark/tispark-quick-start-guide/</guid>
      <description>TiSpark 快速入门指南 为了让大家快速体验 TiSpark, 通过 TiDB-Ansible 安装的 Pre-GA 或 master 版本 TiDB 集群中默认已集成 Spark、TiSpark jar 包及 TiSpark sample data。
部署信息  Spark 默认部署在 TiDB 实例部署目录下 spark 目录中 TiSpark jar 包默认部署在 Spark 部署目录 jars 文件夹下：
spark/jars/tispark-0.1.0-beta-SNAPSHOT-jar-with-dependencies.jar
 TiSpark sample data 及导入脚本默认部署在 TiDB-Ansible 目录下：
tidb-ansible/resources/bin/tispark-sample-data
  环境准备 在 TiDB 实例上安装 JDK 在 Oracle JDK 官方下载页面  下载 JDK 1.8 当前最新版，本示例中下载的版本为 jdk-8u141-linux-x64.tar.gz。
解压并根据您的 JDK 部署目录设置环境变量， 编辑 ~/.bashrc 文件，比如：
export JAVA_HOME=/home/pingcap/jdk1.8.0_144 export PATH=$JAVA_HOME/bin:$PATH 验证 JDK 有效性：</description>
    </item>
    
    <item>
      <title>TiSpark 用户指南</title>
      <link>https://pingcap.com/docs-cn/tispark/tispark-user-guide/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/tispark/tispark-user-guide/</guid>
      <description>TiSpark 用户指南 TiSpark 是 PingCAP 为解决用户复杂 OLAP 需求而推出的产品。借助 Spark 平台，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP （Hybrid Transactional/Analytical Processing）需求。 TiSpark 依赖于 TiKV 集群和 Placement Driver(PD)。当然，TiSpark 也需要您搭建一个 Spark 集群。
本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 相关信息。
概述 TiSpark 是将 Spark SQL 直接运行在分布式存储引擎 TiKV 上的 OLAP 解决方案。其架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查。 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。 除此之外，用户借助 TiSpark 项目可以在 TiDB 上使用 Spark 生态圈提供的多种工具进行数据处理。例如使用 TiSpark 进行数据分析和 ETL；使用 TiKV 作为机器学习的数据源；借助调度系统产生定时报表等等。  环境准备 现有 TiSpark 版本支持 Spark 2.</description>
    </item>
    
    <item>
      <title>Time Zone</title>
      <link>https://pingcap.com/docs/sql/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/time-zone/</guid>
      <description>Time Zone The time zone in TiDB is decided by the global time_zone system variable and the session time_zone system variable. The initial value for time_zone is &amp;lsquo;SYSTEM&amp;rsquo;, which indicates that the server time zone is the same as the system time zone.
You can use the following statement to set the global server time_zone value at runtime:
mysql&amp;gt; SET GLOBAL time_zone = timezone; Each client has its own time zone setting, given by the session time_zone variable.</description>
    </item>
    
    <item>
      <title>Transactions</title>
      <link>https://pingcap.com/docs/sql/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/transaction/</guid>
      <description>Transactions TiDB supports distributed transactions. The statements that relate to transactions include the Autocommit variable, START TRANSACTION/BEGIN, COMMIT and ROLLBACK.
Autocommit Syntax:
SET autocommit = {0 | 1} If you set the value of autocommit to 1, the status of the current Session is autocommit. If you set the value of autocommit to 0, the status of the current Session is non-autocommit. The value of autocommit is 1 by default.</description>
    </item>
    
    <item>
      <title>Try TiDB</title>
      <link>https://pingcap.com/docs-cn/op-guide/try-tidb/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/try-tidb/</guid>
      <description>Try TiDB TiDB 支持 SQL92 标准并兼容 MySQL 语法，目前已经实现了大多数常用的 MySQL 语法。用户可以直接使用现有的 MySQL 客户端连接。如果现有的业务已经基于 MySQL 开发，大多数情况不需要修改代码即可直接替换单机的 MySQL。
创建数据库 使用 CREATE DATABASE 语句可完成对数据库的创建, 创建命令的格式如下:
CREATE DATABASE 数据库名 [其他选项]; 例如我们需要创建一个名为 samp_db 的数据库, 在命令行下执行以下命令:
CREATE DATABASE IF NOT EXISTS samp_db; 查看 TiDB 中的所有数据库：
SHOW DATABASES; 删除数据库：
DROP DATABASE samp_db; 创建表 使用 CREATE TABLE + 表名 + 列名 + 数据类型 + 约束。具体例子如下：
CREATE TABLE person ( number INT(11), name VARCHAR(255), birthday DATE ); 如果表已存在，则使用关键词 IF NOT EXISTS 可以防止发生错误。</description>
    </item>
    
    <item>
      <title>Tune TiKV Performance</title>
      <link>https://pingcap.com/docs/op-guide/tune-tikv/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/op-guide/tune-tikv/</guid>
      <description>Tune TiKV Performance This document describes how to tune the TiKV parameters for optimal performance.
TiKV uses RocksDB for persistent storage at the bottom level of the TiKV architecture. Therefore, many of the performance parameters are related to RocksDB. TiKV uses two RocksDB instances: the default RocksDB instance stores KV data, the Raft RocksDB instance (RaftDB) stores Raft logs.
TiKV implements Column Families (CF) from RocksDB.
The default RocksDB instance stores KV data in the default, write and lock CFs.</description>
    </item>
    
    <item>
      <title>Type Conversion in Expression Evaluation</title>
      <link>https://pingcap.com/docs/sql/type-conversion-in-expression-evaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/type-conversion-in-expression-evaluation/</guid>
      <description>Type Conversion in Expression Evaluation TiDB behaves the same as MySQL: https://dev.mysql.com/doc/refman/5.7/en/type-conversion.html</description>
    </item>
    
    <item>
      <title>Understand the Query Execution Plan</title>
      <link>https://pingcap.com/docs/sql/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/understanding-the-query-execution-plan/</guid>
      <description>Understand the Query Execution Plan Based on the details of your tables, the TiDB optimizer chooses the most efficient query execution plan, which consists of a series of operators. This document details the execution plan information returned by the EXPLAIN statement in TiDB.
Optimize SQL statements using EXPLAIN The result of the EXPLAIN statement provides information about how TiDB executes SQL queries:
 EXPLAIN works together with SELECT, DELETE, INSERT, REPLACE, and UPDATE.</description>
    </item>
    
    <item>
      <title>Use Encrypted Connections</title>
      <link>https://pingcap.com/docs/sql/encrypted-connections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/encrypted-connections/</guid>
      <description>Use Encrypted Connections It is recommended to use the encrypted connection to ensure data security because non-encrypted connection might lead to information leak.
The TiDB server supports the encrypted connection based on the TLS (Transport Layer Security). The protocol is consistent with MySQL encrypted connections and is directly supported by existing MySQL clients such as MySQL operation tools and MySQL drivers. TLS is sometimes referred to as SSL (Secure Sockets Layer).</description>
    </item>
    
    <item>
      <title>User-Defined Variables</title>
      <link>https://pingcap.com/docs-cn/sql/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/user-defined-variables/</guid>
      <description>用户自定义变量 用户自定义变量格式为 @var_name。var_name 目前只支持字母，数字，_$组成。用户自定义变量是大小写不敏感的。
用户自定义变量是跟 session 绑定的，也就是说只有当前连接可以看见设置的用户变量，其他客户端连接无法查看到。
用 SET 语句可以设置用户自定义变量：
SET @var_name = expr [, @var_name = expr] ... 或 SET @var_name := expr 对于 SET 语句，赋值操作符可以是 = 也可以是 :=
例：
mysql&amp;gt; SET @a1=1, @a2=2, @a3:=4; mysql&amp;gt; SELECT @a1, @a2, @t3, @a4 := @a1+@a2+@a3; +------+------+------+--------------------+ | @a1 | @a2 | @a3 | @a4 := @a1+@a2+@a3 | +------+------+------+--------------------+ | 1 | 2 | 4 | 7 | +------+------+------+--------------------+ 如果设置用户变量用了 HEX 或者 BIT 值，TiDB会把它当成二进制字符串。如果你要将其设置成数字，那么需要手动加上 CAST转换: CAST(.</description>
    </item>
    
    <item>
      <title>User-Defined Variables</title>
      <link>https://pingcap.com/docs/sql/user-defined-variables/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/user-defined-variables/</guid>
      <description>User-Defined Variables The format of the user-defined variables is @var_name. @var_name consists of alphanumeric characters, _, and $. The user-defined variables are case-insensitive.
The user-defined variables are session specific, which means a user variable defined by one client cannot be seen or used by other clients. You can use the SET statement to set a user variable:
SET @var_name = expr [, @var_name = expr] ... or
SET @var_name := expr For SET, you can use = or := as the assignment operator.</description>
    </item>
    
    <item>
      <title>Utility Statements</title>
      <link>https://pingcap.com/docs/sql/util/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs/sql/util/</guid>
      <description>Utility Statements DESCRIBE statement The DESCRIBE and EXPLAIN statements are synonyms, which can also be abbreviated as DESC. See the usage of the EXPLAIN statement.
EXPLAIN statement {EXPLAIN | DESCRIBE | DESC} tbl_name [col_name] {EXPLAIN | DESCRIBE | DESC} [explain_type] explainable_stmt explain_type: FORMAT = format_name format_name: &amp;#34;DOT&amp;#34; explainable_stmt: { SELECT statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement } For more information about the EXPLAIN statement, see Understand the Query Execution Plan.</description>
    </item>
    
    <item>
      <title>与 MySQL 兼容性对比</title>
      <link>https://pingcap.com/docs-cn/sql/mysql-compatibility/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/mysql-compatibility/</guid>
      <description>与 MySQL 兼容性对比 TiDB 支持包括跨行事务，JOIN 及子查询在内的绝大多数 MySQL 的语法，用户可以直接使用现有的 MySQL 客户端连接。如果现有的业务已经基于 MySQL 开发，大多数情况不需要修改代码即可直接替换单机的 MySQL。
包括现有的大多数 MySQL 运维工具（如 PHPMyAdmin, Navicat, MySQL Workbench 等），以及备份恢复工具（如 mysqldump, mydumper/myloader）等都可以直接使用。
不过一些特性由于在分布式环境下没法很好的实现，目前暂时不支持或者是表现与 MySQL 有差异。
一些 MySQL 语法在 TiDB 中可以解析通过，但是不会做任何后续的处理，例如 Create Table 语句中 Engine 以及 Partition 选项，都是解析并忽略。更多兼容性差异请参考具体的文档。
不支持的特性  存储过程 视图 触发器 自定义函数 外键约束 全文索引 空间索引 非 UTF8 字符集  与 MySQL 有差异的特性 自增 ID TiDB 的自增 ID (Auto Increment ID) 只保证自增且唯一，并不保证连续分配。TiDB 目前采用批量分配的方式，所以如果在多台 TiDB 上同时插入数据，分配的自增 ID 会不连续。
 注意：</description>
    </item>
    
    <item>
      <title>事务语句</title>
      <link>https://pingcap.com/docs-cn/sql/transaction/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/transaction/</guid>
      <description>TiDB 事务语句 TiDB 支持分布式事务。涉及到事务的语句包括 Autocommit 变量、 START TRANSACTION/BEGIN、 COMMIT 以及 ROLLBACK。
自动提交 语法：
SET autocommit = {0 | 1} 通过设置 autocommit 的值为 1，可以将当前 Session 设置为自动提交状态，0 则表示当前 Session 为非自动提交状态。默认情况下， autocommit 的值为 1。
在自动提交状态，每条语句运行后，会将其修改自动提交到数据库中。否则，会等到运行 COMMIT 语句或者是 BEGIN 语句的时候，才会将之前的修改提交到数据库。
另外 autocommit 也是一个 System Variable，所以可以通过变量赋值语句修改当前 Session 或者是 Global 的值。
SET @@SESSION.autocommit = {0 | 1}; SET @@GLOBAL.autocommit = {0 | 1}; START TRANSACTION, Begin 语法:
BEGIN; START TRANSACTION; START TRANSACTION WITH CONSISTENT SNAPSHOT; 上述三条语句都是事务开始语句，效果相同。通过事务开始语句可以显式地开始一个新的事务，如果这个时候当前 Session 正在一个事务中间过程中，会将当前事务提交后，开启一个新的事务。</description>
    </item>
    
    <item>
      <title>使用 Docker Compose 构建集群</title>
      <link>https://pingcap.com/docs-cn/op-guide/docker-compose/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/docker-compose/</guid>
      <description>使用 Docker Compose 快速构建集群 Docker Compose 可以通过一个 YAML 文件定义多个容器的应用服务，然后一键启动或停止。可以用来在单机上一键部署一套 TiDB 测试集群，使用 Docker Compose 部署 TiDB 集群要求 Docker 是 17.06.0 及以上版本。
快速开始  下载 tidb-docker-compose
git clone https://github.com/pingcap/tidb-docker-compose.git 创建并启动集群
cd tidb-docker-compose &amp;amp;&amp;amp; docker-compose up -d 访问集群
mysql -h 127.0.0.1 -P 4000 -u root 访问集群 Grafana 监控页面：http://localhost:3000 默认用户名和密码都是 admin。
集群数据可视化：http://localhost:8010
  自定义集群 快速开始里面默认部署 3 个 PD，3 个 TiKV，1 个 TiDB 和监控组件 Prometheus，Pushgateway，Grafana 以及 tidb-vision。如果想自定义集群，可以直接修改 docker-compose.yml，但是手动修改比较繁琐而且容易出错，强烈建议使用 Helm 模板引擎生成 docker-compose.yml 文件。
 安装 Helm</description>
    </item>
    
    <item>
      <title>使用 root 用户远程连接 TiDB Ansible 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/root-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/root-ansible-deployment/</guid>
      <description>使用 root 用户远程连接 TiDB Ansible 部署方案  Ansible 远程连接用户(即 incentory.ini 文件中的 ansible_user)，从中控机使用 root 用户 SSH 到部署目标机器部署，不推荐采用该方式安装。
  修改 inventory.ini, 本例使用 tidb 帐户作为服务运行用户：
取消 ansible_user = root 、ansible_become = true 及 ansible_become_user 注释，给 ansible_user = tidb 添加注释：
## Connection # ssh via root: ansible_user = root ansible_become = true ansible_become_user = tidb # ssh via normal user # ansible_user = tidb 使用 local_prepare.yml playbook, 联网下载 TiDB binary 到中控机：
ansible-playbook local_prepare.</description>
    </item>
    
    <item>
      <title>使用加密连接</title>
      <link>https://pingcap.com/docs-cn/sql/encrypted-connections/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/encrypted-connections/</guid>
      <description>使用加密连接 TiDB 服务端默认采用非加密连接，因而具备监视信道流量能力的第三方可以知悉 TiDB 服务端与客户端之间发送和接受的数据，包括但不限于查询语句内容、查询结果等。若信道是不可信的，例如客户端是通过公网连接到 TiDB 服务端的，则非加密连接容易造成信息泄露，建议使用加密连接确保安全性。
TiDB 服务端支持启用基于 TLS（传输层安全）协议的加密连接，协议与 MySQL 加密连接一致，现有 MySQL 客户端如 MySQL 运维工具和 MySQL 驱动等能直接支持。TLS 的前身是 SSL，因而 TLS 有时也被称为 SSL，但由于 SSL 协议有已知安全漏洞，TiDB 实际上并未支持。TiDB 支持的 TLS/SSL 协议版本为 TLS 1.0、TLS 1.1、TLS 1.2。
使用加密连接后，连接将具有以下安全性质：
 保密性：流量明文无法被窃听； 完整性：流量明文无法被篡改； 身份验证（可选）：客户端和服务端能验证双方身份，避免中间人攻击。  TiDB 的加密连接支持默认是关闭的，必须在 TiDB 服务端通过配置开启加密连接的支持后，才能在客户端中使用加密连接。另外，与 MySQL 一致，TiDB 加密连接是以单个连接为单位的，并且是可选的，因而对于开启了加密连接支持的 TiDB 服务端，客户端既可以选择通过加密连接安全地连接到该 TiDB 服务端，也可以选择使用普通的非加密连接。大部分 MySQL 客户端默认不采用加密连接，因此一般还要显式地要求客户端使用加密连接。
简单来说，要使用加密连接必须同时满足以下两个条件：
 TiDB 服务端配置开启加密连接的支持 客户端指定使用加密连接  配置 TiDB 启用加密连接支持 在启动 TiDB 时，至少需要在配置文件中同时指定 ssl-cert 和 ssl-key 参数，才能使 TiDB 服务端接受加密连接。还可以指定 ssl-ca 参数进行客户端身份验证（请参见配置启用身份验证章节）。</description>
    </item>
    
    <item>
      <title>其他函数</title>
      <link>https://pingcap.com/docs-cn/sql/miscellaneous-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/miscellaneous-functions/</guid>
      <description> 其他函数    函数名 功能描述     ANY_VALUE() 在 ONLY_FULL_GROUP_BY 模式下，防止带有 GROUP BY 的语句报错   SLEEP() 休眠指定秒数   UUID() 返回通用唯一识别码 (UUID)   VALUES() 定义 INSERT 过程中要用到的值   INET_ATON() 将 IP 地址转换为数值   INET_NTOA() 将数值转换为 IP 地址   INET6_ATON() 将 IPv6 地址转换为数值    INET6_NTOA() 将数值转换为 IPv6 地址   IS_IPV4() 判断参数是否为 IPv4 地址   IS_IPV4_COMPAT() 判断参数是否为兼容 IPv4 的地址   IS_IPV4_MAPPED() 判断参数是否为 IPv4 映射的地址   IS_IPV6() 判断参数是否为 IPv6 地址   GET_LOCK()  获取命名锁，TiDB 出于兼容性支持这个函数，实际上不会做任何操作，这点和 MySQL 有区别   RELEASE_LOCK() 释放命名锁    </description>
    </item>
    
    <item>
      <title>加密和压缩函数</title>
      <link>https://pingcap.com/docs-cn/sql/encryption-and-compression-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/encryption-and-compression-functions/</guid>
      <description> 加密和压缩函数    函数名 功能描述     MD5()  计算字符串的 MD5 校验和    PASSWORD()（在 MySQL 5.7.6 中已弃用） 计算并返回密码字符串   RANDOM_BYTES() 返回随机字节向量   SHA1(), SHA()  计算 SHA-1 160 位校验和    SHA2()  计算 SHA-2 校验和    AES_DECRYPT() 使用 AES 解密   AES_ENCRYPT() 使用 AES 加密   COMPRESS() 返回经过压缩的二进制字符串   UNCOMPRESS() 解压缩字符串   UNCOMPRESSED_LENGTH()  返回字符串解压后的长度   CREATE_ASYMMETRIC_PRIV_KEY() 创建私钥   CREATE_ASYMMETRIC_PUB_KEY() 创建公钥   CREATE_DH_PARAMETERS() 创建 DH 共享密钥   CREATE_DIGEST() 从字符串创建摘要   ASYMMETRIC_DECRYPT() 使用公钥或私钥解密密文   ASYMMETRIC_DERIVE() 从非对称密钥导出对称密钥   ASYMMETRIC_ENCRYPT() 使用公钥或私钥加密明文   ASYMMETRIC_SIGN() 从摘要创建签名   ASYMMETRIC_VERIFY() 验证签名字符串是否匹配摘要字符串    </description>
    </item>
    
    <item>
      <title>十六进制的字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-hex-decimal/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-hex-decimal/</guid>
      <description>Hexadecimal Literals 十六进制字面值是有 X 和 0x 前缀的字符串，后接表示十六进制的数字。注意 0x 是大小写敏感的，不能表示为 0X。
例:
X&amp;#39;ac12&amp;#39; X&amp;#39;12AC&amp;#39; x&amp;#39;ac12&amp;#39; x&amp;#39;12AC&amp;#39; 0xac12 0x12AC 以下是不合法的十六进制字面值：
X&amp;#39;1z&amp;#39; (z 不是合法的十六进制值) 0X12AC (0X 必须用小写的 0x) 对于使用 X&#39;val&#39; 格式的十六进制字面值，val 必须要有一个数字，可以在前面补一个 0 来避免语法错误。
mysql&amp;gt; select X&amp;#39;aff&amp;#39;; ERROR 1105 (HY000): line 0 column 13 near &amp;#34;&amp;#34;hex literal: invalid hexadecimal format, must even numbers, but 3 (total length 13) mysql&amp;gt; select X&amp;#39;0aff&amp;#39;; +---------+ | X&amp;#39;0aff&amp;#39; | +---------+ | | +---------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>参数解释</title>
      <link>https://pingcap.com/docs-cn/op-guide/configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/configuration/</guid>
      <description>参数解释 TiDB --binlog-socket  TiDB 服务使用 unix socket file 方式接受内部连接，如 PUMP 服务 默认: &amp;ldquo;&amp;rdquo; 譬如我们可以使用 &amp;ldquo;/tmp/pump.sock&amp;rdquo; 来接受 PUMP unix socket file 通信  --cross-join  默认: true 在做 join 的时候，两边表没有任何条件（where 字段），默认可以执行这样的语句。但是设置为 false，则如有这样的 join 语句出现，server 会拒绝执行  --host  TiDB 服务监听 host 默认: &amp;ldquo;0.0.0.0&amp;rdquo; TiDB 服务会监听这个 host 0.0.0.0 默认会监听所有的网卡 address。如果有多块网卡，可以指定对外提供服务的网卡，譬如192.168.100.113  --join-concurrency int  join-concurrency 并发执行 join 的 goroutine 数量 默认: 5 看数据量和数据分布情况，一般情况下是越多越好，数值越大对 CPU 开销越大  -L  Log 级别 默认: &amp;ldquo;info&amp;rdquo; 我们能选择 debug, info, warn, error 或者 fatal  --lease  Schema 的租约时间，单位：秒 默认: &amp;ldquo;10&amp;rdquo; Schema 的 lease 主要用在 online schema changes 上面。这个值会影响到实际的 DDL 语句的执行时间。千万不要随便改动这个值，除非你能知道相关的内部机制  --log-file  Log 文件 默认: &amp;ldquo;&amp;rdquo; 如果没设置这个参数，log 会默认输出到 &amp;ldquo;stderr&amp;rdquo;，如果设置了，log 就会输出到对应的文件里面，在每天凌晨，log 会自动轮转使用一个新的文件，并且将以前的文件改名备份  --metrics-addr  Prometheus Push Gateway 地址 默认: &amp;ldquo;&amp;rdquo; 如果为空，TiDB 不会将统计信息推送给 Push Gateway,参数格式 如 --metrics-addr=192.</description>
    </item>
    
    <item>
      <title>售前技术总监</title>
      <link>https://pingcap.com/recruit-cn/sales/presales-director/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/sales/presales-director/</guid>
      <description>售前技术总监 岗位职责  带领售前团队
 负责组织制定公司数据库产品、数据库解决方案的技术方案编写、标书的准备、讲解及用户答疑等工作
 负责用户的技术交流、技术支持、POC 等工作
 负责合作伙伴厂商的技术交流
 和产品、社区、市场部门密切配合，负责相关的沟通、技术支持、技术文档撰写等工作
  职位要求  8年以上 IT 领域售前工作经验
 熟悉传统商业数据库（如 Oracle）及开源数据库，对云计算和大数据有深入的认识和实践
 丰富的方案设计、标书应答、用户交流经验
 良好的写作和口才、良好的沟通能力
 工作条理性强，具有很强的责任心和团队合作精神
 熟悉金融行业尤佳
  待遇 25K - 35K , 13薪 + 业绩奖金，优秀者可面议
工作地点 北京</description>
    </item>
    
    <item>
      <title>备份与恢复</title>
      <link>https://pingcap.com/docs-cn/op-guide/backup-restore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/backup-restore/</guid>
      <description>备份与恢复 概述 该文档详细介绍了如何对 TiDB 进行备份恢复。本文档暂时只考虑全量备份与恢复。
这里我们假定 TiDB 服务信息如下：
   Name Address Port User Password     TiDB 127.0.0.1 4000 root *    在这个备份恢复过程中，我们会用到下面的工具:
 mydumper 从 TiDB 导出数据 loader 导入数据到 TiDB  下载 TiDB 工具集 (Linux) # 下载 tool 压缩包 wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.tar.gz wget http://download.pingcap.org/tidb-enterprise-tools-latest-linux-amd64.sha256 # 检查文件完整性，返回 ok 则正确 sha256sum -c tidb-enterprise-tools-latest-linux-amd64.sha256 # 解开压缩包 tar -xzf tidb-enterprise-tools-latest-linux-amd64.tar.gz cd tidb-enterprise-tools-latest-linux-amd64 使用 mydumper/loader 全量备份恢复数据 mydumper 是一个强大的数据备份工具，具体可以参考 https://github.</description>
    </item>
    
    <item>
      <title>字符串函数</title>
      <link>https://pingcap.com/docs-cn/sql/string-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/string-functions/</guid>
      <description> 字符串函数    函数名 功能描述     ASCII() 返回最左字符的数值   CHAR()  返回由整数的代码值所给出的字符组成的字符串    BIN() 返回一个数的二进制值的字符串表示   HEX() 返回十进制值或字符串值的十六进制表示   OCT() 返回一个数的八进制值的字符串表示   UNHEX() 返回 HEX 表示的数字所代表的字符串   TO_BASE64() 返回转换为 BASE64 的字符串参数   FROM_BASE64() 解码为 BASE64 的字符串并返回结果   LOWER() 返回小写字母的字符   LCASE() 与 LOWER() 功能相同   UPPER() 返回大写字母的字符   UCASE() 与 UPPER() 功能相同   LPAD()  返回左边由指定字符串填充的字符串参数    RPAD()  返回右边由指定字符串填充的字符串参数    TRIM() 删除字符串的前缀和后缀   LTRIM()  删除前面的空格字符    RTRIM() 删除结尾的空格字符   BIT_LENGTH()  返回字符串的位长度    CHAR_LENGTH()  返回字符串的字符长度    CHARACTER_LENGTH() 与 CHAR_LENGTH() 功能相同   LENGTH()  返回字符串的字节长度    OCTET_LENGTH() 与 LENGTH() 功能相同   INSERT() 在指定位置插入一个子字符串，直到指定的字符数   REPLACE() 替换指定的字符串   SUBSTR() 返回指定的子字符串   SUBSTRING() 返回指定的子字符串   SUBSTRING_INDEX() 返回最终定界符左边或右边的子字符串   MID() 返回从指定位置开始的子字符串   LEFT() 返回指定的最左字符   RIGHT() 返回指定的最右字符   INSTR() 返回子字符串的第一个出现位置   LOCATE() 返回子字符串的第一个出现位置，与 INSTR() 的参数位置相反   POSITION() 与 LOCATE() 功能相同   REPEAT() 返回重复指定次数的字符串   CONCAT() 返回连接的字符串   CONCAT_WS() 返回由分隔符连接的字符串   REVERSE() 返回和字符顺序相反的字符串   SPACE() 返回指定数目的空格组成的字符串   FIELD() 返回参数在后续参数中出现的第一个位置   ELT() 返回指定位置的字符串   EXPORT_SET()  返回一个字符串，其中值位中设置的每个位，可以得到一个 on 字符串，而每个未设置的位，可以得到一个 off 字符串    MAKE_SET()  返回一组逗号分隔的字符串，由位集合中具有相应位的字符串组成    FIND_IN_SET() 返回第一个参数在第二个参数中出现的位置   FORMAT() 返回指定小数位数格式的数字   ORD() 返回参数中最左字符的字符代码   QUOTE()  引用一个字符串，返回一个在 SQL 语句中可用作正确转义的数据值的结果    SOUNDEX() 返回一个 soundex 字符串   SOUNDS LIKE  按发音比较字符串     字符串比较函数    函数名 功能描述     LIKE 进行简单模式匹配   NOT LIKE 否定简单模式匹配   STRCMP() 比较两个字符串   MATCH 执行全文搜索    正则表达式    表达式名 功能描述     REGEXP 使用正则表达式进行模式匹配   RLIKE 与 REGEXP 功能相同   NOT REGEXP 否定 REGEXP    </description>
    </item>
    
    <item>
      <title>字符串字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-string-literals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-string-literals/</guid>
      <description>String Literals String Literals 是一个 bytes 或者 characters 的序列，两端被单引号 &#39; 或者双引号 &amp;quot; 包围，例如：
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; 如果字符串是连续的，会被合并为一个独立的 string。以下表示是一样的：
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; 如果 ANSI_QUOTES SQL MODE 开启了，那么只有单引号内的会被认为是 String Literals，对于双引号内的字符串，会被认为是一个 identifier。
binary string 是一串 bytes 组成的字符串，每一个 binary string 有一个叫做 binary 的 character set 和 collation。一个非二进制的字符串是一个由字符组成的字符串，它有除 binary 外的 character set和与之兼容的 collation。
对于两种字符串类型，比较都是基于每个字符的数值。对于 binary string 而言，比较单元就是字节，对于非二进制的字符串，那么单元就是字符，而有的字符集支持多字节字符。
一个 String Literal 可以拥有一个可选的 character set introducer 和 COLLATE clause，可以用来指派特定的字符集跟 collation（TiDB 对此只是做了语法上的兼容，并不实质做处理)。</description>
    </item>
    
    <item>
      <title>字符集支持</title>
      <link>https://pingcap.com/docs-cn/sql/character-set-support/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/character-set-support/</guid>
      <description>字符集支持 名词解释，下面的阐述中会交错使用中文或者英文，请互相对照： * Character Set：字符集 * Collation：排序规则
目前 TiDB 支持以下字符集：
mysql&amp;gt; SHOW CHARACTER SET; +---------|---------------|-------------------|--------+ | Charset | Description | Default collation | Maxlen | +---------|---------------|-------------------|--------+ | utf8 | UTF-8 Unicode | utf8_bin | 3 | | utf8mb4 | UTF-8 Unicode | utf8mb4_bin | 4 | | ascii | US ASCII | ascii_bin | 1 | | latin1 | Latin1 | latin1_bin | 1 | | binary | binary | binary | 1 | +---------|---------------|-------------------|--------+ 5 rows in set (0.</description>
    </item>
    
    <item>
      <title>字符集配置</title>
      <link>https://pingcap.com/docs-cn/sql/character-set-configuration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/character-set-configuration/</guid>
      <description>字符集配置 目前 TiDB 还没有相应的配置来设置字符集，默认为 utf8。
更多细节</description>
    </item>
    
    <item>
      <title>字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-values/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-values/</guid>
      <description>字面值 String Literals String Literals 是一个 bytes 或者 characters 的序列，两端被单引号 &#39; 或者双引号 &amp;quot; 包围，例如：
&amp;#39;example string&amp;#39; &amp;#34;example string&amp;#34; 如果字符串是连续的，会被合并为一个独立的 string。以下表示是一样的：
&amp;#39;a string&amp;#39; &amp;#39;a&amp;#39; &amp;#39; &amp;#39; &amp;#39;string&amp;#39; &amp;#34;a&amp;#34; &amp;#39; &amp;#39; &amp;#34;string&amp;#34; 如果 ANSI_QUOTES SQL MODE 开启了，那么只有单引号内的会被认为是 String Literals，对于双引号内的字符串，会被认为是一个 identifier。
binary string 是一串 bytes 组成的字符串，每一个 binary string 有一个叫做 binary 的 character set 和 collation。一个非二进制的字符串是一个由字符组成的字符串，它有除 binary 外的 character set和与之兼容的 collation。
对于两种字符串类型，比较都是基于每个字符的数值。对于 binary string 而言，比较单元就是字节，对于非二进制的字符串，那么单元就是字符，而有的字符集支持多字节字符。
一个 String Literal 可以拥有一个可选的 character set introducer 和 COLLATE clause，可以用来指派特定的字符集跟 collation（TiDB 对此只是做了语法上的兼容，并不实质做处理)。</description>
    </item>
    
    <item>
      <title>实用工具语句</title>
      <link>https://pingcap.com/docs-cn/sql/util/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/util/</guid>
      <description>DESCRIBE 语句 DESCRIBE 和 EXPLAIN 是同义词，另外还可以缩写为 DESC。请参考 EXPLAIN 语句的用法。
EXPLAIN 语句 {EXPLAIN | DESCRIBE | DESC} tbl_name [col_name] {EXPLAIN | DESCRIBE | DESC} [explain_type] explainable_stmt explain_type: FORMAT = format_name format_name: &amp;#34;DOT&amp;#34; explainable_stmt: { SELECT statement | DELETE statement | INSERT statement | REPLACE statement | UPDATE statement } EXPLAIN 语句详细信息参考理解 TiDB 执行计划章节。
除了 MySQL 标准的结果格式之外，TiDB 还支持输出 DotGraph 结果，这时需要指定 FORMAT = &amp;quot;dot&amp;quot;，示例如下：
create table t(a bigint, b bigint); desc format = &amp;#34;dot&amp;#34; select A.</description>
    </item>
    
    <item>
      <title>市场运营</title>
      <link>https://pingcap.com/recruit-cn/market/operation-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/market/operation-manager/</guid>
      <description>市场运营 岗位职责  社区活动的维护运营，包括活动的主题策划、内容统筹、人员沟通、现场执行等运营工作；
 企业自媒体平台的日常运营，包括内容编辑、发布、维护、管理、互动、提高影响力和关注度；
 了解技术社区用户需求，收集反馈，根据运营数据挖掘和分析用户需求；
 资料的搜集与编辑整理。
  职位要求：  对 toB 的商业和市场具备一定的感知，了解 toB 或技术社区类运营的特点和调性；
 有亲和力，具有较强的表达与理解能力以及极强的团队合作意识，善于主动发现问题并及时沟通并解决；
 认真负责，逻辑清晰，有良好的文字和语言表达能力；
 性格开朗，积极热情，能够快速学习。
  待遇： 8K -15K，13薪 + 奖金，优秀者可面议
工作地点 北京</description>
    </item>
    
    <item>
      <title>开启 TLS 验证</title>
      <link>https://pingcap.com/docs-cn/op-guide/security/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/security/</guid>
      <description>开启 TLS 验证 概述 本文档介绍 TiDB 集群如何开启 TLS 验证，其支持：
 TiDB 组件之间的双向验证，包括 TiDB、TiKV、PD 相互之间，TiKV Control 与 TiKV、PD Control 与 PD 的双向认证，以及 TiKV peer 之间、PD peer 之间。一旦开启，所有组件之间均使用验证，不支持只开启某一部分的验证。 MySQL Client 与 TiDB 之间的客户端对服务器身份的单向验证以及双向验证。  MySQL Client 与 TiDB 之间使用一套证书，TiDB 集群组件之间使用另外一套证书。
TiDB 集群组件间开启 TLS（双向认证） 准备证书 推荐为 TiDB、TiKV、PD 分别准备一个 server 证书，并保证可以相互验证，而它们的各种客户端共用 client 证书。
有多种工具可以生成自签名证书，如 openssl，easy-rsa，cfssl。
这里提供一个使用 cfssl 生成证书的示例：生成自签名证书。
配置证书 TiDB 在 config 文件或命令行参数中设置：
[security] # Path of file that contains list of trusted SSL CAs for connection with cluster components.</description>
    </item>
    
    <item>
      <title>快速入门指南</title>
      <link>https://pingcap.com/docs-cn/QUICKSTART/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/QUICKSTART/</guid>
      <description>TiDB 快速入门指南 关于 TiDB TiDB 是开源分布式 SQL 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性。TiDB 兼容 MySQL，支持无限的水平扩展，具备强一致性和高可用性。TiDB 的目标是为在线事务和分析提供一站式的解决方案。
关于本指南 本指南为您介绍如何使用 TiDB-Ansible 快速部署一个 TiDB 集群，并了解 TiDB 的基本操作和管理。
TiDB 集群部署 本节具体介绍如何部署一个 TiDB 集群。一个 TiDB 集群由不同的模块组成，包括：TiDB 服务器、TiKV 服务器、Placement Driver (PD) 服务器。
架构图如下所示：
参考TiDB Ansible 部署方案。
TiDB 基本操作 本节具体介绍 TiDB 中基本的增删改查操作。
创建、查看和删除数据库 使用 CREATE DATABASE 语句创建数据库。语法如下：
CREATE DATABASE db_name [options]; 例如，要创建一个名为 samp_db 的数据库，可使用以下语句：
CREATE DATABASE IF NOT EXISTS samp_db; 使用 SHOW DATABASES 语句查看数据库：
SHOW DATABASES; 使用 DROP DATABASE 语句删除数据库，例如：</description>
    </item>
    
    <item>
      <title>控制流程函数</title>
      <link>https://pingcap.com/docs-cn/sql/control-flow-functions/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/control-flow-functions/</guid>
      <description> 控制流程函数    函数名 功能描述     CASE Case 操作符   IF() 构建 if/else   IFNULL() 构建 Null if/else   NULLIF() 如果 expr1 = expr2，返回 NULL    </description>
    </item>
    
    <item>
      <title>数值函数与操作符</title>
      <link>https://pingcap.com/docs-cn/sql/numeric-functions-and-operators/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/numeric-functions-and-operators/</guid>
      <description> 数值函数与操作符 算术操作符    操作符名 功能描述     + 加号   - 减号   * 乘号   / 除号   DIV 整数除法   %, MOD 模运算，取余   - 更改参数符号    数学函数    函数名 功能描述     POW() 返回参数的指定乘方的结果值   POWER() 返回参数的指定乘方的结果值   EXP() 返回 e（自然对数的底）的指定乘方后的值   SQRT() 返回非负数的二次方根   LN() 返回参数的自然对数   LOG() 返回第一个参数的自然对数   LOG2() 返回参数以 2 为底的对数   LOG10() 返回参数以 10 为底的对数   PI() 返回 pi 的值   TAN() 返回参数的正切值   COT() 返回参数的余切值   SIN() 返回参数的正弦值   COS() 返回参数的余弦值   ATAN() 返回参数的反正切值   ATAN2(), ATAN() 返回两个参数的反正切值   ASIN() 返回参数的反正弦值   ACOS() 返回参数的反余弦值   RADIANS() 返回由度转化为弧度的参数   DEGREES() 返回由弧度转化为度的参数   MOD() 返回余数   ABS() 返回参数的绝对值   CEIL() 返回不小于参数的最小整数值   CEILING() 返回不小于参数的最小整数值   FLOOR() 返回不大于参数的最大整数值   ROUND() 返回参数最近似的整数或指定小数位数的数值   RAND() 返回一个随机浮点值   SIGN() 返回参数的符号   CONV() 不同数基间转换数字，返回数字的字符串表示   TRUNCATE() 返回被舍位至指定小数位数的数字   CRC32()  计算循环冗余码校验值并返回一个 32 位无符号值     </description>
    </item>
    
    <item>
      <title>数值字面值</title>
      <link>https://pingcap.com/docs-cn/sql/literal-value-numeric-literals/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/literal-value-numeric-literals/</guid>
      <description>Numeric Literals 数值字面值包括 integer 跟 Decimal 类型跟浮点数字面值。
integer 可以包括 . 作为小数点分隔，数字前可以有 - 或者 + 来表示正数或者负数。
精确数值字面值可以表示为如下格式：1, .2, 3.4, -5, -6.78, +9.10.
科学记数法也是被允许的，表示为如下格式：1.2E3, 1.2E-3, -1.2E3, -1.2E-3。
更多细节</description>
    </item>
    
    <item>
      <title>数据库管理语句</title>
      <link>https://pingcap.com/docs-cn/sql/admin/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/admin/</guid>
      <description>TiDB 可以通过一些语句对数据库进行管理，包括设置权限、修改系统变量、查询数据库状态。
权限管理 参考权限管理文档。
SET 语句 SET 语句有多种作用和形式：
设置变量值 SET variable_assignment [, variable_assignment] ... variable_assignment: user_var_name = expr | param_name = expr | local_var_name = expr | [GLOBAL | SESSION] system_var_name = expr | [@@global. | @@session. | @@] system_var_name = expr 这种语法可以设置 TiDB 的变量值，包括系统变量以及用户定义变量。对于用户自定义变量，都是会话范围的变量；对于系统变量，通过 @@global. 或者是 GLOBAL 设置的变量为全局范围变量，否则为会话范围变量，具体参考系统变量一章。
SET CHARACTER 语句和 SET NAMES SET {CHARACTER SET | CHARSET} {&amp;#39;charset_name&amp;#39; | DEFAULT} SET NAMES {&amp;#39;charset_name&amp;#39; [COLLATE &amp;#39;collation_name&amp;#39;] | DEFAULT} 这个语句设置这三个会话范围的系统变量：character_set_client，character_set_results，character_set_connection 设置为给定的字符集。目前 character_set_connection 变量的值和 MySQL 有所区别，MySQL 将其设置为 character_set_database 的值。</description>
    </item>
    
    <item>
      <title>数据操作语言</title>
      <link>https://pingcap.com/docs-cn/sql/dml/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/dml/</guid>
      <description>TiDB 数据操作语言 数据操作语言（Data Manipulation Language， DML）用于帮助用户实现对数据库的基本操作，比如查询、写入、删除和修改数据库中的数据。
TiDB 支持的数据操作语言包括 Select ，Insert, Delete, Update，和 Replace。
Select 语句 Select 语句用于从数据库中查询数据。
语法定义 SELECT [ALL | DISTINCT | DISTINCTROW ] [HIGH_PRIORITY] [SQL_CACHE | SQL_NO_CACHE] [SQL_CALC_FOUND_ROWS] select_expr [, select_expr ...] [FROM table_references [WHERE where_condition] [GROUP BY {col_name | expr | position} [ASC | DESC], ...] [HAVING where_condition] [ORDER BY {col_name | expr | position} [ASC | DESC], ...] [LIMIT {[offset,] row_count | row_count OFFSET offset}] [FOR UPDATE | LOCK IN SHARE MODE]] 语法元素说明    语法元素 说明     ALL、DISTINCT、DISTINCTROW 查询结果集中可能会包含重复值。指定 DISTINCT/DISTINCTROW 则在查询结果中过滤掉重复的行；指定 ALL 则列出所有的行。默认为 ALL。   HIGH_PRIORITY 该语句为高优先级语句，TiDB 在执行阶段会优先处理这条语句   SQL_CACHE、SQL_NO_CACHE、SQL_CALC_FOUND_ROWS TiDB 出于兼容性解析这三个语法，但是不做任何处理   select_expr 投影操作列表，一般包括列名、表达式，或者是用 &amp;lsquo;*&amp;rsquo; 表示全部列   FROM table_references 表示数据来源，数据来源可以是一个表（select * from t;）或者是多个表 (select * from t1 join t2;) 或者是0个表 (select 1+1 from dual;, 等价于 select 1+1;)   WHERE where_condition Where 子句用于设置过滤条件，查询结果中只会包含满足条件的数据   GROUP BY GroupBy 子句用于对查询结果集进行分组   HAVING where_condition Having 子句与 Where 子句作用类似，Having 子句可以让过滤 GroupBy 后的各种数据，Where 子句用于在聚合前过滤记录。   ORDER BY OrderBy 子句用于指定结果排序顺序，可以按照列、表达式或者是 select_expr 列表中某个位置的字段进行排序。   LIMIT Limit 子句用于限制结果条数。Limit 接受一个或两个数字参数，如果只有一个参数，那么表示返回数据的最大行数；如果是两个参数，那么第一个参数表示返回数据的第一行的偏移量（第一行数据的偏移量是 0），第二个参数指定返回数据的最大条目数。   FOR UPDATE 对查询结果集所有数据上读锁，以监测其他事务对这些的并发修改。TiDB 使用乐观事务模型在语句执行期间不会检测锁冲突，在事务的提交阶段才会检测事务冲突，如果执行 Select For Update 期间，有其他事务修改相关的数据，那么包含 Select For Update 语句的事务会提交失败。   LOCK IN SHARE MODE TiDB 出于兼容性解析这个语法，但是不做任何处理    Insert 语句 Insert 语句用于向数据库中插入数据，TiDB 兼容 MySQL Insert 语句的所有语法。</description>
    </item>
    
    <item>
      <title>数据迁移</title>
      <link>https://pingcap.com/docs-cn/op-guide/migration/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/migration/</guid>
      <description>数据迁移 使用 mydumper/loader 全量导入数据 mydumper 是一个更强大的数据迁移工具，具体可以参考 https://github.com/maxbube/mydumper。
我们使用 mydumper 从 MySQL 导出数据，然后用 loader 将其导入到 TiDB 里面。
 注意：虽然 TiDB 也支持使用 MySQL 官方的 mysqldump 工具来进行数据的迁移工作，但相比于 mydumper / loader，性能会慢很多，大量数据的迁移会花费很多时间，这里我们并不推荐。
 mydumper/loader 全量导入数据最佳实践 为了快速的迁移数据 (特别是数据量巨大的库), 可以参考下面建议
 mydumper 导出数据至少要拥有 SELECT , RELOAD , LOCK TABLES 权限 使用 mydumper 导出来的数据文件尽可能的小, 最好不要超过 64M, 可以设置参数 -F 64 loader的 -t 参数可以根据 tikv 的实例个数以及负载进行评估调整，例如 3个 tikv 的场景， 此值可以设为 3 *（1 ～ n)；当 tikv 负载过高，loader 以及 tidb 日志中出现大量 backoffer.</description>
    </item>
    
    <item>
      <title>数据迁移概述</title>
      <link>https://pingcap.com/docs-cn/op-guide/migration-overview/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/migration-overview/</guid>
      <description>数据迁移概述 概述 该文档详细介绍了如何将 MySQL 的数据迁移到 TiDB。
这里我们假定 MySQL 以及 TiDB 服务信息如下：
   Name Address Port User Password     MySQL 127.0.0.1 3306 root *   TiDB 127.0.0.1 4000 root *    在这个数据迁移过程中，我们会用到下面四个工具:
 checker 检查 schema 能否被 TiDB 兼容 mydumper 从 MySQL 导出数据 loader 导入数据到 TiDB syncer 增量同步 MySQL 数据到 TiDB  两种迁移场景  第一种场景：只全量导入历史数据 （需要 checker + mydumper + loader）； 第二种场景：全量导入历史数据后，通过增量的方式同步新的数据 （需要 checker + mydumper + loader + syncer）。该场景需要提前开启 binlog 且格式必须为 ROW。  MySQL 开启 binlog 注意： 只有上文提到的第二种场景才需要在 dump 数据之前先开启 binlog</description>
    </item>
    
    <item>
      <title>日期和时间类型</title>
      <link>https://pingcap.com/docs-cn/sql/date-and-time-types/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/date-and-time-types/</guid>
      <description>日期和时间类型 用于表示日期和时间类型的值是 DATE，TIME，DATETIME，TIMESTAMP 和 YEAR。每一种类型都有自己的有效值的范围，也有一个零值用于表示它是一个无效的值。TIMESTAMP 类型有个自动更新的行为，后面介绍。
处理日期和时间类型时，请记住下面这些：
 尽管 TiDB 尝试解释不同的格式，日期部分必须是按 年-月-日 的顺序（比如，&amp;rsquo;98-09-04&amp;rsquo;），而不是 月-日-年 或者 日-月-年 的顺序。 日期值中包含两位数字的年份是有歧义的，TiDB 按下面规则解释：  范围在 70-99 之间的被转换成 1970-1999 范围在 00-69 之间的被转换成 2000-2069  如果上下文里面需要的是一个数值，TiDB 自动将日期或时间值转换成数值类型，反之亦然。 如果 TiDB 遇到一个日期或时间值是超过表示范围的，或者无效的，会自动将它转换为该类型的零值。 设置不同的 SQL mode 可以改变 TiDB 的行为。 TiDB 允许 DATE 和 DATETIME 列中出现月份或者日为零的值，比如 &amp;lsquo;2009-00-00&amp;rsquo; 或 &amp;lsquo;2009-01-00&amp;rsquo;。如果这种日期参与计算，比如函数 DATE_SUB() 或者 DATE_ADD()，得到的结果可能会不正确。 TiDB 允许存储零值 &amp;lsquo;0000-00-00&amp;rsquo;，有时候这会比 NULL 值更方便一些。  下面的表格里面显示了不同类型的零值：
   Date Type &amp;ldquo;Zero&amp;rdquo; Value     DATE &amp;lsquo;0000-00-00&amp;rsquo;   TIME &amp;lsquo;00:00:00&amp;rsquo;   DATETIME &amp;lsquo;0000-00-00 00:00:00&amp;rsquo;   TIMESTAMP &amp;lsquo;0000-00-00 00:00:00&amp;rsquo;   YEAR 0000    DATE，DATETIME 和 TIMESTAMP 类型 DATE，DATETIME，TIMESTAMP 类型都是相关的。这里描述它们的共同点和区别。</description>
    </item>
    
    <item>
      <title>时区支持</title>
      <link>https://pingcap.com/docs-cn/sql/time-zone/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/time-zone/</guid>
      <description>TiDB 使用的时区由 time_zone 全局变量和 session 变量决定。time_zone 的初始值是机器当前的系统时区 &amp;lsquo;SYSTEM&amp;rsquo; 。
在运行过程中可以修改全局时区：
mysql&amp;gt; SET GLOBAL time_zone = timezone; TiDB 还可以通过设置 session 变量 time_zone 为每个连接维护各自的时区。默认条件下，这个值取的是全局变量 time_zone 的值。修改 session 使用的时区：
mysql&amp;gt; SET time_zone = timezone; 查看当前使用的时区的值：
mysql&amp;gt; SELECT @@global.time_zone, @@session.time_zone; 设置 time_zone 的值的格式：
 &amp;lsquo;SYSTEM&amp;rsquo; 表明使用系统时间 相对于 UTC 时间的偏移，比如 &amp;lsquo;+10:00&amp;rsquo; 或者 &amp;lsquo;-6:00&amp;rsquo; 某个时区的名字，比如 &amp;lsquo;Europe/Helsinki&amp;rsquo;， &amp;lsquo;US/Eastern&amp;rsquo; 或 &amp;lsquo;MET&amp;rsquo;  NOW() 和 CURTIME() 的返回值都受到时区设置的影响。
注意，只有 Timestamp 数据类型的值是受时区影响的。可以理解为， Timestamp 数据类型的实际表示使用的是 (字面值 + 时区信息)。其它时间和日期类型，比如 Datetime/Date/Time 是不包含时区信息的，所以也不受到时区变化的影响。
mysql&amp;gt; create table t (ts timestamp, dt datetime); Query OK, 0 rows affected (0.</description>
    </item>
    
    <item>
      <title>权限管理</title>
      <link>https://pingcap.com/docs-cn/sql/privilege/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/privilege/</guid>
      <description>权限管理 权限管理概述 TiDB的权限管理系统是按照 MySQL 的权限管理进行实现，大部分的 MySQL 的语法和权限类型都是支持的。如果发现行为跟 MySQL 不一致的地方，欢迎报告 issue。
示例 用户账户操作 更改密码 set password for &amp;#39;root&amp;#39;@&amp;#39;%&amp;#39; = &amp;#39;xxx&amp;#39;; 添加用户 create user &amp;#39;test&amp;#39;@&amp;#39;127.0.0.1&amp;#39; identified by &amp;#39;xxx&amp;#39;; 用户名是大小写敏感的。host则支持模糊匹配，比如：
create user &amp;#39;test&amp;#39;@&amp;#39;192.168.10.%&amp;#39;; 允许 test 用户从 192.168.10 子网的任何一个主机登陆。
如果没有指定 host，则默认是所有 IP 均可登陆。如果没有指定密码，默认为空：
create user &amp;#39;test&amp;#39;; 等价于
create user &amp;#39;test&amp;#39;@&amp;#39;%&amp;#39; identified by &amp;#39;&amp;#39;; 删除用户 drop user &amp;#39;test&amp;#39;@&amp;#39;%&amp;#39;; 这个操作会清除用户在 mysql.user 表里面的记录项，并且清除在授权表里面的相关记录。
忘记root密码 使用一个特殊的启动参数启动 TiDB（需要root权限）：
sudo ./tidb-server -skip-grant-table=true 这个参数启动，TiDB 会跳过权限系统，然后使用 root 登陆以后修改密码：
mysql -h 127.0.0.1 -P 4000 -u root 权限相关操作 授予权限 授予 xxx 用户对数据库 test 的读权限：</description>
    </item>
    
    <item>
      <title>注释语法</title>
      <link>https://pingcap.com/docs-cn/sql/comment-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/comment-syntax/</guid>
      <description>注释语法 TiDB 支持三种注释风格：
 用 # 注释一行 用 -- 注释一行，用 -- 注释必须要在其之后留出至少一个空格。 用 /* */ 注释一块，可以注释多行。  例：
mysql&amp;gt; SELECT 1+1; # This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.00 sec) mysql&amp;gt; SELECT 1+1; -- This comment continues to the end of line +------+ | 1+1 | +------+ | 2 | +------+ 1 row in set (0.</description>
    </item>
    
    <item>
      <title>渠道合作总监</title>
      <link>https://pingcap.com/recruit-cn/sales/channel-co-director/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/sales/channel-co-director/</guid>
      <description>渠道合作总监 岗位职责  根据公司产品（分布式数据库）特性，负责相关合作伙伴的建立、维护、发展与管理
 制定相关合作伙伴的拓展计划
 执行并完成相关合作伙伴拓展计划和销售任务
 配合销售及市场部门完成相关工作
  职位要求  本科以上学历,三年以上软件行业渠道销售经验
 与主要IT系统集成商、行业应用软件开发商具有良好的合作关系
 具有良好的渠道拓展能力和丰富的渠道资源和渠道管理经验
 具有数据库软件等基础软件渠道销售经验者优先，有技术背景优先
 强烈的责任心、良好的沟通能力、团队协作能力
  待遇 20K - 35K , 13薪 + 业绩奖金，优秀者可面议
工作地点 北京</description>
    </item>
    
    <item>
      <title>理解 TiDB 执行计划</title>
      <link>https://pingcap.com/docs-cn/sql/understanding-the-query-execution-plan/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/understanding-the-query-execution-plan/</guid>
      <description>理解 TiDB 执行计划 TiDB 优化器会根据当前数据表的实际情况来选择最优的执行计划，执行计划由一系列的 operator 构成，这里我们详细解释一下 TiDB 中 EXPLAIN 语句返回的执行计划信息。
使用 EXPLAIN 来优化 SQL 语句 EXPLAIN 语句的返回结果提供了 TiDB 执行 SQL 查询的详细信息：
 EXPLAIN 可以和 SELECT, DELETE, INSERT, REPLACE, 以及 UPDATE 语句一起使用； 执行 EXPLAIN，TiDB 会返回被 EXPLAIN 的 SQL 语句经过优化器后的最终物理执行计划。也就是说，EXPLAIN 展示了 TiDB 执行该 SQL 语句的完整信息，比如以什么样的顺序，什么方式 JOIN 两个表，表达式树长什么样等等。详细请看 EXPLAIN 输出格式； TiDB 目前还不支持 EXPLAIN [options] FOR CONNECTION connection_id，我们将在未来支持它，详细请看：#4351；  通过观察 EXPLAIN 的结果，你可以知道如何给数据表添加索引使得执行计划使用索引从而加速 SQL 语句的执行速度；你也可以使用 EXPLAIN 来检查优化器是否选择了最优的顺序来 JOIN 数据表。
EXPLAIN 输出格式 目前 TiDB 的 EXPLAIN 会输出 6 列，分别是：id，parents，children，task，operator info 和 count，执行计划中每个 operator 都由这 6 列属性来描述，EXPLAIN 结果中每一行描述一个 operator。下面详细解释每个属性的含义：</description>
    </item>
    
    <item>
      <title>生成自签名证书</title>
      <link>https://pingcap.com/docs-cn/op-guide/generate-self-signed-certificates/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/generate-self-signed-certificates/</guid>
      <description>生成自签名证书 概述 本文档提供使用 cfssl 生成自签名证书的示例。
假设实例集群拓扑如下：
   Name Host IP Services     node1 172.16.10.1 PD1, TiDB1   node2 172.16.10.2 PD2, TiDB2   node3 172.16.10.3 PD3   node4 172.16.10.4 TiKV1   node5 172.16.10.5 TiKV2   node6 172.16.10.6 TiKV3    下载 cfssl 假设使用 x86_64 Linux 主机：
mkdir ~/bin curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 curl -s -L -o ~/bin/cfssljson https://pkg.</description>
    </item>
    
    <item>
      <title>离线 TiDB Ansible 部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/offline-ansible-deployment/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/offline-ansible-deployment/</guid>
      <description>离线 TiDB Ansible 部署方案 准备机器  下载机一台
 该机器需开放外网访问，用于下载 TiDB-Ansible、TiDB 及相关软件安装包。 推荐安装 CentOS 7.3 及以上版本 Linux 操作系统。  部署目标机器若干及部署中控机一台
 系统要求及配置参考准备机器。 可以无法访问外网。   在中控机器上离线安装 Ansible 及其依赖  CentOS 7 系统 Ansible 离线安装方式：
 下载 Ansible  离线安装包 ，上传至中控机。
 # tar -xzvf ansible-2.4-rpms.el7.tar.gz  # cd ansible-2.4-rpms.el7  # rpm -ivh PyYAML*rpm libyaml*rpm python-babel*rpm python-backports*rpm python-backports-ssl_match_hostname*rpm python-cffi*rpm python-enum34*rpm python-httplib2*rpm python-idna*rpm python-ipaddress*rpm python-jinja2*rpm python-markupsafe*rpm python-paramiko*rpm python-passlib*rpm python-ply*rpm python-pycparser*rpm python-setuptools*rpm python-six*rpm python2-cryptography*rpm python2-jmespath*rpm python2-pyasn1*rpm sshpass*rpm  # rpm -ivh ansible-2.</description>
    </item>
    
    <item>
      <title>系统变量</title>
      <link>https://pingcap.com/docs-cn/sql/variable/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/variable/</guid>
      <description>系统变量 MySQL 系统变量 (System Variables) 是一些系统参数，用于调整数据库运行时的行为，根据变量的作用范围分为全局范围有效（Global Scope）以及会话级别有效（Session Scope）。TiDB 支持 MySQL5.7 的所有系统变量，大部分变量仅仅是为了兼容性而支持，不会影响运行时行为。
设置系统变量 通过 SET 语句可以修改系统变量的值。进行修改时，还要考虑变量可修改的范围，不是所有的变量都能在全局/会话范围内进行修改。具体的可修改范围参考 MySQL 动态变量文档。
全局范围值  在变量名前加 GLOBAL 关键词或者是使用 @@global. 作为修饰符:  SET GLOBAL autocommit = 1; SET @@global.autocommit = 1; 会话范围值  在变量名前加 SESSION 关键词或者是使用 @@session. 作为修饰符，或者是不加任何修饰符:  SET SESSION autocommit = 1; SET @@session.autocommit = 1; SET @@autocommit = 1;  LOCAL 以及 @@local. 是 SESSION 以及 @@session. 的同义词  TiDB 支持的 MySQL 系统变量 下列系统变量是 TiDB 真正支持并且行为和 MySQL 一致：</description>
    </item>
    
    <item>
      <title>统计信息简介</title>
      <link>https://pingcap.com/docs-cn/sql/statistics/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/statistics/</guid>
      <description>统计信息简介 TiDB 优化器会根据统计信息来选择最优的执行计划。统计信息收集了表级别和列级别的信息，表的统计信息包括总行数，以及修改的行数。列的统计信息包括不同值的数量，NULL 的数量，以及该列的直方图信息。
统计信息的收集 手动收集 你可以通过执行 ANALYZE 语句来收集统计信息。
语法：
ANALYZE TABLE TableNameList &amp;gt; 该语句会收集 TableNameList 中所有表的统计信息。 ANALYZE TABLE TableName INDEX IndexNameList &amp;gt; 该语句会收集 TableName 中所有的 IndexNameList 中的索引列的统计信息。 自动更新 在发生增加，删除以及修改语句时，TiDB 会自动更新表的总行数以及修改的行数。这些信息会定期持久化下来， 更新的周期是 5 * stats-lease, stats-lease 的默认值是 3s，如果将其指定为 0，那么将不会自动更新。
控制 ANALYZE 并发度 执行 ANALYZE 语句的时候，你可以通过一些参数来调整并发度，以控制对系统的影响。
tidb_build_stats_concurrency 目前 ANALYZE 执行的时候会被切分成一个个小的任务，每个任务只负责某一个列或者索引。tidb_build_stats_concurrency 可以控制同时执行的任务的数量，其默认值是 4。
tidb_distsql_scan_concurrency 在执行分析普通列任务的时候，tidb_distsql_scan_concurrency 可以用于控制一次读取的 Region 数量，其默认值是 10。
tidb_index_serial_scan_concurrency 在执行分析索引列任务的时候，tidb_index_serial_scan_concurrency 可以用于控制一次读取的 Region 数量，其默认值是 1。
统计信息的查看 你可以通过一些语句来查看统计信息的状态。
表的元信息 你可以通过 SHOW STATS_META 来查看表的总行数以及修改的行数等信息。</description>
    </item>
    
    <item>
      <title>行业销售总监</title>
      <link>https://pingcap.com/recruit-cn/sales/sales-director/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/sales/sales-director/</guid>
      <description>行业销售总监 岗位职责  负责分布式数据库产品的业务拓展、合作及销售
 深入掌握和分析行业市场信息，把握最新销售信息，为公司提供业务发展战略依据
 负责目标顾客的开发与维护、项目谈判，调配各种资源达成公司制定销售指标，扩大产品的市场占有率
 负责拓展新客户和新业务，积极了解客户的需求并进行专业分析和评估，制定合理销售方案
 完成整体业绩指标，包括销售额和回款额
  职位要求  本科或以上学历，通信、计算机、企业管理、市场营销等相关专业
 五年以上IT产品厂商和集成商销售经验，出色的过往销售业绩
 有特定行业的客户和渠道资源，比如政府、银行、保险、电信、能源等
 出众的沟通表达能力、抗压能力、管理能力，具有敬业精神及团队合作意识
 如有数据库技术经验或售前实施经验有加分
  待遇 25K - 35K , 13薪 + 业绩奖金，优秀者可面议
工作地点 北京</description>
    </item>
    
    <item>
      <title>表达式求值的类型转换</title>
      <link>https://pingcap.com/docs-cn/sql/type-conversion-in-expression-evaluation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/type-conversion-in-expression-evaluation/</guid>
      <description>表达式求值的类型转换 TiDB 中表达式求值的类型转换与 MySQL 基本一致，详情参见 MySQL 表达式求值的类型转换。</description>
    </item>
    
    <item>
      <title>表达式语法</title>
      <link>https://pingcap.com/docs-cn/sql/expression-syntax/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/expression-syntax/</guid>
      <description>表达式语法(Expression Syntax) 在 TiDB 中，以下规则是表达式的语法，你可以在 parser/parser.y 中找到定义。TiDB 的语法解析是基于 yacc 的。
Expression: singleAtIdentifier assignmentEq Expression | Expression logOr Expression | Expression &amp;#34;XOR&amp;#34; Expression | Expression logAnd Expression | &amp;#34;NOT&amp;#34; Expression | Factor IsOrNotOp trueKwd | Factor IsOrNotOp falseKwd | Factor IsOrNotOp &amp;#34;UNKNOWN&amp;#34; | Factor Factor: Factor IsOrNotOp &amp;#34;NULL&amp;#34; | Factor CompareOp PredicateExpr | Factor CompareOp singleAtIdentifier assignmentEq PredicateExpr | Factor CompareOp AnyOrAll SubSelect | PredicateExpr PredicateExpr: PrimaryFactor InOrNotOp &amp;#39;(&amp;#39; ExpressionList &amp;#39;)&amp;#39; | PrimaryFactor InOrNotOp SubSelect | PrimaryFactor BetweenOrNotOp PrimaryFactor &amp;#34;AND&amp;#34; PredicateExpr | PrimaryFactor LikeOrNotOp PrimaryExpression LikeEscapeOpt | PrimaryFactor RegexpOrNotOp PrimaryExpression | PrimaryFactor PrimaryFactor: PrimaryFactor &amp;#39;|&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;&amp;amp;&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;&amp;lt;&amp;lt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;&amp;gt;&amp;gt;&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;+&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;-&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;*&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;/&amp;#39; PrimaryFactor | PrimaryFactor &amp;#39;%&amp;#39; PrimaryFactor | PrimaryFactor &amp;#34;DIV&amp;#34; PrimaryFactor | PrimaryFactor &amp;#34;MOD&amp;#34; PrimaryFactor | PrimaryFactor &amp;#39;^&amp;#39; PrimaryFactor | PrimaryExpression PrimaryExpression: Operand | FunctionCallKeyword | FunctionCallNonKeyword | FunctionCallAgg | FunctionCallGeneric | Identifier jss stringLit | Identifier juss stringLit | SubSelect | &amp;#39;!</description>
    </item>
    
    <item>
      <title>跨机房部署方案</title>
      <link>https://pingcap.com/docs-cn/op-guide/location-awareness/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/location-awareness/</guid>
      <description>跨机房部署方案 概述 PD 能够根据 TiKV 集群的拓扑结构进行调度，使得 TiKV 的容灾能力最大化。
阅读本章前，请先确保阅读 Binary 部署方案 和 Docker 部署方案。
TiKV 上报拓扑信息 可以通过 TiKV 的启动参数或者配置文件来让 TiKV 上报拓扑信息给 PD。
假设拓扑结构分为三级：zone &amp;gt; rack &amp;gt; host，可以通过 labels 来指定这些信息。
启动参数：
tikv-server --labels zone=&amp;lt;zone&amp;gt;,rack=&amp;lt;rack&amp;gt;,host=&amp;lt;host&amp;gt; 配置文件：
[server] labels = &amp;#34;zone=&amp;lt;zone&amp;gt;,rack=&amp;lt;rack&amp;gt;,host=&amp;lt;host&amp;gt;&amp;#34; PD 理解 TiKV 拓扑结构 可以通过 PD 的配置文件让 PD 理解 TiKV 集群的拓扑结构。
[replication] max-replicas = 3 location-labels = [&amp;#34;zone&amp;#34;, &amp;#34;rack&amp;#34;, &amp;#34;host&amp;#34;] 其中 location-labels 需要与 TiKV 的 labels 名字对应，这样 PD 才能知道这些 labels 代表了 TiKV 的拓扑结构。</description>
    </item>
    
    <item>
      <title>软件和硬件环境要求</title>
      <link>https://pingcap.com/docs-cn/op-guide/recommendation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/recommendation/</guid>
      <description>TiDB 软件和硬件环境要求 概述 TiDB 作为一款开源分布式 NewSQL 数据库，可以很好的部署和运行在 Intel 架构服务器环境及主流虚拟化环境，并支持绝大多数的主流硬件网络。作为一款高性能数据库系统，TiDB 支持主流的 Linux 操作系统环境。
Linux 操作系统版本要求    Linux 操作系统平台 版本     Red Hat Enterprise Linux 7.3 及以上   CentOS 7.3 及以上   Oracle Enterprise Linux 7.3 及以上   Ubuntu LTS 16.04 及以上     注：
 TiDB 只支持 Red Hat 兼容内核 (RHCK) 的 Oracle Enterprise Linux，不支持 Oracle Enterprise Linux 提供的 Unbreakable Enterprise Kernel。 TiDB 对 Linux 操作系统的以上支持包括部署和运行在物理服务器以及 VMware、KVM、XEN 主流虚拟化环境。   服务器要求 TiDB 支持部署和运行在 Intel x86-64 架构的 64 位通用硬件服务器平台。对于开发，测试，及生产环境的服务器硬件配置有以下要求和建议：</description>
    </item>
    
    <item>
      <title>重要监控指标详解</title>
      <link>https://pingcap.com/docs-cn/op-guide/dashboard-overview-info/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/op-guide/dashboard-overview-info/</guid>
      <description>重要监控指标详解 使用 ansible 部署 tidb 集群时，一键部署监控系统 (prometheus/grafana)，监控架构请看 TiDB 监控框架概述
目前 grafana dashboard 整体分为四个 dashboard，node_export，PD，TIDB，TIKV。 内容较多，主要在于尽快让 TIDB 开发确认问题。
对于日常运维，我们单独挑选出重要的 metrics 放在 overview 页面，方便日常运维人员观察集群组件(PD, TIDB, TIKV)使用状态以及集群使用状态 。
以下为 overview dashboard 说明：
说明  PD
 Storage Capacity : tidb 集群总可用数据库空间大小 Current Storage Size : tidb 集群目前已用数据库空间大小 Store Status &amp;ndash; up store : tikv 正常节点数量 Store Status &amp;ndash; down store : tikv 异常节点数量
如果大于0，证明有节点不正常
 Store Status &amp;ndash; offline store : 手动执行下线操作tikv节点数量</description>
    </item>
    
    <item>
      <title>错误码与故障诊断</title>
      <link>https://pingcap.com/docs-cn/sql/error/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/docs-cn/sql/error/</guid>
      <description>错误码与故障诊断 本篇文档描述在使用 TiDB 过程中会遇到的问题以及解决方法。
错误码 TiDB 兼容 MySQL 的错误码，在大多数情况下，返回和 MySQL 一样的错误码。另外还有一些特有的错误码：
   错误码 说明     9001 请求 PD 超时，请检查 PD Server 状态/监控/日志以及 TiDB Server 与 PD Server 之间的网络   9002 请求 TiKV 超时，请检查 TiKV Server 状态/监控/日志以及 TiDB Server 与 TiKV Server 之间的网络   9003 TiKV 操作繁忙，一般出现在数据库负载比较高时，请检查 TiKV Server 状态/监控/日志   9004 当数据库上承载的业务存在大量的事务冲突时，会遇到这种错误，请检查业务代码   9005 某个 Raft Group 不可用，如副本数目不足，出现在 TiKV 比较繁忙或者是 TiKV 节点停机的时候，请检查 TiKV Server 状态/监控/日志   9006 GC Life Time 间隔时间过短，长事务本应读到的数据可能被清理了,应增加GC Life Time   9500 单个事务过大，原因及解决方法请参考这里    故障诊断 参见故障诊断文档以及 FAQ。</description>
    </item>
    
    <item>
      <title>高级业务拓展（销售）经理</title>
      <link>https://pingcap.com/recruit-cn/sales/senior-business-manager/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/recruit-cn/sales/senior-business-manager/</guid>
      <description>高级业务拓展（销售）经理 岗位职责  负责分布式数据库产品的业务拓展、合作及销售，偏新客户拓展
 收集整理市场信息，推动合作伙伴、分销渠道的横向和纵向发展
 总结行业特性、配合售前部门梳理行业解决方案
 完成整体业绩指标，包括销售额和回款额
  职位要求  本科或以上学历，通信、计算机、企业管理、市场营销等相关专业
 三年以上软件、数据、信息、咨询服务产品的销售、渠道经验
 有潜在客户和渠道资源优先，比如互联网金融行业、游戏行业、券商保险行业、政府行业
 出众的沟通表达能力和抗压能力，具有敬业精神及团队合作意识
 如有数据库技术经验或售前实施经验有加分
  待遇 15K - 30K , 13薪 + 业绩奖金，优秀者可面议
工作地点 北京</description>
    </item>
    
  </channel>
</rss>